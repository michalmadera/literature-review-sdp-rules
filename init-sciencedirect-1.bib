
@article{baum_gimo_2020,
	title = {{GIMO}: A multi-objective anytime rule mining system to ease iterative feedback from domain experts},
	volume = {8},
	issn = {25901885},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090830401&doi=10.1016%2fj.eswax.2020.100040&partnerID=40&md5=0c2a7764b294fd08cc3c164779f2860d},
	doi = {10.1016/j.eswax.2020.100040},
	abstract = {Data extracted from software repositories is used intensively in Software Engineering research, for example, to predict defects in source code. In our research in this area, with data from open source projects as well as an industrial partner, we noticed several shortcomings of conventional data mining approaches for classification problems: (1) Domain experts’ acceptance is of critical importance, and domain experts can provide valuable input, but it is hard to use this feedback. (2) Evaluating the quality of the model is not a matter of calculating {AUC} or accuracy. Instead, there are multiple objectives of varying importance with hard to quantify trade-offs. Furthermore, the performance of the model cannot be evaluated on a per-instance level in our case, because it shares aspects with the set cover problem. To overcome these problems, we take a holistic approach and develop a rule mining system that simplifies iterative feedback from domain experts and can incorporate the domain-specific evaluation needs. A central part of the system is a novel multi-objective anytime rule mining algorithm. The algorithm is based on the {GRASP}-{PR} meta-heuristic but extends it with ideas from several other approaches. We successfully applied the system in the industrial context. In the current article, we focus on the description of the algorithm and the concepts of the system. We make an implementation of the system available. © 2020 The Authors},
	journaltitle = {Expert Systems with Applications: X},
	author = {Baum, T. and Herbold, S. and Schneider, K.},
	date = {2020},
	note = {Publisher: Elsevier Ltd},
	keywords = {Data mining, Open source software, Software repositories, Rule mining, Conventional data mining, Economic and social effects, Electronic trading, Holistic approach, Industrial context, Industrial partners, Industrial research, Iterative methods, Knowledge acquisition, Mining machinery, Multiple-objectives, Open source projects, Rule mining algorithms, Explainable artificial intelligence, Human-in-the-loop, Interpretable artificial intelligence, Multi-objective, Set cover, xyes},
	file = {Full Text:C\:\\Users\\michalm\\Zotero\\storage\\MQY3F42D\\Baum et al. - 2020 - GIMO A multi-objective anytime rule mining system.pdf:application/pdf;Full Text:C\:\\Users\\michalm\\Zotero\\storage\\RKJXJ5TB\\Baum et al. - 2020 - GIMO A multi-objective anytime rule mining system.pdf:application/pdf}
}

@article{shao_software_2020,
	title = {Software defect prediction based on correlation weighted class association rule mining},
	volume = {196},
	issn = {09507051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082463500&doi=10.1016%2fj.knosys.2020.105742&partnerID=40&md5=aafe1f60cfd93765b177edb265fe468d},
	doi = {10.1016/j.knosys.2020.105742},
	abstract = {Software defect prediction based on supervised learning plays a crucial role in guiding software testing for resource allocation. In particular, it is worth noticing that using associative classification with high accuracy and comprehensibility can predict defects. But owing to the imbalance data distribution inherent, it is easy to generate a large number of non-defective class association rules, but the defective class association rules are easily ignored. Furthermore, classical associative classification algorithms mainly measure the interestingness of rules by the occurrence frequency, such as support and confidence, without considering the importance of features, resulting in combinations of the insignificant frequent itemset. This promotes the generation of weighted associative classification. However, the feature weighting based on domain knowledge is subjective and unsuitable for a high dimensional dataset. Hence, we present a novel software defect prediction model based on correlation weighted class association rule mining ({CWCAR}). It leverages a multi-weighted supports-based framework rather than the traditional support-confidence approach to handle class imbalance and utilizes the correlation-based heuristic approach to assign feature weight. Besides, we also optimize the ranking, pruning and prediction stages based on weighted support. Results show that {CWCAR} is significantly superior to state-of-the-art classifiers in terms of Balance, {MCC}, and Gmean. © 2020 Elsevier B.V.},
	journaltitle = {Knowledge-Based Systems},
	author = {Shao, Y. and Liu, B. and Wang, S. and Li, G.},
	date = {2020},
	note = {Publisher: Elsevier B.V.},
	keywords = {Data mining, Defects, Software defect prediction, Forecasting, Apriori, Association rules, Associative classification, Attribute weighting, Class imbalance, Heuristic methods, Software testing, Association rule, xyes}
}

@article{barbez_machine-learning_2020,
	title = {A machine-learning based ensemble method for anti-patterns detection},
	volume = {161},
	issn = {01641212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076559059&doi=10.1016%2fj.jss.2019.110486&partnerID=40&md5=ec8a0ff172eff58af69f033014cacec9},
	doi = {10.1016/j.jss.2019.110486},
	abstract = {Anti-patterns are poor solutions to recurring design problems. Several empirical studies have highlighted their negative impact on program comprehension, maintainability, as well as fault-proneness. A variety of detection approaches have been proposed to identify their occurrences in source code. However, these approaches can identify only a subset of the occurrences and report large numbers of false positives and misses. Furthermore, a low agreement is generally observed among different approaches. Recent studies have shown the potential of machine-learning models to improve this situation. However, such algorithms require large sets of manually-produced training-data, which often limits their application in practice. In this paper, we present {SMAD} ({SMart} Aggregation of Anti-patterns Detectors), a machine-learning based ensemble method to aggregate various anti-patterns detection approaches on the basis of their internal detection rules. Thus, our method uses several detection tools to produce an improved prediction from a reasonable number of training examples. We implemented {SMAD} for the detection of two well known anti-patterns: God Class and Feature Envy. With the results of our experiments conducted on eight java projects, we show that: (1) Our method clearly improves the so aggregated tools; (2) {SMAD} significantly outperforms other ensemble methods. © 2019},
	journaltitle = {Journal of Systems and Software},
	author = {Barbez, A. and Khomh, F. and Guéhéneuc, Y.-G.},
	date = {2020},
	note = {Publisher: Elsevier Inc.},
	keywords = {Computer software selection and evaluation, Software quality, Empirical studies, Learning systems, Machine learning, Anti-patterns, Detection approach, Ensemble methods, Machine learning models, Pattern recognition, Program comprehension, Software Quality, Training example, xno},
	file = {Submitted Version:C\:\\Users\\michalm\\Zotero\\storage\\8J6XU45L\\Barbez et al. - 2020 - A machine-learning based ensemble method for anti-.pdf:application/pdf}
}

@article{chatterjee_mahalanobis_2018,
	title = {A Mahalanobis distance based algorithm for assigning rank to the predicted fault prone software modules},
	volume = {70},
	issn = {15684946},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049096980&doi=10.1016%2fj.asoc.2018.06.032&partnerID=40&md5=ed49f211663087ac70467c0e841e7f11},
	doi = {10.1016/j.asoc.2018.06.032},
	abstract = {This article proposes a methodology based on Artificial Neural Network({ANN}) and type-2 fuzzy logic system ({FLS}) for detecting the fault prone software modules at early development phase. The present research concentrates on software metrics from requirement analysis and design phase of software life cycle. A new approach has been developed to sort out degree of fault proneness ({DFP}) of the software modules through type-2 {FLS}. {ANN} is used to prepare the rule base for inference engine. Furthermore, the proposed model has induced an order relation among the fault prone modules ({FPMs}) with the help of Mahalanobis distance ({MD}) metric. During software development process, a project manager needs to recognize the fault prone software modules with their {DFP}. Hence, the present study is of great importance to the project personnel to develop more cost-effective and reliable software. {KC}2 dataset of {NASA} has been applied for validating the model. Performance analysis clearly indicates the better prediction capability of the proposed model compared to some existing similar models. © 2018 Elsevier B.V.},
	pages = {764--772},
	journaltitle = {Applied Soft Computing Journal},
	author = {Chatterjee, S. and Maji, B.},
	date = {2018},
	note = {Publisher: Elsevier Ltd},
	keywords = {Software metrics, Computer circuits, Software design, {NASA}, Software modules, Fuzzy inference, Fuzzy logic, Interval type-2 fuzzy logic systems, Life cycle, Neural networks, Cost effectiveness, Mahalanobis distances, Performance analysis, Prediction capability, Software development process, Type-2 fuzzy logic system, Artificial neural network, Fault prone software module, Interval type-2 fuzzy logic system, Mahalanobis distance, xno}
}

@article{goyal_fuzzy_2017,
	title = {Fuzzy inferencing to identify degree of interaction in the development of fault prediction models},
	volume = {29},
	issn = {13191578},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006791416&doi=10.1016%2fj.jksuci.2014.12.008&partnerID=40&md5=3e0f7210b23221ef38cf0b4799ed0bdf},
	doi = {10.1016/j.jksuci.2014.12.008},
	abstract = {The software fault prediction models, based on different modeling techniques have been extensively researched to improve software quality for the last three decades. Out of the analytical techniques used by the researchers, fuzzy modeling and its variants are bringing out a major share of the attention of research communities. In this work, we demonstrate the models developed through data driven fuzzy inference system. A comprehensive set of rules induced by such an inference system, followed by a simplification process provides deeper insight into the linguistically identified level of interaction. This work makes use of a publicly available data repository for four software modules, advocating the consideration of compound effects in the model development, especially in the area of software measurement. One related objective is the identification of influential metrics in the development of fault prediction models. A fuzzy rule intrinsically represents a form of interaction between fuzzified inputs. Analysis of these rules establishes that Low and {NOT} (High) level of inheritance based metrics significantly contributes to the F-measure estimate of the model. Further, the Lack of Cohesion of Methods ({LCOM}) metric was found insignificant in this empirical study. © 2015 The Authors},
	pages = {93--102},
	number = {1},
	journaltitle = {Journal of King Saud University - Computer and Information Sciences},
	author = {Goyal, R. and Chandra, P. and Singh, Y.},
	date = {2017},
	note = {Publisher: King Saud bin Abdulaziz University},
	keywords = {Software fault prediction, Object oriented metrics, Fuzzy inference system, Influential metrics, xyes}
}

@article{moeyersoms_comprehensible_2015,
	title = {Comprehensible software fault and effort prediction: A data mining approach},
	volume = {100},
	issn = {01641212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919361139&doi=10.1016%2fj.jss.2014.10.032&partnerID=40&md5=2eab3043a0a68f06cf9b0418d024f57f},
	doi = {10.1016/j.jss.2014.10.032},
	abstract = {Software fault and effort prediction are important tasks to minimize costs of a software project. In software effort prediction the aim is to forecast the effort needed to complete a software project, whereas software fault prediction tries to identify fault-prone modules. In this research both tasks are considered, thereby using different data mining techniques. The predictive models not only need to be accurate but also comprehensible, demanding that the user can understand the motivation behind the model's prediction. Unfortunately, to obtain predictive performance, comprehensibility is often sacrificed and vice versa. To overcome this problem, we extract trees from well performing Random Forests ({RFs}) and Support Vector Machines for regression ({SVRs}) making use of a rule extraction algorithm {ALPA}. This method builds trees (using C4.5 and {REPTree}) that mimic the black-box model ({RF}, {SVR}) as closely as possible. The proposed methodology is applied to publicly available datasets, complemented with new datasets that we have put together based on the Android repository. Surprisingly, the trees extracted from the black-box models by {ALPA} are not only comprehensible and explain how the black-box model makes (most of) its predictions, but are also more accurate than the trees obtained by working directly on the data. © 2014 Elsevier Inc. All rights reserved.},
	pages = {80--90},
	journaltitle = {Journal of Systems and Software},
	author = {Moeyersoms, J. and Junqué De Fortuny, E. and Dejaeger, K. and Baesens, B. and Martens, D.},
	date = {2015},
	note = {Publisher: Elsevier Inc.},
	keywords = {Data mining, Forecasting, Decision trees, Forestry, Effort prediction, Extraction, Software fault prediction, Computer software, Rule extraction, Comprehensibility, Computer Programs, Data Processing, Fault-prone modules, Predictive performance, Rule extraction algorithms, Software effort prediction, Trees, Software fault and effort prediction, xyes},
	file = {Accepted Version:C\:\\Users\\michalm\\Zotero\\storage\\VYDKZISE\\Moeyersoms et al. - 2015 - Comprehensible software fault and effort predictio.pdf:application/pdf}
}

@article{sabbaghi_fcci_2020,
	title = {{FCCI}: A fuzzy expert system for identifying coincidental correct test cases},
	volume = {168},
	issn = {0164-1212},
	doi = {10.1016/j.jss.2020.110635},
	abstract = {Spectrum-based fault localization ({SBFL}) is a promising approach to reduce the cost of program debugging and there has been a large body of research on introducing effective {SBFL} techniques. However, performance of these techniques can be adversely affected by the existence of coincidental correct ({CC}) test cases in the test suites. Such test cases execute the faulty statement but do not cause failures. Given that coincidental correctness is prevalent, it is necessary to precisely identify {CC} test cases and eliminate their effects from test suites. To do so, in this paper, we propose several important factors to identify {CC} test cases and model the {CC} identification process as a decision making system by constructing a fuzzy expert system and proposing a novel fuzzy {CC} identification method, namely {FCCI}. {FCCI} estimates the {CC} likelihood of passed test cases using the designed fuzzy rules, which effectively correlate the proposed {CC} identification factors. We evaluated {FCCI} by conducting extensive experiments on 17 popular and open source subject programs ranging from small- to large-scale containing both artificial and real faults. The experimental results indicate that {FCCI} successfully improves the accuracy of the {CC} identification as well as the accuracy of the representative {SBFL} techniques. (C) 2020 Elsevier Inc. All rights reserved.},
	journaltitle = {{JOURNAL} {OF} {SYSTEMS} {AND} {SOFTWARE}},
	author = {Sabbaghi, Arash and Keyvanpour, Mohammad Reza and Parsa, Saeed},
	date = {2020-10},
	keywords = {Software debugging, Spectrum-based fault localization, Fuzzy expert system, Coincidentally correct test cases, xno}
}

@article{huang_links_2014,
	title = {The links between human error diversity and software diversity: Implications for fault diversity seeking},
	volume = {89},
	issn = {0167-6423},
	doi = {10.1016/j.scico.2014.03.004},
	abstract = {Software diversity is known to improve fault tolerance in N-version software systems by independent development. As the leading cause of software faults, human error is considered an important factor in diversity seeking. However, there is little scientific research focusing on how to seek software fault diversity based on human error mechanisms. A literature review was conducted to extract factors that may differentiate people with respect to human error-proneness. In addition, we constructed a conceptual model of the links between human error diversity and software diversity. An experiment was designed to validate the hypotheses, in the form of a programming contest, accompanied by a survey of cognitive styles and personality traits. One hundred ninety-two programs were submitted for the identical problem, and 70 surveys were collected. Code inspection revealed 23 faults, of which 10 were coincident faults. The results show that personality traits seems not effective predictors for fault diversity as a whole model, whereas cognitive styles and program measurements moderately account for the variation of fault density. The results also show causal relations between performance levels and coincident faults; coincident faults are unlikely to occur at skill-based performance level; the coincident faults introduced in rule-based performances show a high probability of occurrence, and the coincident faults introduced in knowledge-based performances are shaped by the content and formats of the task itself. Based on these results, we have proposed a model to seek software diversity and prevent coincident faults. (C) 2014 Elsevier B.V. All rights reserved.},
	pages = {350--373},
	issue = {C},
	journaltitle = {{SCIENCE} {OF} {COMPUTER} {PROGRAMMING}},
	author = {Huang, Fuqun and Liu, Bin and Song, You and Keyal, Shreya},
	date = {2014-09-01},
	keywords = {Surveys, Computer software, Knowledge based systems, Cognitive styles, Errors, Human errors, N version programming, Personality traits, Software diversity, N-version programming, Cognitive style, Human error, Personality trait, xno}
}

@article{xu_feature_2021,
	title = {Feature selection and embedding based cross project framework for identifying crashing fault residence},
	volume = {131},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920302019},
	doi = {https://doi.org/10.1016/j.infsof.2020.106452},
	abstract = {Context: The automatically produced crash reports are able to analyze the root of fault causing the crash (crashing fault for short) which is a critical activity for software quality assurance. Objective: Correctly predicting the existence of crashing fault residence in stack traces of crash report can speed up program debugging process and optimize debugging efforts. Existing work focused on the collected label information from bug-fixing logs, and the extracted features of crash instances from stack traces and source code for Identification of Crashing Fault Residence ({ICFR}) of newly-submitted crashes. This work develops a novel cross project {ICFR} framework to address the data scarcity problem by using labeled crash data of other project for the {ICFR} task of the project at hand. This framework removes irrelevant features, reduces distribution differences, and eases the class imbalance issue of cross project data since these factors may negatively impact the {ICFR} performance. Method: The proposed framework, called {FSE}, combines Feature Selection and feature Embedding techniques. The {FSE} framework first uses an information gain ratio based feature ranking method to select a relevant feature subset for cross project data, and then employs a state-of-the-art Weighted Balanced Distribution Adaptation ({WBDA}) method to map features of cross project data into a common space. {WBDA} considers both marginal and conditional distributions as well as their weights to reduce data distribution discrepancies. Besides, {WBDA} balances the class proportion of each project data to alleviate the class imbalance issue. Results: We conduct experiments on 7 projects to evaluate the performance of our {FSE} framework. The results show that {FSE} outperforms 25 methods under comparison. Conclusion: This work proposes a cross project learning framework for {ICFR}, which uses feature selection and embedding to remove irrelevant features and reduce distribution differences, respectively. The results illustrate the performance superiority of our {FSE} framework.},
	pages = {106452},
	journaltitle = {Information and Software Technology},
	author = {Xu, Zhou and Zhang, Tao and Keung, Jacky and Yan, Meng and Luo, Xiapu and Zhang, Xiaohong and Xu, Ling and Tang, Yutian},
	date = {2021},
	keywords = {Crashing fault, Cross project framework, Feature embedding, Feature selection, Stack trace, xno}
}

@article{rathore_linear_2017,
	title = {Linear and non-linear heterogeneous ensemble methods to predict the number of faults in software systems},
	volume = {119},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705116305202},
	doi = {https://doi.org/10.1016/j.knosys.2016.12.017},
	abstract = {Several classification techniques have been investigated and evaluated earlier for the software fault prediction. These techniques have produced different prediction accuracy for the different software systems and none of the technique has always performed consistently better across different domains. On the other hand, software fault prediction using ensemble methods can be very effective, as they take the advantage of each participating technique for the given dataset and try to come up with better prediction results compared to the individual techniques. Many works are available for classifying software modules being faulty or non-faulty using the ensemble methods. These works are only specifying that whether a given software module is faulty or not, but number of faults in that module are not predicted by them. The use of ensemble methods for the prediction of number of faults has not been explored so far. To fulfill this gap, this paper presents ensemble methods for the prediction of number of faults in the given software modules. The experimental study is designed and conducted for five open-source software projects with their fifteen releases, collected from the {PROMISE} data repository. The results are evaluated under two different scenarios, intra-release prediction and inter-releases prediction. The prediction accuracy of ensemble methods is evaluated using absolute error, relative error, prediction at level l, and measure of completeness performance measures. Results show that the presented ensemble methods yield improved prediction accuracy over the individual fault prediction techniques under consideration. Further, the results are consistent for all the used datasets. The evidences obtained from the prediction at level l and measure of completeness analysis have also confirmed the effectiveness of the proposed ensemble methods for predicting the number of faults.},
	pages = {232--256},
	journaltitle = {Knowledge-Based Systems},
	author = {Rathore, Santosh Singh and Kumar, Sandeep},
	date = {2017},
	keywords = {Ensemble methods, Software fault prediction, Heterogeneous ensemble, Prediction of number of faults, xno}
}

@article{tahmooresi_studying_2020,
	title = {Studying the Relationship Between the Usage of {APIs} Discussed in the Crowd and Post-Release Defects},
	volume = {170},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301606},
	doi = {https://doi.org/10.1016/j.jss.2020.110724},
	abstract = {Software development nowadays is heavily based on libraries, frameworks and their proposed Application Programming Interfaces ({APIs}). However, due to challenges such as the complexity and the lack of documentation, these {APIs} may introduce various obstacles for developers and common defects in software systems. To resolve these issues, developers usually utilize Question and Answer (Q\&A) websites such as Stack Overflow by asking their questions and finding proper solutions for their problems on {APIs}. Therefore, these websites have become inevitable sources of knowledge for developers, which is also known as the crowd knowledge. However, the relation of this knowledge to the software quality has never been adequately explored before. In this paper, we study whether using {APIs} which are challenging according to the discussions of the Stack Overflow is related to code quality defined in terms of post-release defects. To this purpose, we define the concept of challenge of an {API}, which denotes how much the {API} is discussed in high-quality posts on Stack Overflow. Then, using this concept, we propose a set of products and process metrics. We empirically study the statistical correlation between our metrics and post-release defects as well as added explanatory and predictive power to traditional models through a case study on five open source projects including Spring, Elastic Search, Jenkins, K-8 Mail Android Client, and {OwnCloud} Android client. Our findings reveal that our metrics have a positive correlation with post-release defects which is comparable to known high-performance traditional process metrics, such as code churn and number of pre-release defects. Furthermore, our proposed metrics can provide additional explanatory and predictive power for software quality when added to the models based on existing products and process metrics. Our results suggest that software developers should consider allocating more resources on reviewing and improving external {API} usages to prevent further defects.},
	pages = {110724},
	journaltitle = {Journal of Systems and Software},
	author = {Tahmooresi, Hamed and Heydarnoori, Abbas and Nadri, Reza},
	date = {2020},
	keywords = {Defect prediction, {API}, Crowd knowledge, Stack overflow, xno}
}

@article{zhu_software_2021,
	title = {Software defect prediction based on enhanced metaheuristic feature selection optimization and a hybrid deep neural network},
	volume = {180},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121221001230},
	doi = {https://doi.org/10.1016/j.jss.2021.111026},
	abstract = {Software defect prediction aims to identify the potential defects of new software modules in advance by constructing an effective prediction model. However, the model performance is susceptible to irrelevant and redundant features. In addition, previous studies mainly use traditional data mining or machine learning techniques for defect prediction, the prediction performance is not superior enough. For the first issue, motivated by the idea of search based software engineering, we leverage the recently proposed whale optimization algorithm ({WOA}) and another complementary simulated annealing ({SA}) to construct an enhanced metaheuristic search based feature selection algorithm named {EMWS}, which can effectively select fewer but closely related representative features. For the second issue, we employ a hybrid deep neural network — convolutional neural network ({CNN}) and kernel extreme learning machine ({KELM}) to construct a unified defect prediction predictor called {WSHCKE}, which can further integrate the selected features into the abstract deep semantic features by {CNN} and boost the prediction performance by taking full advantage of the strong classification capacity of {KELM}. We conduct extensive experiments for feature selection or extraction and defect prediction across 20 widely-studied software projects on four evaluation indicators. Experimental results demonstrate the superiority of {EMWS} and {WSHCKE}.},
	pages = {111026},
	journaltitle = {Journal of Systems and Software},
	author = {Zhu, Kun and Ying, Shi and Zhang, Nana and Zhu, Dandan},
	date = {2021},
	keywords = {Software defect prediction, Convolutional neural network, Kernel extreme learning machine, Metaheuristic feature selection, Whale optimization algorithm, xno}
}

@article{malhotra_empirical_2016,
	title = {An empirical framework for defect prediction using machine learning techniques with Android software},
	volume = {49},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494616301806},
	doi = {https://doi.org/10.1016/j.asoc.2016.04.032},
	abstract = {Context Software defect prediction is important for identification of defect-prone parts of a software. Defect prediction models can be developed using software metrics in combination with defect data for predicting defective classes. Various studies have been conducted to find the relationship between software metrics and defect proneness, but there are few studies that statistically determine the effectiveness of the results. Objective The main objectives of the study are (i) comparison of the machine-learning techniques using data sets obtained from popular open source software (ii) use of appropriate performance measures for measuring the performance of defect prediction models (iii) use of statistical tests for effective comparison of machine-learning techniques and (iv) validation of models over different releases of data sets. Method In this study we use object-oriented metrics for predicting defective classes using 18 machine-learning techniques. The proposed framework has been applied to seven application packages of well known, widely used Android operating system viz. Contact, {MMS}, Bluetooth, Email, Calendar, Gallery2 and Telephony. The results are validated using 10-fold and inter-release validation methods. The reliability and significance of the results are evaluated using statistical test and post-hoc analysis. Results The results show that the area under the curve measure for Naïve Bayes, {LogitBoost} and Multilayer Perceptron is above 0.7 in most of the cases. The results also depict that the difference between the {ML} techniques is statistically significant. However, it is also proved that the Support Vector Machines based techniques such as Support Vector Machines and voted perceptron do not possess the predictive capability for predicting defects. Conclusion The results confirm the predictive capability of various {ML} techniques for developing defect prediction models. The results also confirm the superiority of one {ML} technique over the other {ML} techniques. Thus, the software engineers can use the results obtained from this study in the early phases of the software development for identifying defect-prone classes of given software.},
	pages = {1034--1050},
	journaltitle = {Applied Soft Computing},
	author = {Malhotra, Ruchika},
	date = {2016},
	keywords = {Statistical tests, Inter-release validation, Machine-learning, Object-oriented metrics, Software defect proneness, xno}
}

@article{wang_invariant_2019,
	title = {Invariant based fault localization by analyzing error propagation},
	volume = {94},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X18319186},
	doi = {https://doi.org/10.1016/j.future.2018.12.016},
	abstract = {Software intelligence is gradually becoming an interdisciplinary field with cognitive science and other disciplines. Especially in the mission-critical areas, whether the behavior of intelligent software conforms to expectations is a crucial issue. Program invariant based fault localization methods can obtain the desired behavior of the program by learning the execution information of successful test cases, and localize bugs by detecting invariant violations, which helps developers understand the cause of the failure and improve the quality of the software. This paper studies the problems of the existing methods, such as the limitation of the invariant definition, the lack of analysis on the impact of test cases and the error propagation, and tires to reduce the false negatives and false positives of invariant violation detection. First, the definition of the program invariants is enriched to localize more types of bugs. Then, the optimization strategies of reducing false positives and false negatives are studied. On the Siemens benchmark, we carried out incremental experimental analysis of the optimization strategies. The experimental results have shown that compared with the simple value range invariant based method, after performing the optimization strategies, the {NScore} value was increased by 75.2\%, which means that our method can effectively localize more kinds of bugs. When reviewing the same percentage of code, the ratio of localized buggy versions of our method is significantly higher than that of the spectra-based methods. When reviewing 1\% of the code with the worst effectiveness, the ratio of localized buggy versions of our method is about 0.6, and the ratio value of the spectra-based method is about 0.2.},
	pages = {549--563},
	journaltitle = {Future Generation Computer Systems},
	author = {Wang, {TianTian} and Wang, {KeChao} and Su, {XiaoHong} and Lei, Zhang},
	date = {2019},
	keywords = {Error propagation, Program invariant, Software fault localization, Test case selection, xno}
}

@article{szoke_empirical_2017,
	title = {Empirical study on refactoring large-scale industrial systems and its effects on maintainability},
	volume = {129},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121216301558},
	doi = {https://doi.org/10.1016/j.jss.2016.08.071},
	abstract = {Software evolves continuously, it gets modified, enhanced, and new requirements always arise. If we do not spend time occasionally on improving our source code, its maintainability will inevitably decrease. The literature tells us that we can improve the maintainability of a software system by regularly refactoring it. But does refactoring really increase software maintainability? Can it happen that refactoring decreases the maintainability? Empirical studies show contradicting answers to these questions and there have been only a few studies which were performed in a large-scale, industrial context. In our paper, we assess these questions in an in vivo context, where we analyzed the source code and measured the maintainability of 6 large-scale, proprietary software systems in their manual refactoring phase. We analyzed 2.5 million lines of code and studied the effects on maintainability of 315 refactoring commits which fixed 1273 coding issues. We found that single refactorings only make a very little difference (sometimes even decrease maintainability), but a whole refactoring period, in general, can significantly increase maintainability, which can result not only in the local, but also in the global improvement of the code.},
	pages = {107--126},
	journaltitle = {Journal of Systems and Software},
	author = {Szőke, Gábor and Antal, Gábor and Nagy, Csaba and Ferenc, Rudolf and Gyimóthy, Tibor},
	date = {2017},
	keywords = {Software quality, Maintainability, Antipatterns, Coding issues, {ISO}/{IEC} 25010, Refactoring, xno}
}

@article{miholca_comet_2020,
	title = {{COMET}: A conceptual coupling based metrics suite for software defect prediction},
	volume = {176},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050920318287},
	doi = {https://doi.org/10.1016/j.procs.2020.08.004},
	abstract = {Identifying defective software components is an essential activity during software development which contributes to continuously improving the software quality. Since relatively numerous defects are due to violated software dependencies, coupling metrics could increase the performance of software defect prediction. Among various measures expressing the coupling between software components, the conceptual coupling metrics capture similarities based on the semantic information contained in the source code. We are introducing a new conceptual coupling based metric suite, named {COMET}, for software defect prediction. Experiments conducted on publicly available data sets, using both unsupervised and supervised learning models, emphasize that {COMET} metrics suite is superior to the software metrics widely used in the defect prediction literature.},
	pages = {31--40},
	journaltitle = {Procedia Computer Science},
	author = {Miholca, Diana-Lucia and Czibula, Gabriela and Tomescu, Vlad},
	date = {2020},
	keywords = {Software metrics, Software defect prediction, Machine learning, 03B52, 68T35, Conceptual coupling, Source code 2000 {MSC}: 68T05, xyes}
}

@article{jaafar_analyzing_2017,
	title = {Analyzing software evolution and quality by extracting Asynchrony change patterns},
	volume = {131},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217300948},
	doi = {https://doi.org/10.1016/j.jss.2017.05.047},
	abstract = {Change patterns describe two or more files were often changed together during the development or the maintenance of software systems. Several studies have been presented to detect change patterns and to analyze their types and their impact on software quality. In this context, we introduced the Asynchrony change pattern to describes a set of files that always change together in the same change periods, regardless developers who maintained them. In this paper, we investigate the impact of Asynchrony change pattern on design and code smells such as anti-patterns and code clones. Concretely, we conduct an empirical study by detecting Asynchrony change patterns, anti-patterns and code clones occurrences on 22 versions of four software systems and analyzing their fault-proneness. Results show that cloned files that follow the same Asynchrony change patterns have significantly increased fault-proneness with respect to other clones, and that anti-patterns following the same Asynchrony change pattern can be up to five times more risky in terms of fault-proneness as compared to other anti-patterns. Asynchrony change patterns thus seem to be strong indicators of fault-proneness for clones and anti-patterns.},
	pages = {311--322},
	journaltitle = {Journal of Systems and Software},
	author = {Jaafar, Fehmi and Lozano, Angela and Guéhéneuc, Yann-Gaël and Mens, Kim},
	date = {2017},
	keywords = {Software quality, Anti-patterns, Fault-proneness, Change patterns, Clones, xno}
}

@article{palomba_predicting_2021,
	title = {Predicting the emergence of community smells using socio-technical metrics: A machine-learning approach},
	volume = {171},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220302375},
	doi = {https://doi.org/10.1016/j.jss.2020.110847},
	abstract = {Community smells represent sub-optimal conditions appearing within software development communities (e.g., non-communicating sub-teams, deviant contributors, etc.) that may lead to the emergence of social debt and increase the overall project’s cost. Previous work has studied these smells under different perspectives, investigating their nature, diffuseness, and impact on technical aspects of source code. Furthermore, it has been shown that some socio-technical metrics like, for instance, the well-known socio-technical congruence, can potentially be employed to foresee their appearance. Yet, there is still a lack of knowledge of the actual predictive power of such socio-technical metrics. In this paper, we aim at tackling this problem by empirically investigating (i) the potential value of socio-technical metrics as predictors of community smells and (ii) what is the performance of within- and cross-project community smell prediction models based on socio-technical metrics. To this aim, we exploit a dataset composed of 60 open-source projects and consider four community smells such as Organizational Silo, Black Cloud, Lone Wolf, and Bottleneck. The key results of our work report that a within-project solution can reach F-Measure and {AUC}-{ROC} of 77\% and 78\%, respectively, while cross-project models still require improvements, being however able to reach an F-Measure of 62\% and overcome a random baseline. Among the metrics investigated, socio-technical congruence, communicability, and turnover-related metrics are the most powerful predictors of the emergence of community smells.},
	pages = {110847},
	journaltitle = {Journal of Systems and Software},
	author = {Palomba, Fabio and Tamburri, Damian Andrew},
	date = {2021},
	keywords = {Community smells, Empirical software engineering, Social debt, xno}
}

@article{kumar_empirical_2017,
	title = {An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes},
	volume = {53},
	issn = {0920-5489},
	url = {https://www.sciencedirect.com/science/article/pii/S0920548916300885},
	doi = {https://doi.org/10.1016/j.csi.2017.02.003},
	abstract = {Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for fault prediction. The obtained set of source code metrics are considered as the input to develop a fault prediction model using a neural network with five different training algorithms and three different ensemble methods. The effectiveness of the developed fault prediction models are evaluated using a proposed cost evaluation framework. We performed experiments on fifty six Open Source Java projects. The experimental results reveal that the model developed by considering the selected set of source code metrics using the suggested source code metrics validation framework as the input achieves better results compared to all other metrics. The experimental results also demonstrate that the fault prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low – 48.89\%, median- 39.26\%, and high – 27.86\%).},
	pages = {1--32},
	journaltitle = {Computer Standards \& Interfaces},
	author = {Kumar, Lov and Misra, Sanjay and Rath, Santanu Ku},
	date = {2017},
	keywords = {Source code metrics, Artificial neural network, Cost analysis framework, Ensemble method, Feature selection techniques, xno}
}

@article{carrozza_software_2018,
	title = {A software quality framework for large-scale mission-critical systems engineering},
	volume = {102},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918300922},
	doi = {https://doi.org/10.1016/j.infsof.2018.05.009},
	abstract = {Context:In the industry of large-scale mission-critical systems, software is a pivotal asset and a key business driver. Production and maintenance costs of systems in domains like air/naval traffic control or homeland security are largely dependent on the quality of software, and there are numerous examples where poor software quality is blamed for major business failures. Because of the size, the complexity and the nature of systems and engineering processes in this industry, there is a strong need yet a slow shift toward innovation in software quality management. Objective:We present {SVEVIA}, a framework for software quality assessment and strategic decisions support for large-scale mission-critical systems engineering, and its application in a three years long industry-academy cooperation. Method:We started with the analysis of the industrial software quality management processes, and identified the key challenges toward a satisfying quality-cost-time trade-off. We defined new methods for product/process quality assessment, prediction, planning and optimization. We experimented them on the industrial partner systems and processes. They finally conflated in the {SVEVIA} framework. Results:{SVEVIA} was integrated into the industrial process, and tested with hundreds of software (sub)systems. More than 20 millions of lines of code – deployed in about 20 sites in Italy and {UK} – have come under the new quality measurement and improvement chain. The framework proved its ability to support systematic management of software quality and key decisions for productivity improvement. Conclusion:{SVEVIA} supports team leaders and managers coping with software quality in mission-critical industries, yielding figures and projections about quality and productivity trends for a prompt and informed decision-making.},
	pages = {100--116},
	journaltitle = {Information and Software Technology},
	author = {Carrozza, Gabriella and Pietrantuono, Roberto and Russo, Stefano},
	date = {2018},
	keywords = {Software quality, Software testing, Software reliability, Fault prediction, Defect prediction, Decision support systems, Automatic static analysis, Mission-critical systems, Testing resource allocation, xno}
}

@incollection{koren_chapter_2021,
	location = {San Francisco ({CA})},
	edition = {Second Edition},
	title = {Chapter 5 - Software Fault Tolerance},
	isbn = {978-0-12-818105-8},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128181058000152},
	abstract = {Software has become increasingly complex. It is very difficult to test software to the point where one can be confident that it is free of all faults. Therefore when used in applications, where high reliability is required, fault tolerance is necessary. We cover in this chapter the major approaches that have been developed to ensure fault tolerance in software. The topics covered include wrapping software to make it less failure-prone, the use of rejuvenation, N-version programming, and recovery blocks; software reliability models; exception handling, and fault-tolerant remote procedure calls.},
	pages = {161--202},
	booktitle = {Fault-Tolerant Systems (Second Edition)},
	publisher = {Morgan Kaufmann},
	author = {Koren, Israel and Krishna, C. Mani},
	editor = {Koren, Israel and Krishna, C. Mani},
	date = {2021},
	doi = {https://doi.org/10.1016/B978-0-12-818105-8.00015-2},
	keywords = {data diversity, exception handling, fault-tolerant remote procedure calls, N-version programming, recovery blocks, software rejuvenation, software reliability models, Software wrappers, xno}
}

@article{agrawal_source_2019,
	title = {A source code perspective framework to produce secure web applications},
	volume = {2019},
	issn = {1361-3723},
	url = {https://www.sciencedirect.com/science/article/pii/S1361372319301071},
	doi = {https://doi.org/10.1016/S1361-3723(19)30107-1},
	abstract = {Hackers and other cyber attackers remain fearless concerning the mitigation mechanisms that have evolved for addressing security over the past few years. Cyber attacks are on the rise and countless security breaches take place daily. It is believed that cybercrime in its various forms will cost the world \$6tr per year by 2021.1 It has become essential that software companies evaluate their businesses to identify application security needs, strategies and weaknesses. Establishing a security policy to safeguard their software applications has become an urgent need. Vulnerable applications are the bane of the software industry. Software companies need to make sure that their developers write more secure code, but developers struggle with this issue. To encourage developers to write secure source code, there is a need to integrate the whole process of scanning, detecting and mitigating security vulnerabilities and flaws during code analysis. Alka Agrawal, Mamdouh Alenezi, Rajeev Kumar and Raees Ahmad Khan propose an integrated and prescriptive framework intended to identify and mitigate vulnerabilities and provide suggestions for writing more secure code.},
	pages = {11--18},
	number = {10},
	journaltitle = {Computer Fraud \& Security},
	author = {Agrawal, Alka and Alenezi, Mamdouh and Kumar, Rajeev and Khan, Raees Ahmad},
	date = {2019},
	keywords = {xno}
}

@article{lenarduzzi_sonarqube_2020,
	title = {Some {SonarQube} issues have a significant but small effect on faults and changes. A large-scale empirical study},
	volume = {170},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301734},
	doi = {https://doi.org/10.1016/j.jss.2020.110750},
	abstract = {Context: Companies frequently invest effort to remove technical issues believed to impact software qualities, such as removing anti-patterns or coding styles violations. Objective: We aim to analyze the diffuseness of {SonarQube} issues in software systems and to assess their impact on code changes and fault-proneness, considering also their different types and severities. Methods: We conducted a case study among 33 Java projects from the Apache Software Foundation repository. Results: We analyzed 726 commits containing 27K faults and 12M changes in Java files. The projects violated 173 {SonarQube} rules generating more than 95K {SonarQube} issues in more than 200K classes. Classes not affected by {SonarQube} issues are less change-prone than affected ones, but the difference between the groups is small. Non-affected classes are slightly more change-prone than classes affected by {SonarQube} issues of type Code Smell or Security Vulnerability. As for fault-proneness, there is no difference between non-affected and affected classes. Moreover, we found incongruities in the type and severity assigned by {SonarQube}. Conclusion: Our result can be useful for practitioners to understand which {SonarQube} issues should be refactored and for researchers to bridge the missing gaps. Moreover, results can also support companies and tool vendors in identifying {SonarQube} issues as accurately as possible.},
	pages = {110750},
	journaltitle = {Journal of Systems and Software},
	author = {Lenarduzzi, Valentina and Saarimäki, Nyyti and Taibi, Davide},
	date = {2020},
	keywords = {Fault-proneness, {SonarQube}, Change-proneness, Empirical study, xno}
}

@article{higo_tracking_2020,
	title = {On tracking Java methods with Git mechanisms},
	volume = {165},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220300522},
	doi = {https://doi.org/10.1016/j.jss.2020.110571},
	abstract = {Method-level historical information is useful in various research on mining software repositories such as fault-prone module detection or evolutionary coupling identification. An existing technique named Historage converts a Git repository of a Java project to a finer-grained one. In a finer-grained repository, each Java method exists as a single file. Treating Java methods as files has an advantage, which is that Java methods can be tracked with Git mechanisms. The biggest benefit of tracking methods with Git mechanisms is that it can easily connect with any other tools and techniques build on Git infrastructure. However, Historage’s tracking has an issue of accuracy, especially on small methods. More concretely, in the case that a small method is renamed or moved to another class, Historage has a limited capability to track the method. In this paper, we propose a new technique, {FinerGit}, to improve the trackability of Java methods with Git mechanisms. We implement {FinerGit} as a system and apply it to 182 open source software projects, which include 1,768K methods in total. The experimental results show that our tool has a higher capability of tracking methods in the case that methods are renamed or moved to other classes.},
	pages = {110571},
	journaltitle = {Journal of Systems and Software},
	author = {Higo, Yoshiki and Hayashi, Shinpei and Kusumoto, Shinji},
	date = {2020},
	keywords = {Mining software repositories, Source code analysis, Tracking Java methods, xno}
}

@article{nunez-varela_source_2017,
	title = {Source code metrics: A systematic mapping study},
	volume = {128},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217300663},
	doi = {https://doi.org/10.1016/j.jss.2017.03.044},
	abstract = {Context Source code metrics are essential components in the software measurement process. They are extracted from the source code of the software, and their values allow us to reach conclusions about the quality attributes measured by the metrics. Objectives This paper aims to collect source code metrics related studies, review them, and perform an analysis, while providing an overview on the current state of source code metrics and their current trends. Method A systematic mapping study was conducted. A total of 226 studies, published between the years 2010 and 2015, were selected and analyzed. Results Almost 300 source code metrics were found. Object oriented programming is the most commonly studied paradigm with the Chidamber and Kemerer metrics, lines of code, {McCabe}'s cyclomatic complexity, and number of methods and attributes being the most used metrics. Research on aspect and feature oriented programming is growing, especially for the current interest in programming concerns and software product lines. Conclusions Object oriented metrics have gained much attention, but there is a current need for more studies on aspect and feature oriented metrics. Software fault prediction, complexity and quality assessment are recurrent topics, while concerns, big scale software and software product lines represent current trends.},
	pages = {164--197},
	journaltitle = {Journal of Systems and Software},
	author = {Nuñez-Varela, Alberto S. and Pérez-Gonzalez, Héctor G. and Martínez-Perez, Francisco E. and Soubervielle-Montalvo, Carlos},
	date = {2017},
	keywords = {Software metrics, Source code metrics, Object-oriented metrics, Aspect-oriented metrics, Feature-oriented metrics, Systematic mapping study, xno}
}

@article{andreou_software_2016,
	title = {Software defect prediction using doubly stochastic Poisson processes driven by stochastic belief networks},
	volume = {122},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121216301601},
	doi = {https://doi.org/10.1016/j.jss.2016.09.001},
	abstract = {Accurate prediction of software defects is of crucial importance in software engineering. Software defect prediction comprises two major procedures: (i) Design of appropriate software metrics to represent characteristic software system properties; and (ii) development of effective regression models for count data, allowing for accurate prediction of the number of software defects. Although significant research effort has been devoted to software metrics design, research in count data regression has been rather limited. More specifically, most used methods have not been explicitly designed to tackle the problem of metrics-driven software defect counts prediction, thus postulating irrelevant assumptions, such as (log-)linearity of the modeled data. In addition, a lack of simple and efficient algorithms for posterior computation has made more elaborate hierarchical Bayesian approaches appear unattractive in the context of software defect prediction. To address these issues, in this paper we introduce a doubly stochastic Poisson process for count data regression, the failure log-rate of which is driven by a novel latent space stochastic feedforward neural network. Our approach yields simple and efficient updates for its complicated conditional distributions by means of sampling importance resampling and error backpropagation. We exhibit the efficacy of our approach using publicly available and benchmark datasets.},
	pages = {72--82},
	journaltitle = {Journal of Systems and Software},
	author = {Andreou, Andreas S. and Chatzis, Sotirios P.},
	date = {2016},
	keywords = {Software defect prediction, Doubly stochastic Poisson process, Sampling importance resampling, Stochastic belief network, xno}
}

@article{hamill_analyzing_2017,
	title = {Analyzing and predicting effort associated with finding and fixing software faults},
	volume = {87},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917300290},
	doi = {https://doi.org/10.1016/j.infsof.2017.01.002},
	abstract = {Context: Software developers spend a significant amount of time fixing faults. However, not many papers have addressed the actual effort needed to fix software faults. Objective: The objective of this paper is twofold: (1) analysis of the effort needed to fix software faults and how it was affected by several factors and (2) prediction of the level of fix implementation effort based on the information provided in software change requests. Method: The work is based on data related to 1200 failures, extracted from the change tracking system of a large {NASA} mission. The analysis includes descriptive and inferential statistics. Predictions are made using three supervised machine learning algorithms and three sampling techniques aimed at addressing the imbalanced data problem. Results: Our results show that (1) 83\% of the total fix implementation effort was associated with only 20\% of failures. (2) Both post-release failures and safety-critical failures required more effort to fix than pre-release and non-critical counterparts, respectively; median values were two or more times higher. (3) Failures with fixes spread across multiple components or across multiple types of software artifacts required more effort. The spread across artifacts was more costly than spread across components. (4) Surprisingly, some types of faults associated with later life-cycle activities did not require significant effort. (5) The level of fix implementation effort was predicted with 73\% overall accuracy using the original, imbalanced data. Oversampling techniques improved the overall accuracy up to 77\% and, more importantly, significantly improved the prediction of the high level effort, from 31\% to 85\%. Conclusions: This paper shows the importance of tying software failures to changes made to fix all associated faults, in one or more software components and/or in one or more software artifacts, and the benefit of studying how the spread of faults and other factors affect the fix implementation effort.},
	pages = {1--18},
	journaltitle = {Information and Software Technology},
	author = {Hamill, Maggie and Goseva-Popstojanova, Katerina},
	date = {2017},
	keywords = {Analysis, Case study, Prediction, Software faults and failures, Software fix implementation effort, xno}
}

@article{singh_taxonomy_2018,
	title = {Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics},
	volume = {132},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050918308470},
	doi = {https://doi.org/10.1016/j.procs.2018.05.115},
	abstract = {Prediction of Fault proneness of a software component is the compelling field of investigations in software testing arena. Software coupling plays a vital role in assessing the software quality through fault prediction and complexity measures. Various fault prediction models, have used the object oriented metrics for the predicting and localizing the faults. Many of these metrics have direct influence on the quality of software. More over prior knowledge of the fault proneness of a component may significantly reduce the testing effort and time. The measures of object oriented features like inheritance, polymorphism and encapsulation etc may be used to estimate fault proneness. Many researchers have investigated the usage of object oriented metrics in the software fault prediction. In this study we present taxonomy of usage these metrics in the fault prediction. We also present the analysis of machine learning techniques in fault prediction.},
	pages = {993--1001},
	journaltitle = {Procedia Computer Science},
	author = {Singh, Ajmer and Bhatia, Rajesh and Singhrova, Anita},
	date = {2018},
	keywords = {Software fault prediction, machine learning, Object Oriented Coupling, Object Oriented Testing, software faults prediction, xno}
}

@article{dallal_investigating_2018,
	title = {Investigating the impact of fault data completeness over time on predicting class fault-proneness},
	volume = {95},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917305062},
	doi = {https://doi.org/10.1016/j.infsof.2017.11.001},
	abstract = {Context The adequacy of fault-proneness prediction models in representing the relationship between the internal quality of classes and their fault-proneness relies on several factors. One of these factors is the completeness of the fault data. A fault-proneness prediction model that is built using fault data collected during testing or after a relatively short period of time after release may be inadequate and may not be reliable enough in predicting faulty classes. Objective We empirically study the relationship between the time interval since a system is released and the performance of the fault-proneness prediction models constructed based on the fault data reported within the time interval. Method We construct prediction models using fault data collected at several time intervals since a system has been released and study the performance of the models in representing the relationship between the internal quality of classes and their fault-proneness. In addition, we empirically explore the relationship between the performance of a prediction model and the percentage of increase in the number of classes detected faulty ({PIF}) over time. Results Our results show evidence in favor of the expectation that predictions models that use more complete fault data, to a certain extent, more adequately represent the expected relationship between the internal quality of classes and their fault-proneness and have better performance. A threshold based on the {PIF} value can be used as an indicator for deciding when to stop collecting fault data. When reaching this threshold, collecting additional fault data will not significantly improve the prediction ability of the constructed model. Conclusion When constructing fault-proneness prediction models, researchers and software engineers are advised to rely on systems that have relatively long maintenance histories. Researchers and software engineers can use the {PIF} value as an indicator for deciding when to stop collecting fault data.},
	pages = {86--105},
	journaltitle = {Information and Software Technology},
	author = {Dallal, Jehad Al and Morasca, Sandro},
	date = {2018},
	keywords = {Fault data, Class fault-proneness, Internal quality attributes, Object-oriented software, Quality measures, xno}
}

@article{arora_open_2015,
	title = {Open Issues in Software Defect Prediction},
	volume = {46},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050915002252},
	doi = {https://doi.org/10.1016/j.procs.2015.02.161},
	abstract = {Software Defect Prediction ({SDP}) is one of the most assisting activities of the Testing Phase of {SDLC}. It identifies the modules that are defect prone and require extensive testing. This way, the testing resources can be used efficiently without violating the constraints. Though {SDP} is very helpful in testing, it's not always easy to predict the defective modules. There are various issues that hinder the smooth performance as well as use of the Defect Prediction models. In this report, we have distinguished some of the major issues of {SDP} and studied what has been done so far to address them.},
	pages = {906--912},
	journaltitle = {Procedia Computer Science},
	author = {Arora, Ishani and Tetarwal, Vivek and Saha, Anju},
	date = {2015},
	keywords = {machine learning, data mining, defect prediction, software quality, software testing, xno}
}

@incollection{hurson_chapter_2012,
	title = {Chapter 5 - A Framework for Detecting and Diagnosing Configuration Faults in Web Applications},
	volume = {86},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123965356000053},
	series = {Advances in Computers},
	abstract = {Software portability is a key concern when configuration settings affect software correctness and target operational environments are highly configurable. While achieving portability is key for a wide range of software types, it is particularly important in Web application development. The client configuration used to navigate and interact with Web content is known to be an important factor in the subsequent quality of deployed Web applications. Given current approaches and limited development resources, it is a significant challenge to develop Web applications that are viewable, functional, and portable for the vast Web configuration space. As a result, faults that only surface in precise configurations, termed configuration faults, have the potential to escape detection until Web applications are fielded. This chapter presents an automated, model-based framework that uses static analysis to detect and diagnose Web configuration faults. Our approach overcomes the limitations of current techniques by enabling efficient portability analysis across the vast array of client environments. The basic idea behind this approach is that source code fragments (i.e., Hypertext Markup Language ({HTML}) tags and Cascading Style Sheet ({CSS}) rules) embedded in Web application source code adversely impact portability of Web applications when they are unsupported in target client configurations. Without proper support, the source code is either processed incorrectly or ignored and the aesthetic or functional properties associated with the code may be lost resulting in configuration faults. Our approach is to model source code support in various configurations and perform portability analysis by checking for support violations in source code inclusion. In the effort to fully exploit this approach, improve practicality, and maximize fault detection efficiency, manual and automated approaches to client support knowledge acquisition have been implemented, variations of Web application and support criteria models have been investigated, and visualization of configuration fault detection results has been explored. To optimize the automated acquisition of client support knowledge, alternate learning strategies have been empirically investigated and provisions for capturing tag interaction have been integrated into the process.},
	pages = {137--181},
	publisher = {Elsevier},
	author = {Eaton, Cyntrica},
	editor = {Hurson, Ali and Memon, Atif},
	date = {2012},
	doi = {https://doi.org/10.1016/B978-0-12-396535-6.00005-3},
	note = {{ISSN}: 0065-2458},
	keywords = {Client configurations, Cross-platform compatibility, {CSS} rules, {HTML} tags, Web applications, Web testing, xno}
}

@article{mahdieh_incorporating_2020,
	title = {Incorporating fault-proneness estimations into coverage-based test case prioritization methods},
	volume = {121},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920300197},
	doi = {https://doi.org/10.1016/j.infsof.2020.106269},
	abstract = {Context: During the development process of a software program, regression testing is used to ensure that the correct behavior of the software is retained after updates to the source code. This regression testing becomes costly over time as the number of test cases increases and it makes sense to prioritize test cases in order to execute fault-detecting test cases as soon as possible. There are many coverage-based test case prioritization ({TCP}) methods that only use the code coverage data to prioritize test cases. By incorporating the fault-proneness estimations of code units into the coverage-based {TCP} methods, we can improve such techniques. Objective: In this paper, we aim to propose an approach which improves coverage-based {TCP} methods by considering the fault-proneness distribution over code units. Further, we present the results of an empirical study that shows using our proposed approach significantly improves the additional strategy, which is a widely used coverage-based {TCP} method. Method: The approach presented in this study uses the bug history of the software in order to introduce a defect prediction method to learn a neural network model. This model is then used to estimate fault-proneness of each area of the source code and then the estimations are incorporated into coverage-based {TCP} methods. Our proposed approach is a general idea that can be applied to many coverage-based methods, such as the additional and total {TCP} methods. Results: The proposed methods are evaluated on datasets collected from the development history of five real-world projects including 357 versions in total. The experiments show that using an appropriate bug history can improve coverage-based {TCP} methods. Conclusion: The proposed approach can be applied to various coverage-based {TCP} methods and the experiments show that it can improve these methods by incorporating estimations of code units fault-proneness.},
	pages = {106269},
	journaltitle = {Information and Software Technology},
	author = {Mahdieh, Mostafa and Mirian-Hosseinabadi, Seyed-Hassan and Etemadi, Khashayar and Nosrati, Ali and Jalali, Sajad},
	date = {2020},
	keywords = {Machine learning, Defect prediction, Regression testing, Bug history, Test case prioritization, xno}
}

@article{murtaza_empirical_2014,
	title = {An empirical study on the use of mutant traces for diagnosis of faults in deployed systems},
	volume = {90},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121213002768},
	doi = {https://doi.org/10.1016/j.jss.2013.11.1094},
	abstract = {Debugging deployed systems is an arduous and time consuming task. It is often difficult to generate traces from deployed systems due to the disturbance and overhead that trace collection may cause on a system in operation. Many organizations also do not keep historical traces of failures. On the other hand earlier techniques focusing on fault diagnosis in deployed systems require a collection of passing–failing traces, in-house reproduction of faults or a historical collection of failed traces. In this paper, we investigate an alternative solution. We investigate how artificial faults, generated using software mutation in test environment, can be used to diagnose actual faults in deployed software systems. The use of traces of artificial faults can provide relief when it is not feasible to collect different kinds of traces from deployed systems. Using artificial and actual faults we also investigate the similarity of function call traces of different faults in functions. To achieve our goal, we use decision trees to build a model of traces generated from mutants and test it on faulty traces generated from actual programs. The application of our approach to various real world programs shows that mutants can indeed be used to diagnose faulty functions in the original code with approximately 60–100\% accuracy on reviewing 10\% or less of the code; whereas, contemporary techniques using pass–fail traces show poor results in the context of software maintenance. Our results also show that different faults in closely related functions occur with similar function call traces. The use of mutation in fault diagnosis shows promising results but the experiments also show the challenges related to using mutants.},
	pages = {29--44},
	journaltitle = {Journal of Systems and Software},
	author = {Murtaza, Syed Shariyar and Hamou-Lhadj, Abdelwahab and Madhavji, Nazim H. and Gittens, Mechelle},
	date = {2014},
	keywords = {Fault diagnosis, Mutation, Software maintenance, xno}
}

@article{ozakinci_early_2018,
	title = {Early software defect prediction: A systematic map and review},
	volume = {144},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218301213},
	doi = {https://doi.org/10.1016/j.jss.2018.06.025},
	abstract = {Context Software defect prediction is a trending research topic, and a wide variety of the published papers focus on coding phase or after. A limited number of papers, however, includes the prior (early) phases of the software development lifecycle ({SDLC}). Objective The goal of this study is to obtain a general view of the characteristics and usefulness of Early Software Defect Prediction ({ESDP}) models reported in scientific literature. Method A systematic mapping and systematic literature review study has been conducted. We searched for the studies reported between 2000 and 2016. We reviewed 52 studies and analyzed the trend and demographics, maturity of state-of-research, in-depth characteristics, success and benefits of {ESDP} models. Results We found that categorical models that rely on requirement and design phase metrics, and few continuous models including metrics from requirements phase are very successful. We also found that most studies reported qualitative benefits of using {ESDP} models. Conclusion We have highlighted the most preferred prediction methods, metrics, datasets and performance evaluation methods, as well as the addressed {SDLC} phases. We expect the results will be useful for software teams by guiding them to use early predictors effectively in practice, and for researchers in directing their future efforts.},
	pages = {216--239},
	journaltitle = {Journal of Systems and Software},
	author = {Özakıncı, Rana and Tarhan, Ayça},
	date = {2018},
	keywords = {Software quality, Prediction model, Software defect, Early defect prediction, Systematic literature review, Systematic mapping, xno}
}

@article{honel_using_2020,
	title = {Using source code density to improve the accuracy of automatic commit classification into maintenance activities},
	volume = {168},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301291},
	doi = {https://doi.org/10.1016/j.jss.2020.110673},
	abstract = {Source code is changed for a reason, e.g., to adapt, correct, or adapt it. This reason can provide valuable insight into the development process but is rarely explicitly documented when the change is committed to a source code repository. Automatic commit classification uses features extracted from commits to estimate this reason. We introduce source code density, a measure of the net size of a commit, and show how it improves the accuracy of automatic commit classification compared to previous size-based classifications. We also investigate how preceding generations of commits affect the class of a commit, and whether taking the code density of previous commits into account can improve the accuracy further. We achieve up to 89\% accuracy and a Kappa of 0.82 for the cross-project commit classification where the model is trained on one project and applied to other projects. Models trained on single projects yield accuracies of up to 93\% with a Kappa approaching 0.90. The accuracy of the automatic commit classification has a direct impact on software (process) quality analyses that exploit the classification, so our improvements to the accuracy will also improve the confidence in such analyses.},
	pages = {110673},
	journaltitle = {Journal of Systems and Software},
	author = {Hönel, Sebastian and Ericsson, Morgan and Löwe, Welf and Wingkvist, Anna},
	date = {2020},
	keywords = {Software quality, Software evolution, Commit classification, Maintenance activities, Source code density, xno}
}

@article{agnelo_using_2020,
	title = {Using Orthogonal Defect Classification to characterize {NoSQL} database defects},
	volume = {159},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121219302250},
	doi = {https://doi.org/10.1016/j.jss.2019.110451},
	abstract = {{NoSQL} databases are increasingly used for storing and managing data in business-critical Big Data systems. The presence of software defects (i.e., bugs) in these databases can bring in severe consequences to the {NoSQL} services being offered, such as data loss or service unavailability. Thus, it is essential to understand the types of defects that frequently affect these databases, allowing developers take action in an informed manner (e.g., redirect testing efforts). In this paper, we use Orthogonal Defect Classification ({ODC}) to classify a total of 4096 software defects from three of the most popular {NoSQL} databases: {MongoDB}, Cassandra, and {HBase}. The results show great similarity for the defects across the three different {NoSQL} systems and, at the same time, show the differences and heterogeneity regarding research carried out in other domains and types of applications, emphasizing the need for possessing such information. Our results expose the defect distributions in {NoSQL} databases, provide a foundation for selecting representative defects for {NoSQL} systems, and, overall, can be useful for developers for verifying and building more reliable {NoSQL} database systems.},
	pages = {110451},
	journaltitle = {Journal of Systems and Software},
	author = {Agnelo, João and Laranjeiro, Nuno and Bernardino, Jorge},
	date = {2020},
	keywords = {Software fault, Defect analysis, Software defect, {NoSQL}, Orthogonal Defect Classification, xno}
}

@article{liu_weighted_2019,
	title = {A weighted fuzzy classification approach to identify and manipulate coincidental correct test cases for fault localization},
	volume = {151},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121219300196},
	doi = {https://doi.org/10.1016/j.jss.2019.01.056},
	abstract = {Identifying the location of faults effectively and accurately is highly important in the debugging process of software engineering. Coverage-based Fault Localization ({CBFL}) has been widely studied that can alleviate the effort of developers to find the faults position using the execution information of test cases. Coincidental Correct ({CC}) test cases are the specific test cases that execute the faulty statements but with a correct output, which have been illustrated with a negative effect on the accuracy of {CBFL}. In this paper, we propose a weighted fuzzy classification approach to identify {CC} test cases and three fuzzy strategies are suggested to manipulate {CC} test cases for {CBFL}. Firstly, we present a simple but efficient approach to identify some {CC} test cases for single fault programs, which provide labeled samples that enable the application of supervised classification algorithms for {CC} identification. Then, a Fuzzy Weighted K-Nearest Neighbor ({FW}-{KNN}) algorithm is proposed to classify potential {CC} from the passed test cases, in which a ‘weighted’ similarity measure and a “weighted” {CC} probability computation are presented. Finally, three fuzzy {CC} test cases manipulation strategies are presented to mitigate the impact of {CC} test cases in {CBFL}. Various empirical studies are conducted on 190 faulty versions of 12 programs to investigate the impact of “weighted” and “fuzzy” methods for {CC} identification by the comparison of the effectiveness and efficiency between {FW}-{KNN} and three popular cluster and classification techniques. The results indicate that the proposed {FW}-{KNN} has higher accuracy and lower time cost. The Precision, Recall and False Positive Rate of {FW}-{KNN} is 96.47\%, 83.40\% and 2.85\%, respectively. Besides, by utilizing code block coverage, the time cost can be reduced by 72.97\% in average compared to statement coverage. The experimental results also indicate that the fault localization accuracy of {CBFL} can be improved by the proposed {CC} test cases manipulation strategies.},
	pages = {20--37},
	journaltitle = {Journal of Systems and Software},
	author = {Liu, Yong and Li, Meiying and Wu, Yonghao and Li, Zheng},
	date = {2019},
	keywords = {Fuzzy classification, Coincidental correct test cases, Coverage-Based fault localization, K-Nearest Neighbor, Software debugging, xno}
}

@article{polaczek_exploring_2021,
	title = {Exploring the software repositories of embedded systems: An industrial experience},
	volume = {131},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920302317},
	doi = {https://doi.org/10.1016/j.infsof.2020.106489},
	abstract = {Context Tracing reports for software repositories have attracted many researchers. Most of them have focused on defect analysis and development processes in relation to open source programs. There exists a gap between open source and industrial software projects, which, in particular, relates to different schemes for creating software repositories and development schemes. This is especially true for embedded systems that gain large markets and become more complex. Objective The aim is to explore the software repositories of industrial embedded systems and derive characteristic features in order to evaluate quality and identify problems to do with development processes. Method In this paper we have proposed a novel approach to software repository analysis based on the fine grained exploration of issue tracking and code control repositories. In particular, we distinguish the various activities of project actors (e.g. creating new functions, correcting defects, improving performance, modifying tests) and analyse them in a context, not only of a single project, but also a set of correlated projects that have been developed in the company. These issues have been neglected in the literature. These analyses needed new holistic schemes for repository exploration, including various statistical metrics, text mining, and machine learning techniques. Results In exploring selected industrial projects we have identified that only 40–75\% of issues relate to defects; the issue reports and commit descriptions included here comprise a lot of data that has been disregarded in the literature. These data allow us to trace diverse types of code changes and identify imperfections in software repositories. Conclusion We show that fine grained repository analysis gives a broader and more complete view of project development, which may lead to its improvement.},
	pages = {106489},
	journaltitle = {Information and Software Technology},
	author = {Polaczek, Jakub and Sosnowski, Janusz},
	date = {2021},
	keywords = {Mining software repositories, Project management, Embedded systems, Defect handling, Software development monitoring, xno}
}

@article{tomas_open_2013,
	title = {Open source tools for measuring the Internal Quality of Java software products. A survey},
	volume = {36},
	issn = {0920-5489},
	url = {https://www.sciencedirect.com/science/article/pii/S0920548913000858},
	doi = {https://doi.org/10.1016/j.csi.2013.08.006},
	abstract = {Collecting metrics and indicators to assess objectively the different products resulting during the lifecycle of a software project is a research area that encompasses many different aspects, apart from being highly demanded by companies and software development teams. Focusing on software products, one of the most used methods by development teams for measuring Internal Quality is the static analysis of the source code. This paper works in this line and presents a study of the state-of-the-art open source software tools that automate the collection of these metrics, particularly for developments in Java. These tools have been compared according to certain criteria defined in this study.},
	pages = {244--255},
	number = {1},
	journaltitle = {Computer Standards \& Interfaces},
	author = {Tomas, P. and Escalona, M. J. and Mejias, M.},
	date = {2013},
	keywords = {Automation, Static analysis, Tools, Java, Internal Quality, Metrics, Open source, Software product, Source code, xno}
}

@article{kwiatkowski_recovering_2013,
	title = {Recovering management information from source code},
	volume = {78},
	issn = {0167-6423},
	url = {https://www.sciencedirect.com/science/article/pii/S016764231200144X},
	doi = {https://doi.org/10.1016/j.scico.2012.07.016},
	abstract = {{IT} has become a production means for many organizations and an important element of business strategy. Even though its effective management is a must, reality shows that this area still remains in its infancy. {IT} management relies profoundly on relevant information which enables risk mitigation or cost control. However, the needed information is either missing or its gathering boils down to daunting tasks. We propose an approach to recovery of management information from the essence of {IT}; the software’s source code. In this paper we show how to employ source code analysis techniques and recover management information. In our approach we exploit the potential of the concealed data which resides in the source code statements, source comments, and also compiler listings. We show how to depart from the raw sources, extract data, organize it, and eventually utilize so that the bit level data provides {IT} executives with support at the portfolio level. Our approach is pragmatic as we rely on real management questions, best practices in software engineering, and also {IT} market specifics. We enable, for instance, an assessment of the {IT}-portfolio market value, support for carrying out what-if scenarios, or identification and evaluation of the hidden risks for {IT}-portfolio maintainability. The study is based on a real-life {IT}-portfolio which supports business functions of an organization operating in the financial sector. The {IT}-portfolio comprises Cobol applications run on a mainframe with the total number of lines of code amounting to over 18 million. The approach we propose is suited for facilitation within a large organization. It provides for a fact-based support for strategic decision making at the portfolio level.},
	pages = {1368--1406},
	number = {9},
	journaltitle = {Science of Computer Programming},
	author = {Kwiatkowski, Ł M. and Verhoef, C.},
	date = {2013},
	keywords = {Legacy systems, Source code analysis, Case study, Automated data extraction, Cobol, Compilers, Cost control, Information retrieval, {IT} assets, {IT} metrics, {IT}-portfolio management, Latent Semantic Indexing, Lexical analysis, {LSI}, Management information, Market value, Obsolete language constructs, Operational risk, Risk mitigation, Scenario analysis, Source code comments, Technology risk, Vendor locks, Volatility, xno}
}

@article{jeon_autovas_2021,
	title = {{AutoVAS}: An automated vulnerability analysis system with a deep learning approach},
	volume = {106},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404821001322},
	doi = {https://doi.org/10.1016/j.cose.2021.102308},
	abstract = {Owing to the advances in automated hacking and analysis technologies in recent years, numerous software security vulnerabilities have been announced. Software vulnerabilities are increasing rapidly, whereas methods to analyze and cope with them depend on manual analyses, which result in a slow response. In recent years, studies concerning the prediction of vulnerabilities or the detection of patterns of previous vulnerabilities have been conducted by applying deep learning algorithms in an automated vulnerability search based on source code. However, existing methods target only certain security vulnerabilities or make limited use of source code to compile information. Few studies have been conducted on methods that represent source code as an embedding vector. Thus, this study proposes a deep learning-based automated vulnerability analysis system ({AutoVAS}) that effectively represents source code as embedding vectors by using datasets from various projects in the National Vulnerability Database ({NVD}) and Software Assurance Reference Database ({SARD}). To evaluate {AutoVAS}, we present and share a dataset for deep learning models. Experimental results show that {AutoVAS} achieves a false negative rate ({FNR}) of 3.62\%, a false positive rate ({FPR}) of 1.88\%, and an F1-score of 96.11\%, which represent lower {FNR} and {FPR} values than those achieved by other approaches. We further apply {AutoVAS} to nine open-source projects and detect eleven vulnerabilities, most of which are missed by the other approaches we experimented with. Notably, we discovered three zero-day vulnerabilities, two of which were patched after being informed by {AutoVAS}. The other vulnerability received the Common Vulnerabilities and Exposures ({CVE}) {ID} after being detected by {AutoVAS}.},
	pages = {102308},
	journaltitle = {Computers \& Security},
	author = {Jeon, Sanghoon and Kim, Huy Kang},
	date = {2021},
	keywords = {Static analysis, Cybersecurity, Data-driven security, Program slicing, Vulnerability detection, xno}
}

@article{diaz_static_2013,
	title = {Static analysis of source code security: Assessment of tools against {SAMATE} tests},
	volume = {55},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584913000384},
	doi = {https://doi.org/10.1016/j.infsof.2013.02.005},
	abstract = {Context Static analysis tools are used to discover security vulnerabilities in source code. They suffer from false negatives and false positives. A false positive is a reported vulnerability in a program that is not really a security problem. A false negative is a vulnerability in the code which is not detected by the tool. Objective The main goal of this article is to provide objective assessment results following a well-defined and repeatable methodology that analyzes the performance detecting security vulnerabilities of static analysis tools. The study compares the performance of nine tools ({CBMC}, K8-Insight, {PC}-lint, Prevent, Satabs, {SCA}, Goanna, Cx-enterprise, Codesonar), most of them commercials tools, having a different design. Method We executed the static analysis tools against {SAMATE} Reference Dataset test suites 45 and 46 for C language. One includes test cases with known vulnerabilities and the other one is designed with specific vulnerabilities fixed. Afterwards, the results are analyzed by using a set of well known metrics. Results Only {SCA} is designed to detect all vulnerabilities considered in {SAMATE}. None of the tools detect “cross-site scripting” vulnerabilities. The best results for F-measure metric are obtained by Prevent, {SCA} and K8-Insight. The average precision for analyzed tools is 0.7 and the average recall is 0.527. The differences between all tools are relevant, detecting different kinds of vulnerabilities. Conclusions The results provide empirical evidences that support popular propositions not objectively demonstrated until now. The methodology is repeatable and allows ranking strictly the analyzed static analysis tools, in terms of vulnerabilities coverage and effectiveness for detecting the highest number of vulnerabilities having few false positives. Its use can help practitioners to select appropriate tools for a security review process of code. We propose some recommendations for improving the reliability and usefulness of static analysis tools and the process of benchmarking.},
	pages = {1462--1476},
	number = {8},
	journaltitle = {Information and Software Technology},
	author = {Díaz, Gabriel and Bermejo, Juan Ramón},
	date = {2013},
	keywords = {Quality analysis and evaluation, Security development lifecycle, Security tools, Software/program verification, Vulnerability, xno}
}

@article{ghadhab_augmenting_2021,
	title = {Augmenting commit classification by using fine-grained source code changes and a pre-trained deep neural language model},
	volume = {135},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921000495},
	doi = {https://doi.org/10.1016/j.infsof.2021.106566},
	abstract = {Context: Analyzing software maintenance activities is very helpful in ensuring cost-effective evolution and development activities. The categorization of commits into maintenance tasks supports practitioners in making decisions about resource allocation and managing technical debt. Objective: In this paper, we propose to use a pre-trained language neural model, namely {BERT} (Bidirectional Encoder Representations from Transformers) for the classification of commits into three categories of maintenance tasks — corrective, perfective and adaptive. The proposed commit classification approach will help the classifier better understand the context of each word in the commit message. Methods: We built a balanced dataset of 1793 labeled commits that we collected from publicly available datasets. We used several popular code change distillers to extract fine-grained code changes that we have incorporated into our dataset as additional features to {BERT}’s word representation features. In our study, a deep neural network ({DNN}) classifier has been used as an additional layer to fine-tune the {BERT} model on the task of commit classification. Several models have been evaluated to come up with a deep analysis of the impact of code changes on the classification performance of each commit category. Results and conclusions: Experimental results have shown that the {DNN} model trained on {BERT}’s word representations and Fixminer code changes ({DNN}@{BERT}+Fix\_cc) provided the best performance and achieved 79.66\% accuracy and a macro-average f1 score of 0.8. Comparison with the state-of-the-art model that combines keywords and code changes ({RF}@{KW}+{CD}\_cc) has shown that our model achieved approximately 8\% improvement in accuracy. Results have also shown that a {DNN} model using only {BERT}’s word representation features achieved an improvement of 5\% in accuracy compared to the {RF}@{KW}+{CD}\_cc model.},
	pages = {106566},
	journaltitle = {Information and Software Technology},
	author = {Ghadhab, Lobna and Jenhani, Ilyes and Mkaouer, Mohamed Wiem and Messaoud, Montassar Ben},
	date = {2021},
	keywords = {Software maintenance, Commit classification, Code changes, Deep neural networks, Pre-trained neural language model, xno}
}

@article{yu_mutation-oriented_2013,
	title = {Mutation-oriented test data augmentation for {GUI} software fault localization},
	volume = {55},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S095058491300150X},
	doi = {https://doi.org/10.1016/j.infsof.2013.07.004},
	abstract = {Context Fault localization lies at the heart of program debugging and often proceeds by contrasting the statistics of program constructs executed by passing and failing test cases. A vital issue here is how to obtain these “suitable” test cases. Techniques presented in the literature mostly assume the existence of a large test suite a priori. However, developers often encounter situations where a failure occurs, but where no or no appropriate test suite is available for use to localize the fault. Objective This paper aims to alleviate this key limitation of traditional fault localization techniques for {GUI} software particularly, namely, it aims at enabling cost-effective fault localization process for {GUI} software in the described scenario. Method To address this scenario, we propose a mutation-oriented test data augmentation technique, which actually is directed by the “similarity” criterion in {GUI} software’s test case context towards the generation of test suite with excellent fault localization capabilities. More specifically, the technique mainly uses four proposed novel mutation operators to iteratively mutate some failing {GUI} test cases’ event sequences to derive new test cases potentially useful to localize the specific encountered fault. We then compare the fault localization performance of the test suite generated using this technique with that of an original provided large event-pair adequate test suite on some {GUI} applications. Results The results indicate that the proposed technique is capable of generating a test suite that has comparable, if not better, fault localization effectiveness to the event-pair adequate test suite, but it is much smaller and it is generated immediately once a failure is encountered by developers. Conclusion It is concluded that the proposed technique can truly enable quick-start cost-effective fault localization process under the investigated all-too-common scenario, greatly alleviating one key limitation of traditional fault localization techniques and prompting the test–diagnose–repair cycle.},
	pages = {2076--2098},
	number = {12},
	journaltitle = {Information and Software Technology},
	author = {Yu, Zhongxing and Bai, Chenggang and Cai, Kai-Yuan},
	date = {2013},
	keywords = {Fault localization, {GUI} software, Mutation operator, Test data augmentation, xno}
}

@article{neto_mults_2019,
	title = {{MULTS}: A multi-cloud fault-tolerant architecture to manage transient servers in cloud computing},
	volume = {101},
	issn = {1383-7621},
	url = {https://www.sciencedirect.com/science/article/pii/S1383762119304588},
	doi = {https://doi.org/10.1016/j.sysarc.2019.101651},
	abstract = {The large-scale utilization of cloud computing resources has led to the emergence of cloud environment reliability as an important issue. In addition, cloud providers are negotiating unreliable virtual machines as a result of exploring unused resources offering them as transient servers - a lower price virtual machine service with resource revocations without user intervention. To increase the availability of transient servers, we propose a multi-cloud fault-tolerant architecture to provide a resilient environment using a scenario-based optimal checkpoint in a scheme to guarantee running processes with reduced user costs. The architecture combines a heuristic to extract information from a case-based reasoning and a statistical model to predict failure events helping to refine fault tolerance parameters. As a result, a cloud environment with better levels of reliability and reduced execution time is provided. Extensive simulations show high levels of accuracy reaching up to 92\% survival prediction success rate and a gain of 74,58\% of execution time reduction for long running applications. The results are promising, indicating that the proposed architecture can prevent revocation failures under realistic working conditions.},
	pages = {101651},
	journaltitle = {Journal of Systems Architecture},
	author = {Neto, Jose Pergentino Araujo and Pianto, Donald M. and Ralha, Célia Ghedini},
	date = {2019},
	keywords = {Machine learning, Fault tolerance, Cloud computing, Checkpoint, Resilient architecture, Spot instance, Survival analysis, xno}
}

@article{zhao_empirical_2015,
	title = {An empirical analysis of package-modularization metrics: Implications for software fault-proneness},
	volume = {57},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584914002055},
	doi = {https://doi.org/10.1016/j.infsof.2014.09.006},
	abstract = {Context In a large object-oriented software system, packages play the role of modules which group related classes together to provide well-identified services to the rest of the system. In this context, it is widely believed that modularization has a large influence on the quality of packages. Recently, Sarkar, Kak, and Rama proposed a set of new metrics to characterize the modularization quality of packages from important perspectives such as inter-module call traffic, state access violations, fragile base-class design, programming to interface, and plugin pollution. These package-modularization metrics are quite different from traditional package-level metrics, which measure software quality mainly from size, extensibility, responsibility, independence, abstractness, and instability perspectives. As such, it is expected that these package-modularization metrics should be useful predictors for fault-proneness. However, little is currently known on their actual usefulness for fault-proneness prediction, especially compared with traditional package-level metrics. Objective In this paper, we examine the role of these new package-modularization metrics for determining software fault-proneness in object-oriented systems. Method We first use principal component analysis to analyze whether these new package-modularization metrics capture additional information compared with traditional package-level metrics. Second, we employ univariate prediction models to investigate how these new package-modularization metrics are related to fault-proneness. Finally, we build multivariate prediction models to examine the ability of these new package-modularization metrics for predicting fault-prone packages. Results Our results, based on six open-source object-oriented software systems, show that: (1) these new package-modularization metrics provide new and complementary views of software complexity compared with traditional package-level metrics; (2) most of these new package-modularization metrics have a significant association with fault-proneness in an expected direction; and (3) these new package-modularization metrics can substantially improve the effectiveness of fault-proneness prediction when used with traditional package-level metrics together. Conclusions The package-modularization metrics proposed by Sarkar, Kak, and Rama are useful for practitioners to develop quality software systems.},
	pages = {186--203},
	journaltitle = {Information and Software Technology},
	author = {Zhao, Yangyang and Yang, Yibiao and Lu, Hongmin and Zhou, Yuming and Song, Qinbao and Xu, Baowen},
	date = {2015},
	keywords = {Fault-proneness, Prediction, Metrics, Modularization, Object-oriented, Package, xno}
}

@article{yu_fault-based_2012,
	title = {Fault-based test suite prioritization for specification-based testing},
	volume = {54},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584911001947},
	doi = {https://doi.org/10.1016/j.infsof.2011.09.005},
	abstract = {Context Existing test suite prioritization techniques usually rely on code coverage information or historical execution data that serve as indicators for estimating the fault-detecting ability of test cases. Such indicators are primarily empirical in nature and not theoretically driven; hence, they do not necessarily provide sound estimates. Also, these techniques are not applicable when the source code is not available or when the software is tested for the first time. Objective We propose and develop the novel notion of fault-based prioritization of test cases which directly utilizes the theoretical knowledge of their fault-detecting ability and the relationships among the test cases and the faults in the prescribed fault model, based on which the test cases are generated. Method We demonstrate our approach of fault-based prioritization by applying it to the testing of the implementation of logical expressions against their specifications. We then validate our proposal by an empirical study that evaluates the effectiveness of prioritization techniques using two different metrics. Results A theoretically guided fault-based prioritization technique generally outperforms other techniques under study, as assessed by two different metrics. Our empirical results also show that the technique helps to reveal all target faults by executing only about 72\% of the prioritized test suite, thereby reducing the effort required in testing. Conclusions The fault-based prioritization approach is not only applicable to the instance empirically validated in this paper, but should also be adaptable to other fault-based testing strategies. We also envisage new research directions to be opened up by our work.},
	pages = {179--202},
	number = {2},
	journaltitle = {Information and Software Technology},
	author = {Yu, Yuen Tak and Lau, Man Fai},
	date = {2012},
	keywords = {Software testing, Fault class hierarchy, Fault-based prioritization, Fault-based testing, Specification-based testing, Test suite prioritization, xno}
}

@article{ford_portauthority_2021,
	title = {{PortAuthority}: Integrating energy efficiency analysis into cross-platform development cycles via dynamic program analysis},
	volume = {30},
	issn = {2210-5379},
	url = {https://www.sciencedirect.com/science/article/pii/S2210537921000238},
	doi = {https://doi.org/10.1016/j.suscom.2021.100530},
	abstract = {Source code improvements can be suggested or automatically applied from within an {IDE} augmenting the skills of a developer. In addition, compiler optimizations are readily available for a variety of languages and programming environments that continue to enhance a developer's code on the back end. Common optimizations include transformations that automatically improve the speed or lower the memory usage of an application. However, no equivalent options exist to tailor the compilation, linking or refactoring of a program for better energy efficiency. This paper fills the gap by proposing a methodology that can integrate energy efficiency analysis into software development cycles via dynamic program analysis. Our goal is to provide the same usability and increased code quality that are available for performance-oriented optimizations in the context of a development environment but for issues concerning power consumption. We explore using {PortAuthority} as an easy-to-use tool that can increase developer awareness of energy related improvements via both descriptive messages and indicators of severity. By analyzing the power efficiency of basic instructions at the binary level and building generalized rules for improving code's energy efficiency, our approach is language agnostic, cross-platform, and can be seamlessly integrated to popular {IDEs}. We present the integrated solution to the Visual Studio Code {IDE} and demonstrate its usage in several sample projects.},
	pages = {100530},
	journaltitle = {Sustainable Computing: Informatics and Systems},
	author = {Ford, Blake W. and Zong, Ziliang},
	date = {2021},
	keywords = {Dynamic program analysis, {IDE} integration, Power profiling, Software energy efficiency, Usability and portability, xno}
}

@article{mesquita_classification_2016,
	title = {Classification with reject option for software defect prediction},
	volume = {49},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494616303039},
	doi = {https://doi.org/10.1016/j.asoc.2016.06.023},
	abstract = {Context Software defect prediction ({SDP}) is an important task in software engineering. Along with estimating the number of defects remaining in software systems and discovering defect associations, classifying the defect-proneness of software modules plays an important role in software defect prediction. Several machine-learning methods have been applied to handle the defect-proneness of software modules as a classification problem. This type of “yes” or “no” decision is an important drawback in the decision-making process and if not precise may lead to misclassifications. To the best of our knowledge, existing approaches rely on fully automated module classification and do not provide a way to incorporate extra knowledge during the classification process. This knowledge can be helpful in avoiding misclassifications in cases where system modules cannot be classified in a reliable way. Objective We seek to develop a {SDP} method that (i) incorporates a reject option in the classifier to improve the reliability in the decision-making process; and (ii) makes it possible postpone the final decision related to rejected modules for an expert analysis or even for another classifier using extra domain knowledge. Method We develop a {SDP} method called {rejoELM} and its variant, {IrejoELM}. Both methods were built upon the weighted extreme learning machine ({ELM}) with reject option that makes it possible postpone the final decision of non-classified modules, the rejected ones, to another moment. While {rejoELM} aims to maximize the accuracy for a rejection rate, {IrejoELM} maximizes the F-measure. Hence, {IrejoELM} becomes an alternative for classification with reject option for imbalanced datasets. Results {rejoEM} and {IrejoELM} are tested on five datasets of source code metrics extracted from real world open-source software projects. Results indicate that {rejoELM} has an accuracy for several rejection rates that is comparable to some state-of-the-art classifiers with reject option. Although {IrejoELM} shows lower accuracies for several rejection rates, it clearly outperforms all other methods when the F-measure is used as a performance metric. Conclusion It is concluded that {rejoELM} is a valid alternative for classification with reject option problems when classes are nearly equally represented. On the other hand, {IrejoELM} is shown to be the best alternative for classification with reject option on imbalanced datasets. Since {SDP} problems are usually characterized as imbalanced learning problems, the use of {IrejoELM} is recommended.},
	pages = {1085--1093},
	journaltitle = {Applied Soft Computing},
	author = {Mesquita, Diego P. P. and Rocha, Lincoln S. and Gomes, João Paulo P. and Neto, Ajalmar R. Rocha},
	date = {2016},
	keywords = {Software defect prediction, Classification with reject option, Extreme learning machines, xno}
}

@article{xu_comprehensive_2021,
	title = {A comprehensive comparative study of clustering-based unsupervised defect prediction models},
	volume = {172},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220302521},
	doi = {https://doi.org/10.1016/j.jss.2020.110862},
	abstract = {Software defect prediction recommends the most defect-prone software modules for optimization of the test resource allocation. The limitation of the extensively-studied supervised defect prediction methods is that they require labeled software modules which are not always available. An alternative solution is to apply clustering-based unsupervised models to the unlabeled defect data, called Clustering-based Unsupervised Defect Prediction ({CUDP}). However, there are few studies to explore the impacts of clustering-based models on defect prediction performance. In this work, we performed a large-scale empirical study on 40 unsupervised models to fill this gap. We chose an open-source dataset including 27 project versions with 3 types of features. The experimental results show that (1) different clustering-based models have significant performance differences and the performance of models in the instance-violation-score-based clustering family is obviously superior to that of models in hierarchy-based, density-based, grid-based, sequence-based, and hybrid-based clustering families; (2) the models in the instance-violation-score-based clustering family achieves competitive performance compared with typical supervised models; (3) the impacts of feature types on the performance of the models are related to the indicators used; and (4)the clustering-based unsupervised models do not always achieve better performance on defect data with the combination of the 3 types of features.},
	pages = {110862},
	journaltitle = {Journal of Systems and Software},
	author = {Xu, Zhou and Li, Li and Yan, Meng and Liu, Jin and Luo, Xiapu and Grundy, John and Zhang, Yifeng and Zhang, Xiaohong},
	date = {2021},
	keywords = {Empirical study, Clustering-based unsupervised models, Data analytics for defect prediction, xno}
}

@article{ferenc_automatically_2020,
	title = {An automatically created novel bug dataset and its validation in bug prediction},
	volume = {169},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301436},
	doi = {https://doi.org/10.1016/j.jss.2020.110691},
	abstract = {Bugs are inescapable during software development due to frequent code changes, tight deadlines, etc.; therefore, it is important to have tools to find these errors. One way of performing bug identification is to analyze the characteristics of buggy source code elements from the past and predict the present ones based on the same characteristics, using e.g. machine learning models. To support model building tasks, code elements and their characteristics are collected in so-called bug datasets which serve as the input for learning. We present the {BugHunter} Dataset: a novel kind of automatically constructed and freely available bug dataset containing code elements (files, classes, methods) with a wide set of code metrics and bug information. Other available bug datasets follow the traditional approach of gathering the characteristics of all source code elements (buggy and non-buggy) at only one or more pre-selected release versions of the code. Our approach, on the other hand, captures the buggy and the fixed states of the same source code elements from the narrowest timeframe we can identify for a bug’s presence, regardless of release versions. To show the usefulness of the new dataset, we built and evaluated bug prediction models and achieved F-measure values over 0.74.},
	pages = {110691},
	journaltitle = {Journal of Systems and Software},
	author = {Ferenc, Rudolf and Gyimesi, Péter and Gyimesi, Gábor and Tóth, Zoltán and Gyimóthy, Tibor},
	date = {2020},
	keywords = {Machine learning, Static code analysis, Code metrics, Bug dataset, Bug prediction, {GitHub}, xno, xdataset}
}

@article{xu_imbalanced_2020,
	title = {Imbalanced metric learning for crashing fault residence prediction},
	volume = {170},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301837},
	doi = {https://doi.org/10.1016/j.jss.2020.110763},
	abstract = {As the software crash usually does great harm, locating the fault causing the crash (i.e., the crashing fault) has always been a hot research topic. As the stack trace in the crash reports usually contains abundant information related the crash, it is helpful to find the root cause of the crash. Recently, researchers extracted features of the crash, then constructed the classification model on the features to predict whether the crashing fault resides in the stack trace. This process can accelerate the debugging process and save debugging efforts. In this work, we apply a state-of-the-art metric learning method called {IML} to crash data for crashing fault residence prediction. This method uses Mahalanobis distance based metric learning to learn high-quality feature representation by reducing the distance between crash instances with the same label and increasing the distance between crash instances with different labels. In addition, this method designs a new loss function that includes four types of losses with different weights to cope with the class imbalanced issue of crash data. The experiments on seven open source software projects show that our {IML} method performs significantly better than nine sampling based and five ensemble based imbalanced learning methods in terms of three performance indicators.},
	pages = {110763},
	journaltitle = {Journal of Systems and Software},
	author = {Xu, Zhou and Zhao, Kunsong and Yan, Meng and Yuan, Peipei and Xu, Ling and Lei, Yan and Zhang, Xiaohong},
	date = {2020},
	keywords = {Stack trace, Class imbalanced learning, Crashing fault residence prediction, Metric learning, xno}
}

@article{alsmadi_evaluating_2011,
	title = {Evaluating the change of software fault behavior with dataset attributes based on categorical correlation},
	volume = {42},
	issn = {0965-9978},
	url = {https://www.sciencedirect.com/science/article/pii/S096599781100038X},
	doi = {https://doi.org/10.1016/j.advengsoft.2011.03.010},
	abstract = {Utilization of data mining in software engineering has been the subject of several research papers. Majority of subjects of those paper were in making use of historical data for decision making activities such as cost estimation and product or project attributes prediction and estimation. The ability to predict software fault modules and the ability to correlate relations between faulty modules and product attributes using statistics is the subject of this paper. Correlations and relations between the attributes and the categorical variable or the class are studied through generating a pool of records from each dataset and then select two samples every time from the dataset and compare them. The correlation between the two selected records is studied in terms of changing from faulty to non-faulty or the opposite for the module defect attribute and the value change between the two records in each evaluated attribute (e.g. equal, larger or smaller). The goal was to study if there are certain attributes that are consistently affecting changing the state of the module from faulty to none, or the opposite. Results indicated that such technique can be very useful in studying the correlations between each attribute and the defect status attribute. Another prediction algorithm is developed based on statistics of the module and the overall dataset. The algorithm gave each attribute true class and faulty class predictions. We found that dividing prediction capability for each attribute into those two (i.e. correct and faulty module prediction) facilitate understanding the impact of attribute values on the class and hence improve the overall prediction relative to previous studies and data mining algorithms. Results were evaluated and compared with other algorithms and previous studies. {ROC} metrics were used to evaluate the performance of the developed metrics. Results from those metrics showed that accuracy or prediction performance calculated traditionally using accurately predicted records divided by the total number of records in the dataset does not necessarily give the best indicator of a good metric or algorithm predictability. Those predictions may give wrong implication if other metrics are not considered with them. The {ROC} metrics were able to show some other important aspects of performance or accuracy.},
	pages = {535--546},
	number = {8},
	journaltitle = {Advances in Engineering Software},
	author = {Alsmadi, Izzat and Najadat, Hassan},
	date = {2011},
	keywords = {Data mining, Software quality, Clustering, Prediction algorithms, Correlation, Fault prone modules, Software mining, xno}
}

@article{rustambekovich_challenging_2017,
	title = {Challenging the ways to determine the faults in software: Technique based on associative interconnections},
	volume = {120},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050917325024},
	doi = {https://doi.org/10.1016/j.procs.2017.11.290},
	abstract = {The dynamic world of software development brings into arena the issues to deliver the products in the specified time with the fulfilled requirements, wherein the prevention or defining of the faults are among tackling and actual. In this paper the conceptual framework and approach for predicting the faults and errors in software systems is proposed with introducing associative interconnections implied in software systems as prerequisites for better performance assessment and software problem management. This framework, as it is denoted in paper, can be smoothly interrelated with concepts of Data Mining in software fault detection, and intelligent support of decision making.},
	pages = {641--648},
	journaltitle = {Procedia Computer Science},
	author = {Rustambekovich, Yusupbekov Nodirbek and Gulyamov, Sh M. and Usmanova, N. B. and Mirzaev, D. A.},
	date = {2017},
	keywords = {Software reliability, associative rules, software reliability assessment, xno}
}

@article{qiao_deep_2020,
	title = {Deep learning based software defect prediction},
	volume = {385},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231219316698},
	doi = {https://doi.org/10.1016/j.neucom.2019.11.067},
	abstract = {Software systems have become larger and more complex than ever. Such characteristics make it very challengeable to prevent software defects. Therefore, automatically predicting the number of defects in software modules is necessary and may help developers efficiently to allocate limited resources. Various approaches have been proposed to identify and fix such defects at minimal cost. However, the performance of these approaches require significant improvement. Therefore, in this paper, we propose a novel approach that leverages deep learning techniques to predict the number of defects in software systems. First, we preprocess a publicly available dataset, including log transformation and data normalization. Second, we perform data modeling to prepare the data input for the deep learning model. Third, we pass the modeled data to a specially designed deep neural network-based model to predict the number of defects. We also evaluate the proposed approach on two well-known datasets. The evaluation results illustrate that the proposed approach is accurate and can improve upon the state-of-the-art approaches. On average, the proposed method significantly reduces the mean square error by more than 14\% and increases the squared correlation coefficient by more than 8\%.},
	pages = {100--110},
	journaltitle = {Neurocomputing},
	author = {Qiao, Lei and Li, Xuesong and Umer, Qasim and Guo, Ping},
	date = {2020},
	keywords = {Software metrics, Software quality, Software defect prediction, Deep learning, Robustness evaluation, xno}
}

@article{kumar_effective_2018,
	title = {Effective fault prediction model developed using Least Square Support Vector Machine ({LSSVM})},
	volume = {137},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217300717},
	doi = {https://doi.org/10.1016/j.jss.2017.04.016},
	abstract = {Software developers and project teams spend considerable amount of time in identifying and fixing faults reported by testers and users. Predicting defects and identifying regions in the source code containing faults before it is discovered or invoked by users can be valuable in terms of saving maintenance resources, user satisfaction and preventing major system failures post deployment. Fault prediction can also improve the effectiveness of software quality assurance activities by guiding the test team to focus efforts on fault prone components. The work presented in this paper involves building an effective fault prediction tool by identifying and investigating the predictive power of several well-known and widely used software metrics for fault prediction. We apply ten different feature selection techniques to choose the best set of metrics from a set of twenty source code metrics. We build the fault prediction model using Least Squares Support Vector Machine ({LSSVM}) learning method associated with linear, polynomial and radial basis function kernel functions. We perform experiments on 30 Open Source Java projects. Experimental results reveals that our prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low- 52.139\%, median- 46.206\%, and high- 32.080\%).},
	pages = {686--712},
	journaltitle = {Journal of Systems and Software},
	author = {Kumar, Lov and Sripada, Sai Krishna and Sureka, Ashish and Rath, Santanu Ku},
	date = {2018},
	keywords = {Fault, Feature selection techniques, Object-oriented software, {CK} metrics, Cost analysis, Least Squares Support Vector Machine ({LSSVM}), xno}
}

@article{taneja_novel_2020,
	title = {A Novel technique for test case minimization in object oriented testing},
	volume = {167},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050920307407},
	doi = {https://doi.org/10.1016/j.procs.2020.03.274},
	abstract = {Software maintenance is the costliest phase of software life cycle and it consumes almost 70 percent of resources of development process. Software testing involves the examining the built software with the intension to find the defects in it. Exhaustive testing of the software for all possible test cases is not feasible as may take infinitely large amount of time and may consume large number of other resources. Researchers in the field of the software testing are exploring the different possibilities to reduce the required number of test cases to test given software. In case of an object oriented ({OO}) software, the complexities like inheritance, coupling and cohesion, make the software modules more prone to the faults. This problem gets augmented in case of very large software systems. Many researchers have solved the problem of test case minimization from the different perspectives like requirements coverage; statement coverage and risk coverage. But negligible research has been done of the basis of security metrics coverage. In this paper, a technique has been presented for minimization of test cases for the {OO} systems. The research reported in the paper has considered security as a perspective for test cases evaluation and minimization. Publically available data sets pertaining to open source software Camel 1.6.1 have been used for the evaluation of proposed methodology. Linear Regression ({LR}) model for the bugs present in the data and various object oriented metrics for security have been developed. The proposed model dissects the given metrics sets into effective and non-effective metrics. Effective metrics are then utilized for giving weights to the test cases, further with the help of weights obtained the test suite is minimized. The performance results of proposed approach are encouraging.},
	pages = {2221--2228},
	journaltitle = {Procedia Computer Science},
	author = {Taneja, Divya and Singh, Rajvir and Singh, Ajmer and Malik, Himanshu},
	date = {2020},
	keywords = {machine learning, Object oriented metrics, object oriented testing, Test Case Minimization, xno}
}

@article{sun_collaborative_2020,
	title = {Collaborative filtering based recommendation of sampling methods for software defect prediction},
	volume = {90},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494620301034},
	doi = {https://doi.org/10.1016/j.asoc.2020.106163},
	abstract = {The performance of software defect prediction have been hindered by the imbalanced nature of software defect data. Fortunately, a variety of sampling methods have been employed to improve defect prediction performance. However, researchers and practitioners are usually burdened with selecting the optimal sampling methods for the defect data at hand. In practice, no sampling method has been found to perform best in theory and practice. Therefore it is necessary and valuable to study how to select applicable sampling methods according to the current data characteristics. This paper presents a collaborative filtering based sampling methods recommendation algorithm ({CFSR}) for automatically recommending applicable sampling methods for the new defect data. {CFSR} firstly ranks existing sampling methods with historical defect data, and then mines the data similarity between the new and historical defect data with meta-features. Finally, all the information of ranked sampling methods and data similarity are combined to build a recommendation network, with which the user-based collaborative filtering algorithm is employed to recommend appropriate sampling methods for the new defect data. A thorough experiment with five classification algorithms, two prediction performance, five recommendation performance and 12 popular sampling methods was conducted over 20 imbalanced software defect data. The experimental results firstly demonstrate the importance and necessity of present study, and then show that the proposed {CFSR} method is feasible and effective.},
	pages = {106163},
	journaltitle = {Applied Soft Computing},
	author = {Sun, Zhongbin and Zhang, Jingqi and Sun, Heli and Zhu, Xiaoyan},
	date = {2020},
	keywords = {Defect prediction, Recommendation, Sampling methods, xno}
}

@article{couto_predicting_2014,
	title = {Predicting software defects with causality tests},
	volume = {93},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121214000351},
	doi = {https://doi.org/10.1016/j.jss.2014.01.033},
	abstract = {In this paper, we propose a defect prediction approach centered on more robust evidences towards causality between source code metrics (as predictors) and the occurrence of defects. More specifically, we rely on the Granger causality test to evaluate whether past variations in source code metrics values can be used to forecast changes in time series of defects. Our approach triggers alarms when changes made to the source code of a target system have a high chance of producing defects. We evaluated our approach in several life stages of four Java-based systems. We reached an average precision greater than 50\% in three out of the four systems we evaluated. Moreover, by comparing our approach with baselines that are not based on causality tests, it achieved a better precision.},
	pages = {24--41},
	journaltitle = {Journal of Systems and Software},
	author = {Couto, Cesar and Pires, Pedro and Valente, Marco Tulio and Bigonha, Roberto S. and Anquetil, Nicolas},
	date = {2014},
	keywords = {Defect prediction, Causality, Granger test, xno}
}

@article{morrison_mapping_2018,
	title = {Mapping the field of software life cycle security metrics},
	volume = {102},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S095058491830096X},
	doi = {https://doi.org/10.1016/j.infsof.2018.05.011},
	abstract = {Context: Practitioners establish a piece of software’s security objectives during the software development process. To support control and assessment, practitioners and researchers seek to measure security risks and mitigations during software development projects. Metrics provide one means for assessing whether software security objectives have been achieved. A catalog of security metrics for the software development life cycle could assist practitioners in choosing appropriate metrics, and researchers in identifying opportunities for refinement of security measurement. Objective: The goal of this research is to support practitioner and researcher use of security measurement in the software life cycle by cataloging security metrics presented in the literature, their validation, and the subjects they measure. Method: We conducted a systematic mapping study, beginning with 4818 papers and narrowing down to 71 papers reporting on 324 unique security metrics. For each metric, we identified the subject being measured, how the metric has been validated, and how the metric is used. We categorized the metrics, and give examples of metrics for each category. Results: In our data, 85\% of security metrics have been proposed and evaluated solely by their authors, leaving room for replication and confirmation through field studies. Approximately 60\% of the metrics have been empirically evaluated, by their authors or by others. The available metrics are weighted heavily toward the implementation and operations phases, with relatively few metrics for requirements, design, and testing phases of software development. Some artifacts and processes remain unmeasured. Measured by phase, Testing received the least attention, with 1.5\% of the metrics. Conclusions: At present, the primary application of security metrics to the software development life cycle in the literature is to study the relationship between properties of source code and reported vulnerabilities. The most-cited and most used metric, vulnerability count, has multiple definitions and operationalizations. We suggest that researchers must check vulnerability count definitions when making comparisons between papers. In addition to refining vulnerability measurement, we see research opportunities for greater attention to metrics for the requirement, design, and testing phases of development. We conjecture from our data that the field of software life cycle security metrics has yet to converge on an accepted set of metrics.},
	pages = {146--159},
	journaltitle = {Information and Software Technology},
	author = {Morrison, Patrick and Moye, David and Pandita, Rahul and Williams, Laurie},
	date = {2018},
	keywords = {Measurement, Metrics, Security, xno}
}

@article{lopes_automating_2020,
	title = {Automating orthogonal defect classification using machine learning algorithms},
	volume = {102},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X19308283},
	doi = {https://doi.org/10.1016/j.future.2019.09.009},
	abstract = {Software systems are increasingly being used in business or mission critical scenarios, where the presence of certain types of software defects, i.e., bugs, may result in catastrophic consequences (e.g., financial losses or even the loss of human lives). To deploy systems in which we can rely on, it is vital to understand the types of defects that tend to affect such systems. This allows developers to take proper action, such as adapting the development process or redirecting testing efforts (e.g., using a certain set of testing techniques, or focusing on certain parts of the system). Orthogonal Defect Classification ({ODC}) has emerged as a popular method for classifying software defects, but it requires one or more experts to categorize each defect in a quite complex and time-consuming process. In this paper, we evaluate the use of machine learning algorithms (k-Nearest Neighbors, Support Vector Machines, Naïve Bayes, Nearest Centroid, Random Forest and Recurrent Neural Networks) for automatic classification of software defects using {ODC}, based on unstructured textual bug reports. Experimental results reveal the difficulties in automatically classifying certain {ODC} attributes solely using reports, but also suggest that the overall classification accuracy may be improved in most of the cases, if larger datasets are used.},
	pages = {932--947},
	journaltitle = {Future Generation Computer Systems},
	author = {Lopes, Fábio and Agnelo, João and Teixeira, César A. and Laranjeiro, Nuno and Bernardino, Jorge},
	date = {2020},
	keywords = {Software defects, Machine learning, Bug reports, Orthogonal defect classification, Text classification, xno}
}

@article{sung_mutant_2011,
	title = {Mutant generation for embedded systems using kernel-based software and hardware fault simulation},
	volume = {53},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584911000863},
	doi = {https://doi.org/10.1016/j.infsof.2011.03.010},
	abstract = {Context Mutation testing is a fault-injection-based technique to help testers generate test cases for detecting specific and predetermined types of faults. Objective Before mutation testing can be effectively applied to embedded systems, traditional mutation testing needs to be modified. To inject a fault into an embedded system without causing any system failure or hardware damage is a challenging task as it requires some knowledge of the underlying layers such as the kernel and the corresponding hardware. Method We propose a set of mutation operators for embedded systems using kernel-based software and hardware fault simulation. These operators are designed for software developers so that they can use the mutation technique to test the entire system after the software is integrated with the kernel and hardware devices. Results A case study on a programmable logic controller for a digital reactor protection system in a nuclear power plant is conducted. Our results suggest that the proposed mutation operators are useful for fault-injection and this is evidenced by the fact that faults not injected by us were discovered in the subject software as a result of the case study. Conclusion We conclude that our mutation operators are useful for integration testing of an embedded system.},
	pages = {1153--1164},
	number = {10},
	journaltitle = {Information and Software Technology},
	author = {Sung, Ahyoung and Choi, Byoungju and Wong, W. Eric and Debroy, Vidroha},
	date = {2011},
	keywords = {Embedded systems, Integration testing, Fault injection, Mutation operators, xno}
}

@article{friedrich_understanding_2020,
	title = {Understanding strategy differences in a fault-finding task},
	volume = {59},
	issn = {1389-0417},
	url = {https://www.sciencedirect.com/science/article/pii/S1389041719304838},
	doi = {https://doi.org/10.1016/j.cogsys.2019.09.017},
	abstract = {This article examines strategy choices for how people find faults in a simple device by using models of several strategies and new data. Diag, a model solving this task, used a single strategy that predicted the behavior of most participants in a previous study with remarkable accuracy. This article explores additional strategies used in this reasoning task that arise when less directive instructions are provided. Based on our observations, five new strategies for the task were identified and described by being modeled. These different strategies, realized in different models, predict the speed of solution while the participant is learning the task, and were validated by comparing their predictions to the observations (r2 = .27 to .90). The results suggest that participants not only created different strategies for this simple fault-finding task but that some also, with practice, shifted between strategies. This research provides insights into how strategies are an important aspect of the variability in learning, illustrates the transfer of learning on a problem-by-problem level, and shows that the noisiness that most learning curves show can arise from differential transfer between problems.},
	pages = {133--150},
	journaltitle = {Cognitive Systems Research},
	author = {Friedrich, Maik B. and Ritter, Frank E.},
	date = {2020},
	keywords = {xno}
}

@article{boucher_software_2018,
	title = {Software metrics thresholds calculation techniques to predict fault-proneness: An empirical comparison},
	volume = {96},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584916303135},
	doi = {https://doi.org/10.1016/j.infsof.2017.11.005},
	abstract = {Context: Nowadays, fault-proneness prediction is an important field of software engineering. It can be used by developers and testers to prioritize tests. This would allow a better allocation of resources, reducing testing time and costs, and improving the effectiveness of software testing. Non-supervised fault-proneness prediction models, especially thresholds-based models, can easily be automated and give valuable insights to developers and testers on the classification performed. Objective: In this paper, we investigated three thresholds calculation techniques that can be used for fault-proneness prediction: {ROC} Curves, {VARL} (Value of an Acceptable Risk Level) and Alves rankings. We compared the performance of these techniques with the performance of four machine learning and two clustering based models. Method: Threshold values were calculated on a total of twelve different public datasets: eleven from the {PROMISE} Repository and another based on the Eclipse project. Thresholds-based models were then constructed using each thresholds calculation technique investigated. For comparison, results were also computed for supervised machine learning and clustering based models. Inter-dataset experimentation between different systems and versions of a same system was performed. Results: Results show that {ROC} Curves is the best performing method among the three thresholds calculation methods investigated, closely followed by Alves Rankings. {VARL} method didn’t give valuable results for most of the datasets investigated and was easily outperformed by the two other methods. Results also show that thresholds-based models using {ROC} Curves outperformed machine learning and clustering based models. Conclusion: The best of the three thresholds calculation techniques for fault-proneness prediction is {ROC} Curves, but Alves Rankings is a good choice too. In fact, the advantage of Alves Rankings over {ROC} Curves technique is that it is completely unsupervised and can therefore give pertinent threshold values when fault data is not available.},
	pages = {38--67},
	journaltitle = {Information and Software Technology},
	author = {Boucher, Alexandre and Badri, Mourad},
	date = {2018},
	keywords = {Machine learning, Fault-proneness prediction, Code quality, Clustering, Object-oriented metrics, Class-level metrics, Cross-validation, Faults, Metrics thresholds, Object-oriented programming, xno}
}

@article{cao_bgnn4vd_2021,
	title = {{BGNN}4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection},
	volume = {136},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921000586},
	doi = {https://doi.org/10.1016/j.infsof.2021.106576},
	abstract = {Context: Previous studies have shown that existing deep learning-based approaches can significantly improve the performance of vulnerability detection. They represent code in various forms and mine vulnerability features with deep learning models. However, the differences of code representation forms and deep learning models make various approaches still have some limitations. In practice, their false-positive rate ({FPR}) and false-negative rate ({FNR}) are still high. Objective: To address the limitations of existing deep learning-based vulnerability detection approaches, we propose {BGNN}4VD (Bidirectional Graph Neural Network for Vulnerability Detection), a vulnerability detection approach by constructing a Bidirectional Graph Neural-Network ({BGNN}). Method: In Phase 1, we extract the syntax and semantic information of source code through abstract syntax tree ({AST}), control flow graph ({CFG}), and data flow graph ({DFG}). Then in Phase 2, we use vectorized source code as input to Bidirectional Graph Neural-Network ({BGNN}). In Phase 3, we learn the different features between vulnerable code and non-vulnerable code by introducing backward edges on the basis of traditional Graph Neural-Network ({GNN}). Finally in Phase 4, a Convolutional Neural-Network ({CNN}) is used to further extract features and detect vulnerabilities through a classifier. Results: We evaluate {BGNN}4VD on four popular C/C++ projects from {NVD} and {GitHub}, and compare it with four state-of-the-art (Flawfinder, {RATS}, {SySeVR}, and {VUDDY}) vulnerab ility detection approaches. Experiment results show that, when compared these baselines, {BGNN}4VD achieves 4.9\%, 11.0\%, and 8.4\% improvement in F1-measure, accuracy and precision, respectively. Conclusion: The proposed {BGNN}4VD achieves a higher precision and accuracy than the state-of-the-art methods. In addition, when applied on the latest vulnerabilities reported by {CVE}, {BGNN}4VD can still achieve a precision at 45.1\%, which demonstrates the feasibility of {BGNN}4VD in practical application.},
	pages = {106576},
	journaltitle = {Information and Software Technology},
	author = {Cao, Sicong and Sun, Xiaobing and Bo, Lili and Wei, Ying and Li, Bin},
	date = {2021},
	keywords = {Vulnerability detection, Bidirectional Graph Neural-Network, Code representation, xno}
}

@article{arisholm_systematic_2010,
	title = {A systematic and comprehensive investigation of methods to build and evaluate fault prediction models},
	volume = {83},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121209001605},
	doi = {https://doi.org/10.1016/j.jss.2009.06.055},
	abstract = {This paper describes a study performed in an industrial setting that attempts to build predictive models to identify parts of a Java system with a high fault probability. The system under consideration is constantly evolving as several releases a year are shipped to customers. Developers usually have limited resources for their testing and would like to devote extra resources to faulty system parts. The main research focus of this paper is to systematically assess three aspects on how to build and evaluate fault-proneness models in the context of this large Java legacy system development project: (1) compare many data mining and machine learning techniques to build fault-proneness models, (2) assess the impact of using different metric sets such as source code structural measures and change/fault history (process measures), and (3) compare several alternative ways of assessing the performance of the models, in terms of (i) confusion matrix criteria such as accuracy and precision/recall, (ii) ranking ability, using the receiver operating characteristic area ({ROC}), and (iii) our proposed cost-effectiveness measure ({CE}). The results of the study indicate that the choice of fault-proneness modeling technique has limited impact on the resulting classification accuracy or cost-effectiveness. There is however large differences between the individual metric sets in terms of cost-effectiveness, and although the process measures are among the most expensive ones to collect, including them as candidate measures significantly improves the prediction models compared with models that only include structural measures and/or their deltas between releases – both in terms of {ROC} area and in terms of {CE}. Further, we observe that what is considered the best model is highly dependent on the criteria that are used to evaluate and compare the models. And the regular confusion matrix criteria, although popular, are not clearly related to the problem at hand, namely the cost-effectiveness of using fault-proneness prediction models to focus verification efforts to deliver software with less faults at less cost.},
	pages = {2--17},
	number = {1},
	journaltitle = {Journal of Systems and Software},
	author = {Arisholm, Erik and Briand, Lionel C. and Johannessen, Eivind B.},
	date = {2010},
	keywords = {Verification, Cost-effectiveness, Fault prediction models, xno}
}

@article{nunez-varela_dynamic_2020,
	title = {Dynamic creation of source code models for the extraction of code metrics data through grammar querying},
	volume = {196},
	issn = {0167-6423},
	url = {https://www.sciencedirect.com/science/article/pii/S0167642320300903},
	doi = {https://doi.org/10.1016/j.scico.2020.102480},
	abstract = {Source code metrics extraction is a complex task that has to be done automatically given the current size of software. They are extracted using software metric tools and more generic extraction mechanisms. These mechanisms usually work by querying a source code representation model. These models are static, and the information that can be obtained from them is limited. In this work an extraction methodology is presented in which the model is created every time certain information is needed. This is accomplished by querying the language context-free grammar, and from the information obtained by the query, a dynamic model is created. Current extraction mechanisms work by querying a model, while the proposed methodology queries the grammar directly, thus the model is created afterwards from the query result, and contains all the needed information. A metrics tool is created based on the proposed methodology, and in order to prove the correct functioning of extracting the desired information from the source code, not as already predefined as in current tools, several metrics are extracted as defined by four existing metrics tools. Querying the language grammar allows access to all available data in the source code, regardless of the programming language and paradigm.},
	pages = {102480},
	journaltitle = {Science of Computer Programming},
	author = {Nuñez-Varela, Alberto S. and Pérez-Gonzalez, Héctor G. and Martínez-Perez, Francisco E. and Soubervielle-Montalvo, Carlos and Perez-Cham, Oscar E.},
	date = {2020},
	keywords = {Source code metrics, Metrics extraction, Software metrics tool, xno}
}

@article{mi_improving_2018,
	title = {Improving code readability classification using convolutional neural networks},
	volume = {104},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918301496},
	doi = {https://doi.org/10.1016/j.infsof.2018.07.006},
	abstract = {Context Code readability classification (which refers to classification of a piece of source code as either readable or unreadable) has attracted increasing concern in academia and industry. To construct accurate classification models, previous studies depended mainly upon handcrafted features. However, the manual feature engineering process is usually labor-intensive and can capture only partial information about the source code, which is likely to limit the model performance. Objective To improve code readability classification, we propose the use of Convolutional Neural Networks ({ConvNets}). Method We first introduce a representation strategy (with different granularities) to transform source codes into integer matrices as the input to {ConvNets}. We then propose {DeepCRM}, a deep learning-based model for code readability classification. {DeepCRM} consists of three separate {ConvNets} with identical architectures that are trained on data preprocessed in different ways. We evaluate our approach against five state-of-the-art code readability models. Results The experimental results show that {DeepCRM} can outperform previous approaches. The improvement in accuracy ranges from 2.4\% to 17.2\%. Conclusions By eliminating the need for manual feature engineering, {DeepCRM} provides a relatively improved performance, confirming the efficacy of deep learning techniques in the task of code readability classification.},
	pages = {60--71},
	journaltitle = {Information and Software Technology},
	author = {Mi, Qing and Keung, Jacky and Xiao, Yan and Mensah, Solomon and Gao, Yujin},
	date = {2018},
	keywords = {Open source software, Program comprehension, Deep learning, Empirical software engineering, Code readability, Convolutional Neural Network, xno}
}

@article{xiao_albfl_2021,
	title = {{ALBFL}: A novel neural ranking model for software fault localization via combining static and dynamic features},
	volume = {139},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921001166},
	doi = {https://doi.org/10.1016/j.infsof.2021.106653},
	abstract = {Context Automatic software fault localization serves as a significant purpose in helping developers solve bugs efficiently. Existing approaches for software fault localization can be categorized into static methods and dynamic ones, which have improved the fault locating ability greatly by analyzing static features from the source code or tracking dynamic behaviors during the runtime respectively. However, the accuracy of fault localization is still unsatisfactory. Objective To enhance the capability of detecting software faults with the statement granularity, this paper puts forward {ALBFL}, a novel neural ranking model that combines the static and dynamic features, which obtains excellent fault localization accuracy. Firstly, {ALBFL} learns the semantic features of the source code by a transformer encoder. Then, it exploits a self-attention layer to integrate those static features and dynamic features. Finally, those integrated features are fed into a {LambdaRank} model, which can list the suspicious statements in descending order by their ranked scores. Method The experiments are conducted on an authoritative dataset (i.e., Defect4J), which includes 5 open-source projects, 357 faulty programs in total. We evaluate the effectiveness of {ALBFL}, effectiveness of combining features, effectiveness of model components and aggregation on method level. Result The results reflect that {ALBFL} identifies triple more faulty statements than 11 traditional {SBFL} methods and outperforms 2 state-of-the-art approaches by on average 14\% on ranking faults in the first position. Conclusions To improve the precision of automatic software fault localization, {ALBFL} combines neural network ranking model equipped with the self-attention layer and the transformer encoder, which can take full use of various techniques to judge whether a code statement is fault-inducing or not. Moreover, the joint architecture of {ALBFL} is capable of training the integration of these features under various strategies so as to improve accuracy further. In the future, we plan to exploit more features so as to improve our method's efficiency and accuracy.},
	pages = {106653},
	journaltitle = {Information and Software Technology},
	author = {Xiao, Xi and Pan, Yuqing and Zhang, Bin and Hu, Guangwu and Li, Qing and Lu, Runiu},
	date = {2021},
	keywords = {Software quality, Fault localization, Attention mechanism, Learning to rank, xno}
}

@article{shi_pathpair2vec_2020,
	title = {{PathPair}2Vec: An {AST} path pair-based code representation method for defect prediction},
	volume = {59},
	issn = {2590-1184},
	url = {https://www.sciencedirect.com/science/article/pii/S2590118420300393},
	doi = {https://doi.org/10.1016/j.cola.2020.100979},
	abstract = {Software project defect prediction ({SDP}) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new {AST} path pair-based source code representation method ({PathPair}2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the {PROMISE} dataset show that our method improves the F1 score by 17.88\% over the state-of-the-art {SDP} method, and the {AST} path pair-based source code representation can better identify the defect features of the source code.},
	pages = {100979},
	journaltitle = {Journal of Computer Languages},
	author = {Shi, Ke and Lu, Yang and Chang, Jingfei and Wei, Zhen},
	date = {2020},
	keywords = {Defect prediction, Deep learning, {AST} path, Representation learning, xno}
}

@article{ramirez-mora_descriptions_2020,
	title = {Descriptions of issues and comments for predicting issue success in software projects},
	volume = {168},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301242},
	doi = {https://doi.org/10.1016/j.jss.2020.110663},
	abstract = {Software development tasks must be performed successfully to achieve software quality and customer satisfaction. Knowing whether software tasks are likely to fail is essential to ensure the success of software projects. Issue Tracking Systems store information of software tasks (issues) and comments, which can be useful to predict issue success; however; almost no research on this topic exists. This work studies the usefulness of textual descriptions of issues and comments for predicting whether issues will be resolved successfully or not. Issues and comments of 588 software projects were extracted from four popular Issue Tracking Systems. Seven machine learning classifiers were trained on 30k issues and more than 120k comments, and more than 6000 experiments were performed to predict the success of three types of issues: bugs, improvements and new features. The results provided evidence that descriptions of issues and comments are useful for predicting issue success with more than 85\% of accuracy and precision, and that the predictions of issue success vary over time. Words related to software development were particularly relevant for predicting issue success. Other communication aspects and their relationship to the success of software projects must be researched in detail using data from software tools.},
	pages = {110663},
	journaltitle = {Journal of Systems and Software},
	author = {Ramírez-Mora, Sandra L. and Oktaba, Hanna and Gómez-Adorno, Helena},
	date = {2020},
	keywords = {Machine learning, Software project, Issue success, Issue Tracking System, Software development, xno}
}

@article{afric_repd_2020,
	title = {{REPD}: Source code defect prediction as anomaly detection},
	volume = {168},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301138},
	doi = {https://doi.org/10.1016/j.jss.2020.110641},
	abstract = {In this paper, we present a novel approach for within-project source code defect prediction. Since defect prediction datasets are typically imbalanced, and there are few defective examples, we treat defect prediction as anomaly detection. We present our Reconstruction Error Probability Distribution ({REPD}) model which can handle point and collective anomalies. We compare it on five different traditional code feature datasets against five models: Gaussian Naive Bayes, logistic regression, k-nearest-neighbors, decision tree, and Hybrid {SMOTE}-Ensemble. In addition, {REPD} is compared on 24 semantic features datasets against previously mentioned models. In order to compare the performance of competing models, we utilize F1-score measure. By using statistical means, we show that our model produces significantly better results, improving F1-score up to 7.12\%. Additionally, {REPD}’s robustness to dataset imbalance is analyzed by creating defect undersampled and non-defect oversampled datasets.},
	pages = {110641},
	journaltitle = {Journal of Systems and Software},
	author = {Afric, Petar and Sikic, Lucija and Kurdija, Adrian Satja and Silic, Marin},
	date = {2020},
	keywords = {Defect prediction, Anomaly detection, Program analysis, {REPD}, xno}
}

@article{tiugashev_toolset_2016,
	title = {Toolset for Construction and Verification of Rules for Spacecraft's Autonomous Decision Making},
	volume = {96},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050916320658},
	doi = {https://doi.org/10.1016/j.procs.2016.08.254},
	abstract = {Dependability of control system is one of the most complex problems in space projects. Decision making in case of contingencies is a non-trivial process requiring some “intelligence”. We can implement the “onboard intelligence” in different ways. The most common approach involves its implementation in the source code of the flight control software. The approach presented in the paper uses an onboard real-time decision making system. The decision making rules can be added or updated from Earth by radio channel. Currently, the rules should be specified in a table form, leading to misunderstandings in project team and errors. The improved approach provides the special toolset including, visual constructor of rules and support of rules’ verification. The proposed approach allows the engineers to define visually construct and update the decision making rules without programming background easily. The toolset prototype was positively evaluated at enterprise {JSC} Information Satellite Systems, Russia.},
	pages = {811--818},
	journaltitle = {Procedia Computer Science},
	author = {Tiugashev, Andrei A. and Belozubov, Alexander V.},
	date = {2016},
	keywords = {Autonomous spacecraft control, decision making, software toolset, verification, visual builder, xno}
}

@article{lopez-martin_transformed_2020,
	title = {Transformed k-nearest neighborhood output distance minimization for predicting the defect density of software projects},
	volume = {167},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220300728},
	doi = {https://doi.org/10.1016/j.jss.2020.110592},
	abstract = {Background Software defect prediction is one of the most important research topics in software engineering. An important product measure to determine the effectiveness of software processes is the defect density ({DD}). Cased-based reasoning ({CBR}) has been the prediction technique most widely applied in the software prediction field. The {CBR} involves k-nearest neighborhood for finding the number (k) of similar software projects selected to be involved in the prediction process. Objective To propose the application of a transformed k-nearest neighborhood output distance minimization ({TkDM}) algorithm to predict the {DD} of software projects to compare its prediction accuracy with those obtained from statistical regression, support vector regression, and neural networks. Method Data sets were obtained from the {ISBSG} release 2018. A leave-one-out cross validation method was performed. Absolute residual was used as the prediction accuracy criterion for models. Results Statistical significance tests among models showed that the {TkDM} had the best prediction accuracy than those ones from statistical regression, support vector regression, and neural networks. Conclusions A {TkDM} can be used for predicting the {DD} of new and enhanced software projects developed and coded in specific platforms and programming languages types.},
	pages = {110592},
	journaltitle = {Journal of Systems and Software},
	author = {López-Martín, Cuauhtémoc and Villuendas-Rey, Yenny and Azzeh, Mohammad and Nassif, Ali Bou and Banitaan, Shadi},
	date = {2020},
	keywords = {Support vector regression, Neural networks, Case-based reasoning, {ISBSG}, Software defect density prediction, Transformed k-nearest neighborhood output distance minimization, xno}
}

@article{mahmood_reproducibility_2018,
	title = {Reproducibility and replicability of software defect prediction studies},
	volume = {99},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917304202},
	doi = {https://doi.org/10.1016/j.infsof.2018.02.003},
	abstract = {Context: Replications are an important part of scientific disciplines. Replications test the credibility of original studies and can separate true results from those that are unreliable. Objective: In this paper we investigate the replication of defect prediction studies and identify the characteristics of replicated studies. We further assess how defect prediction replications are performed and the consistency of replication findings. Method: Our analysis is based on tracking the replication of 208 defect prediction studies identified by a highly cited Systematic Literature Review ({SLR}) [1]. We identify how often each of these 208 studies has been replicated and determine the type of replication carried out. We identify quality, citation counts, publication venue, impact factor, and data availability from all 208 {SLR} defect prediction papers to see if any of these factors are associated with the frequency with which they are replicated. Results: Only 13 (6\%) of the 208 studies are replicated. Replication seems related to original papers appearing in the Transactions of Software Engineering ({TSE}) journal. The number of citations an original paper had was also an indicator of replications. In addition, studies conducted using closed source data seems to have more replications than those based on open source data. Where a paper has been replicated, 11 (38\%) out of 29 studies revealed different results to the original study. Conclusion: Very few defect prediction studies are replicated. The lack of replication means that it remains unclear how reliable defect prediction is. We provide practical steps for improving the state of replication.},
	pages = {148--163},
	journaltitle = {Information and Software Technology},
	author = {Mahmood, Zaheed and Bowes, David and Hall, Tracy and Lane, Peter C. R. and Petrić, Jean},
	date = {2018},
	keywords = {Software defect prediction, Replication, Reproducibility, xno}
}

@article{kim_vfl_2019,
	title = {{VFL}: Variable-based fault localization},
	volume = {107},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918302453},
	doi = {https://doi.org/10.1016/j.infsof.2018.11.009},
	abstract = {{ABSTRACT} Context Fault localization is one of the most important debugging tasks. Hence, many automatic fault localization techniques have been proposed to reduce the burden on developers for such tasks. Among them, Spectrum-based Fault Localization ({SFL}) techniques leverage coverage information and localize faults based on the coverage difference between the failed and passed test cases. Objective However, such {SFL} techniques cannot localize faults effectively when coverage differences are not clear. To address this issue and improve the fault localization performance of the {SFL} techniques, we propose a Variable-based Fault Localization ({VFL}) technique. Method The {VFL} technique identifies suspicious variables and uses them to generate a ranked list of suspicious source code lines. Since it only requires additional information about variables that are also available in the {SFL} techniques, the proposed technique is lightweight and can be used to improve the performance of existing the {SFL} techniques. Results In an evaluation with 224 real Java faults and 120 C faults, the {VFL} technique outperforms the {SFL} techniques using the same similarity coefficient. The average Exam scores of the {VFL} techniques are reduced by more than 55\% compared to the {SFL} techniques, and the {VFL} techniques localize faults at a lower rank than the {SFL} techniques for about 73\% of the 344 faults. Conclusion We proposed a novel variable-based fault localization technique for more effective debugging. The {VFL} technique has better performance than the existing techniques and the results were more useful for actual fault localization tasks. In addition, this technique is very lightweight and scalable, so it is very easy to collaborate with other fault localization techniques.},
	pages = {179--191},
	journaltitle = {Information and Software Technology},
	author = {Kim, Jeongho and Kim, Jindae and Lee, Eunseok},
	date = {2019},
	keywords = {Software testing, Software debugging, Spectrum-based fault localization, Suspicious variable, Variable-based fault localization, xno}
}

@article{xu_ldfr_2019,
	title = {{LDFR}: Learning deep feature representation for software defect prediction},
	volume = {158},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121219301761},
	doi = {https://doi.org/10.1016/j.jss.2019.110402},
	abstract = {Software Defect Prediction ({SDP}) aims to detect defective modules to enable the reasonable allocation of testing resources, which is an economically critical activity in software quality assurance. Learning effective feature representation and addressing class imbalance are two main challenges in {SDP}. Ideally, the more discriminative the features learned from the modules and the better the rescue performed on the imbalance issue, the more effective it should be in detecting defective modules. In this study, to solve these two challenges, we propose a novel framework named {LDFR} by Learning Deep Feature Representation from the defect data for {SDP}. Specifically, we use a deep neural network with a new hybrid loss function that consists of a triplet loss to learn a more discriminative feature representation of the defect data and a weighted cross-entropy loss to remedy the imbalance issue. To evaluate the effectiveness of the proposed {LDFR} framework, we conduct extensive experiments on a benchmark dataset with 27 defect data (each with three types of features), using three traditional and three effort-aware indicators. Overall, the experimental results demonstrate the superiority of our {LDFR} framework in detecting defective modules when compared with 27 baseline methods, except in terms of the indicator of Precision.},
	pages = {110402},
	journaltitle = {Journal of Systems and Software},
	author = {Xu, Zhou and Li, Shuai and Xu, Jun and Liu, Jin and Luo, Xiapu and Zhang, Yifeng and Zhang, Tao and Keung, Jacky and Tang, Yutian},
	date = {2019},
	keywords = {Software defect prediction, Deep feature representation, Deep neural network, Triplet loss, Weighted cross-entropy loss, xno}
}

@article{zhao_comprehensive_2021,
	title = {A comprehensive investigation of the impact of feature selection techniques on crashing fault residence prediction models},
	volume = {139},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921001154},
	doi = {https://doi.org/10.1016/j.infsof.2021.106652},
	abstract = {Context: Software crash is a serious form of the software failure, which often occurs during the software development and maintenance process. As the stack trace reported when the software crashes contains a wealth of information about crashes, recent work utilized classification models with the collected features from stack traces and source code to predict whether the fault causing the crash resides in the stack trace. This could speed-up the crash localization task. Objective: As the quality of features can affect the performance of the constructed classification models, researchers proposed to use feature selection methods to select a representative feature subset to build models by replacing the original features. However, only limited feature selection methods and classification models were taken into consideration for this issue in previous work. In this work, we look into this topic deeply and find out the best feature selection method for crash fault residence prediction task. Method: We study the performance of 24 feature selection techniques with 21 classification models on a benchmark dataset containing crash instances from 7 real-world software projects. We use 4 indicators to evaluate the performance of these feature selection methods which are applied to the classification models. Results: The experimental results show that, overall, a probability-based feature selection, called Symmetrical Uncertainty, performs well across the studied classification models and projects. Thus, we recommend such a feature selection method to preprocess the crash instances before constructing classification models to predict the crash fault residence. Conclusion: This work conducts a large-scale empirical study to investigate the impact of feature selection methods on the performance of classification models for the crashing fault residence prediction task. The results clearly demonstrate that there exist significant performance differences among these feature selection techniques across different classification models and projects.},
	pages = {106652},
	journaltitle = {Information and Software Technology},
	author = {Zhao, Kunsong and Xu, Zhou and Yan, Meng and Zhang, Tao and Yang, Dan and Li, Wei},
	date = {2021},
	keywords = {Feature selection, Stack trace, Empirical study, Crash localization, xno}
}

@article{lu_concurrent_2013,
	title = {Concurrent and comparative fault simulation in {SystemC} and its application in robustness evaluation},
	volume = {37},
	issn = {0141-9331},
	url = {https://www.sciencedirect.com/science/article/pii/S0141933112001676},
	doi = {https://doi.org/10.1016/j.micpro.2012.09.005},
	abstract = {In this work, we present extensions to the {SystemC} library and automatable model transformations that enable efficient system-level fault simulation in {SystemC}. The method is based on extended data types which represent variables or signals as lists of values (instead of one value) consisting of a fault free reference value and any number of faulty values each of which corresponds to one fault. We inject faults (variable level faults as well as bit level faults) into objects declared with the extended data types. These faults are then propagated to other objects during {SystemC} simulation, until either they are classified and dropped or the simulation ends. The extended {SystemC} simulator is intended for robustness evaluation of digital and embedded designs, for which we propose a condition-oriented quantitative fault model. Speedups of up to 1905 and 10 are achieved for transient faults in digital circuit simulation and for a custom fault model in software algorithm robustness evaluation, respectively.},
	pages = {115--128},
	number = {2},
	journaltitle = {Microprocessors and Microsystems},
	author = {Lu, Weiyun and Radetzki, Martin},
	date = {2013},
	keywords = {Robustness evaluation, Concurrent comparative simulation, Fault simulation, {SystemC}, xno}
}

@article{santos_runtime_2021,
	title = {Runtime testing of context-aware variability in adaptive systems},
	volume = {131},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920301002},
	doi = {https://doi.org/10.1016/j.infsof.2020.106482},
	abstract = {Context: A Dynamically Adaptive System ({DAS}) supports runtime adaptations to handle changes in the operational environment. These adaptations can change the system’s structure or behavior and even the logic of its adaptation mechanism. However, these adaptations may insert defects, leading the system to fail at runtime. Objective: Aiming to identify these failures, testing can be executed to verify the system at runtime. Studies in the literature mostly focus on testing to verify the adaptations at design-time or functionalities at runtime, rather than exercising the adaptation mechanism at runtime. So, we propose {RETAkE} ({RuntimE} Testing of dynamically Adaptive {systEms}). Method: {RETAkE} is an approach to perform the runtime testing based on the system’s context variability and feature modeling. {RETAkE} tests the adaptation mechanism, enabling the verification of its adaptation rules with the system’s variability model. The runtime testing is supported by the verification of behavioral properties. For the evaluation, we used the mutation testing technique with two {DAS}. We also conducted an evaluation to measure the overhead introduced when {RETAkE} is integrated to the {DAS}. Results: {RETAkE} identified the mutants in the two mobile {DAS}, but the results vary due to the probabilistic nature of the approach to generate test sequences. Regarding the overhead, test sequences of size 30 had a low impact. However, bigger test sequences increase the overhead. Conclusion: The integration of {RETAkE} to the {DAS} adaptation mechanism can support the discovery of adaptation failures that occur at runtime. Furthermore, the results of the evaluation suggest its feasibility to perform runtime testing.},
	pages = {106482},
	journaltitle = {Information and Software Technology},
	author = {Santos, Erick Barros dos and Andrade, Rossana M. C. and Santos, Ismayle de Sousa},
	date = {2021},
	keywords = {Adaptive systems, Dynamic variability, Runtime testing, xno}
}

@article{aghamohammadi_generating_2020,
	title = {Generating summaries for methods of event-driven programs: An Android case study},
	volume = {170},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220302065},
	doi = {https://doi.org/10.1016/j.jss.2020.110800},
	abstract = {The lack of proper documentation makes program comprehension a cumbersome process for developers. Source code summarization is one of the existing solutions to this problem. Many approaches have been proposed to summarize source code in recent years. A prevalent weakness of these solutions is that they do not pay much attention to interactions among elements of software. An element is simply a callable code snippet such as a method or even a clickable button. As a result, these approaches cannot be applied to event-driven programs, such as Android applications, because they have specific features such as numerous interactions between their elements. To tackle this problem, we propose a novel approach based on deep neural networks and dynamic call graphs to generate summaries for methods of event-driven programs. First, we collect a set of comment/code pairs from Github and train a deep neural network on the set. Afterward, by exploiting a dynamic call graph, the Pagerank algorithm, and the pre-trained deep neural network, we generate summaries. An empirical evaluation with 14 real-world Android applications and 42 participants indicates 32.3\% {BLEU}4 which is a definite improvement compared to the existing state-of-the-art techniques. We also assessed the informativeness and naturalness of our generated summaries from developers’ perspectives and showed they are sufficiently understandable and informative.},
	pages = {110800},
	journaltitle = {Journal of Systems and Software},
	author = {Aghamohammadi, Alireza and Izadi, Maliheh and Heydarnoori, Abbas},
	date = {2020},
	keywords = {Deep learning, Event-driven programs, Neural machine translation, Source code summarization, xno}
}

@article{li_semantically_2020,
	title = {Semantically find similar binary codes with mixed key instruction sequence},
	volume = {125},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920300732},
	doi = {https://doi.org/10.1016/j.infsof.2020.106320},
	abstract = {Context Software similarity comparison has always been a common technique for software reuse detection, plagiarism detection, and defect detection. Objective Considering the role of {API} calls and arithmetic operations in software execution, a semantic-based dynamic software analysis method–mixed key instruction sequence ({MKIS}) is proposed. Method {MKIS} embeds key value sets into a vector and constructs a novel software execution sequence that contains {API} calls and arithmetic operations during software execution. To determine the location of key values, a key-value equivalent matching algorithm is proposed, combined with the longest common subsequence algorithm to optimize the software execution sequence. Results Experiments show that {MKIS} can accurately compare the similarity of binary programs without obtaining the software source code, and has better resiliency and credibility. Conclusion Moreover, in the case when the software source code is changed with some main function-independent modification and code obfuscator, software reuse can be successfully detected.},
	pages = {106320},
	journaltitle = {Information and Software Technology},
	author = {Li, Yuancheng and Wang, Boyan and Hu, Baiji},
	date = {2020},
	keywords = {Binary code similarity comparison, Code obfuscators, Dynamic software analysis, Mixed key instruction sequence, Software birthmark, xno}
}

@article{huang_towards_2020,
	title = {Towards automatically generating block comments for code snippets},
	volume = {127},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920301427},
	doi = {https://doi.org/10.1016/j.infsof.2020.106373},
	abstract = {Code commenting is a common programming practice of practical importance to help developers review and comprehend source code. There are two main types of code comments for a method: header comments that summarize the method functionality located before a method, and block comments that describe the functionality of the code snippets within a method. Inspired by the effectiveness of deep learning techniques in the {NLP} field, many studies focus on using the machine translation model to automatically generate comment for the source code. Because the data set of block comments is difficult to collect, current studies focus more on the automatic generation of header comments than that of block comments. However, block comments are important for program comprehension due to their explanation role for the code snippets in a method. To fill the gap, we have proposed an approach that combines heuristic rules and learning-based method to collect a large number of comment-code pairs from 1,032 open source projects in our previous study. In this paper, we propose a reinforcement learning-based method, {RL}-{BlockCom}, to automatically generate block comments for code snippets based on the collected comment-code pairs. Specifically, we utilize the abstract syntax tree (i.e., {AST}) of a code snippet to generate a token sequence with a statement-based traversal way. Then we propose a composite learning model, which combines the actor-critic algorithm of reinforcement learning with the encoder-decoder algorithm, to generate block comments. On the data set of the comment-code pairs, the {BLEU}-4 score of our method is 24.28, which outperforms the baselines and state-of-the-art in comment generation.},
	pages = {106373},
	journaltitle = {Information and Software Technology},
	author = {Huang, Yuan and Huang, Shaohao and Chen, Huanchao and Chen, Xiangping and Zheng, Zibin and Luo, Xiapu and Jia, Nan and Hu, Xinyu and Zhou, Xiaocong},
	date = {2020},
	keywords = {Source code summarization, Automatic comment generation, Code comment scope, Reinforcement learning, xno}
}

@article{feng_investigation_2021,
	title = {Investigation on the stability of {SMOTE}-based oversampling techniques in software defect prediction},
	volume = {139},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921001257},
	doi = {https://doi.org/10.1016/j.infsof.2021.106662},
	abstract = {Context: In practice, software datasets tend to have more non-defective instances than defective ones, which is referred to as the class imbalance problem in software defect prediction ({SDP}). Synthetic Minority Oversampling {TEchnique} ({SMOTE}) and its variants alleviate the class imbalance problem by generating synthetic defective instances. {SMOTE}-based oversampling techniques were widely adopted as the baselines to compare with the newly proposed oversampling techniques in {SDP}. However, randomness is introduced during the procedure of {SMOTE}-based oversampling techniques. If the performance of {SMOTE}-based oversampling techniques is highly unstable, the conclusion drawn from the comparison between {SMOTE}-based oversampling techniques and the newly proposed techniques may be misleading and less convincing. Objective: This paper aims to investigate the stability of {SMOTE}-based oversampling techniques. Moreover, a series of stable {SMOTE}-based oversampling techniques are proposed to improve the stability of {SMOTE}-based oversampling techniques. Method: Stable {SMOTE}-based oversampling techniques reduce the randomness in each step of {SMOTE}-based oversampling techniques by selecting defective instances in turn, distance-based selection of K neighbor instances, and evenly distributed interpolation. Besides, we mathematically prove and also empirically investigate the stability of {SMOTE}-based and stable {SMOTE}-based oversampling techniques on four common classifiers across 26 datasets in terms of {AUC}, balance, and {MCC}. Results: The analysis of {SMOTE}-based and stable {SMOTE}-based oversampling techniques shows that the performance of stable {SMOTE}-based oversampling techniques is more stable and better than that of {SMOTE}-based oversampling techniques. The difference between the worst and best performances of {SMOTE}-based oversampling techniques is up to 23.3\%, 32.6\%, and 204.2\% in terms of {AUC}, balance, and {MCC}, respectively. Conclusion: Stable {SMOTE}-based oversampling techniques should be considered as a drop-in replacement for {SMOTE}-based oversampling techniques.},
	pages = {106662},
	journaltitle = {Information and Software Technology},
	author = {Feng, Shuo and Keung, Jacky and Yu, Xiao and Xiao, Yan and Zhang, Miao},
	date = {2021},
	keywords = {Software defect prediction, Class imbalance, {SMOTE}, Empirical Software Engineering, Oversampling, xno}
}

@article{shippey_automatically_2019,
	title = {Automatically identifying code features for software defect prediction: Using {AST} N-grams},
	volume = {106},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918302052},
	doi = {https://doi.org/10.1016/j.infsof.2018.10.001},
	abstract = {Context: Identifying defects in code early is important. A wide range of static code metrics have been evaluated as potential defect indicators. Most of these metrics offer only high level insights and focus on particular pre-selected features of the code. None of the currently used metrics clearly performs best in defect prediction. Objective: We use Abstract Syntax Tree ({AST}) n-grams to identify features of defective Java code that improve defect prediction performance. Method: Our approach is bottom-up and does not rely on pre-selecting any specific features of code. We use non-parametric testing to determine relationships between {AST} n-grams and faults in both open source and commercial systems. We build defect prediction models using three machine learning techniques. Results: We show that {AST} n-grams are very significantly related to faults in some systems, with very large effect sizes. The occurrence of some frequently occurring {AST} n-grams in a method can mean that the method is up to three times more likely to contain a fault. {AST} n-grams can have a large effect on the performance of defect prediction models. Conclusions: We suggest that {AST} n-grams offer developers a promising approach to identifying potentially defective code.},
	pages = {142--160},
	journaltitle = {Information and Software Technology},
	author = {Shippey, Thomas and Bowes, David and Hall, Tracy},
	date = {2019},
	keywords = {xno}
}

@article{zou_joint_2021,
	title = {Joint feature representation learning and progressive distribution matching for cross-project defect prediction},
	volume = {137},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921000689},
	doi = {https://doi.org/10.1016/j.infsof.2021.106588},
	abstract = {Context: Cross-Project Defect Prediction ({CPDP}) aims to leverage the knowledge from label-rich source software projects to promote tasks in a label-poor target software project. Existing {CPDP} methods have two major flaws. One is that previous {CPDP} methods only consider global feature representation and ignores local relationship between instances in the same category from different projects, resulting in ambiguous predictions near the decision boundary. The other one is that {CPDP} methods based on pseudo-labels assume that the conditional distribution can be well matched at one stroke, when instances of target project are correctly annotated pseudo labels. However, due to the great gap between projects, the pseudo-labels seriously deviate from the real labels. Objective: To address above issues, this paper proposed a novel {CPDP} method named Joint Feature Representation with Double Marginalized Denoising Autoencoders ({DMDA}\_JFR). Method: Our method mainly includes two parts: joint feature representation learning and progressive distribution matching. We utilize two novel autoencoders to jointly learn the global and local feature representations simultaneously. To achieve progressive distribution matching, we introduce a repetitious pseudo-labels strategy, which makes it possible that distributions are matched after each stack layer learning rather than in one stroke. Results: The effectiveness of the proposed method was evaluated through experiments conducted on 10 open-source projects, including 29 software releases from {PROMISE} repository. Overall, experimental results show that our proposed method outperformed several state-of-the-art baseline {CPDP} methods. Conclusions: It can be concluded that (1) joint deep representations are promising for {CPDP} compared with only considering global feature representation methods, (2) progressive distribution matching is more effective for adapting probability distributions in {CPDP} compared with existing {CPDP} methods based on pseudo-labels.},
	pages = {106588},
	journaltitle = {Information and Software Technology},
	author = {Zou, Quanyi and Lu, Lu and Yang, Zhanyu and Gu, Xiaowei and Qiu, Shaojian},
	date = {2021},
	keywords = {Cross project defect prediction, Domain adaption, Feature representation, Progressive distribution matching, xno}
}

@article{demott_systematic_2013,
	title = {Systematic bug finding and fault localization enhanced with input data tracking},
	volume = {32},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S016740481200168X},
	doi = {https://doi.org/10.1016/j.cose.2012.09.015},
	abstract = {Fault localization ({FL}) is the process of debugging erroneous code and directing analysts to the root cause of the bug. With this in mind, we have developed a distributed, end-to-end fuzzing and analysis system that starts with a binary, identifies bugs, and subsequently localizes the bug's root cause. Our system does not require the test subject's source code, nor do we require a test suite. Our work focuses on an important class of bugs, memory corruption errors, which usually have software security implications. Thus, our approach appeals to software attack researchers as well. In addition to our bug hunting and analysis framework, we have enhanced code-coverage based fault localization by incorporating input data tainting and tracking using a light-weight binary instrumentation technique. By capturing code coverage and select input data usage, our new {FL} algorithm is able to better localize faults, and therefore better assist analysts. We report the application of our approach on large, real-world applications (Firefox and {VLC}), as well as the classic Siemens benchmark and other test programs.},
	pages = {130--157},
	journaltitle = {Computers \& Security},
	author = {{DeMott}, Jared D. and Enbody, Richard J. and Punch, William F.},
	date = {2013},
	keywords = {Software security, Fault localization, Distributed fuzzing, Information flow controls, Testing and debugging, xno}
}

@article{badri_predicting_2015,
	title = {Predicting Unit Testing Effort Levels of Classes: An Exploratory Study based on Multinomial Logistic Regression Modeling},
	volume = {62},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050915026630},
	doi = {https://doi.org/10.1016/j.procs.2015.08.528},
	abstract = {The study aims at investigating empirically the ability of a Quality Assurance Indicator (Qi), a metric that we proposed in a previous work, to predict different levels of unit testing effort of classes in object-oriented systems. To capture the unit testing effort of classes, we used four metrics to quantify various perspectives related to the code of corresponding unit test cases. Classes were classified, according to the involved unit testing effort, in five categories (levels). We collected data from two open source Java software systems ({ANT} and {JFREECHART}) for which {JUnit} test cases exist. In order to explore the ability of the Qi metric to predict different levels of the unit testing effort of classes, we decided to explore the possibility of using the Multinomial Logistic Regression ({MLR}) method. The performance of the Qi metric has been compared to the performance of three well-known source code metrics related respectively to size, complexity and coupling. Results suggest that the {MLR} model based on the Qi metric is able to accurately predict different levels of the unit testing effort of classes.},
	pages = {529--538},
	journaltitle = {Procedia Computer Science},
	author = {Badri, Mourad and Toure, Fadel and Lamontagne, Luc},
	date = {2015},
	keywords = {Prediction, Metrics, Empirical Analysis., {JUnit} Code, Multinomial Logistic Regression, Object-Oriented Systems, Software Testability, Unit Testing Effort, xno}
}

@article{okutan_novel_2016,
	title = {A novel kernel to predict software defectiveness},
	volume = {119},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121216300759},
	doi = {https://doi.org/10.1016/j.jss.2016.06.006},
	abstract = {Although the software defect prediction problem has been researched for a long time, the results achieved are not so bright. In this paper, we propose to use novel kernels for defect prediction that are based on the plagiarized source code, software clones and textual similarity. We generate precomputed kernel matrices and compare their performance on different data sets to model the relationship between source code similarity and defectiveness. Each value in a kernel matrix shows how much parallelism exists between the corresponding files of a software system chosen. Our experiments on 10 real world datasets indicate that support vector machines ({SVM}) with a precomputed kernel matrix performs better than the {SVM} with the usual linear kernel in terms of F-measure. Similarly, when used with a precomputed kernel, the k-nearest neighbor classifier ({KNN}) achieves comparable performance with respect to {KNN} classifier. The results from this preliminary study indicate that source code similarity can be used to predict defect proneness.},
	pages = {109--121},
	journaltitle = {Journal of Systems and Software},
	author = {Okutan, Ahmet and Yildiz, Olcay Taner},
	date = {2016},
	keywords = {Defect prediction, Kernel methods, {SVM}, xno}
}

@article{hegedus_empirical_2018,
	title = {Empirical evaluation of software maintainability based on a manually validated refactoring dataset},
	volume = {95},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584916303561},
	doi = {https://doi.org/10.1016/j.infsof.2017.11.012},
	abstract = {Context Refactoring is a technique for improving the internal structure of software systems. It has a solid theoretical background while being used in development practice also. However, we lack empirical research results on the real effect of code refactoring and its application. Objective This paper presents a manually validated subset of a previously published dataset containing the refactorings extracted by the {RefFinder} tool, code metrics, and maintainability of 7 open-source systems. We found that {RefFinder} had around 27\% overall average precision on the subject systems, thus our manually validated subset has substantial added value. Using the dataset, we studied several aspects of the refactored and non-refactored source code elements (classes and methods), like the differences in their maintainability and source code metrics. Method We divided the source code elements into a group containing the refactored elements and a group with non-refactored elements. We analyzed the elements’ characteristics in these groups using correlation analysis, Mann–Whitney U test and effect size measures. Results Source code elements subjected to refactorings had significantly lower maintainability than elements not affected by refactorings. Moreover, refactored elements had significantly higher size related metrics, complexity, and coupling. Also these metrics changed more significantly in the refactored elements. The results are mostly in line with our previous findings on the not validated dataset, with the difference that clone metrics had no strong connection with refactoring. Conclusions Compared to the preliminary analysis using a not validated dataset, the manually validated dataset led to more significant results, which suggests that developers find targets for refactorings based on some internal quality properties of the source code, like their size, complexity or coupling, but not clone related metrics as reported in our previous studies. They do not just use these properties for identifying targets, but also control them with refactorings.},
	pages = {313--327},
	journaltitle = {Information and Software Technology},
	author = {Hegedűs, Péter and Kádár, István and Ferenc, Rudolf and Gyimóthy, Tibor},
	date = {2018},
	keywords = {Source code metrics, Empirical study, Code refactoring, Manually validated empirical dataset, Software maintainability, xno}
}

@article{zhang_automated_2020,
	title = {Automated defect identification via path analysis-based features with transfer learning},
	volume = {166},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220300662},
	doi = {https://doi.org/10.1016/j.jss.2020.110585},
	abstract = {Recently, artificial intelligence techniques have been widely applied to address various specialized tasks in software engineering, such as code generation, defect identification, and bug repair. Despite the diffuse usage of static analysis tools in automatically detecting potential software defects, developers consider the large number of reported alarms and the expensive cost of manual inspection to be a key barrier to using them in practice. To automate the process of defect identification, researchers utilize machine learning algorithms with a set of hand-engineered features to build classification models for identifying alarms as actionable or unactionable. However, traditional features often fail to represent the deep syntactic structure of alarms. To bridge the gap between programs’ syntactic structure and defect identification features, this paper first extracts a set of novel fine-grained features at variable-level, called path-variable characteristic, by applying path analysis techniques in the feature extraction process. We then raise a two-stage transfer learning approach based on our proposed features, called feature ranking-matching based transfer learning, to increase the performance of cross-project defect identification. Our experimental results for eight open-source projects show that the proposed features at variable-level are promising and can yield significant improvement on both within-project and cross-project defect identification.},
	pages = {110585},
	journaltitle = {Journal of Systems and Software},
	author = {Zhang, Yuwei and Jin, Dahai and Xing, Ying and Gong, Yunzhan},
	date = {2020},
	keywords = {Machine learning, Transfer learning, Automated defect identification, Model evaluation, Path analysis, xno}
}

@article{chen_multi_2018,
	title = {{MULTI}: Multi-objective effort-aware just-in-time software defect prediction},
	volume = {93},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917304627},
	doi = {https://doi.org/10.1016/j.infsof.2017.08.004},
	abstract = {Context: Just-in-time software defect prediction ({JIT}-{SDP}) aims to conduct defect prediction on code changes, which have finer granularity. A recent study by Yang et al. has shown that there exist some unsupervised methods, which are comparative to supervised methods in effort-aware {JIT}-{SDP}. Objective: However, we still believe that supervised methods should have better prediction performance since they effectively utilize the gathered defect prediction datasets. Therefore we want to design a new supervised method for {JIT}-{SDP} with better performance. Method: In this article, we propose a multi-objective optimization based supervised method {MULTI} to build {JIT}-{SDP} models. In particular, we formalize {JIT}-{SDP} as a multi-objective optimization problem. One objective is designed to maximize the number of identified buggy changes and another object is designed to minimize the efforts in software quality assurance activities. There exists an obvious conflict between these two objectives. {MULTI} uses logistic regression to build the models and uses {NSGA}-{II} to generate a set of non-dominated solutions, which each solution denotes the coefficient vector for the logistic regression. Results: We design and conduct a large-scale empirical studies to compare {MULTI} with 43 state-of-the-art supervised and unsupervised methods under the three commonly used performance evaluation scenarios: cross-validation, cross-project-validation, and timewise-cross-validation. Based on six open-source projects with 227,417 changes in total, our experimental results show that {MULTI} can perform significantly better than all of the state-of-the-art methods when considering {ACC} and {POPT} performance metrics. Conclusion: By using multi-objective optimization, {MULTI} can perform significantly better than the state-of-the-art supervised and unsupervised methods in the three performance evaluation scenarios. The results confirm that supervised methods are still promising in effort-aware {JIT}-{SDP}.},
	pages = {1--13},
	journaltitle = {Information and Software Technology},
	author = {Chen, Xiang and Zhao, Yingquan and Wang, Qiuping and Yuan, Zhidan},
	date = {2018},
	keywords = {Empirical studies, Just-in-time defect prediction, Multi-objective optimization, Search based software engineering, xno}
}

@article{cotroneo_testing_2013,
	title = {Testing techniques selection based on {ODC} fault types and software metrics},
	volume = {86},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121213000319},
	doi = {https://doi.org/10.1016/j.jss.2013.02.020},
	abstract = {Software testing techniques differ in the type of faults they are more prone to detect, and their performance varies depending on the features of the application being tested. Practitioners often use informally their knowledge about the software under test in order to combine testing techniques for maximizing the number of detected faults. This work presents an approach to enable practitioners to select testing techniques according to the features of the software to test. A method to build a testing-related base of knowledge for tailoring the techniques selection process to the specific application(s) is proposed. The method grounds upon two basic steps: (i) constructing, on an empirical basis, models to characterize the software to test in terms of fault types it is more prone to contain; (ii) characterizing testing techniques with respect to fault types they are more prone to detect in the given context. Using the created base of knowledge, engineers within an organization can define the mix of techniques so as to maximize the effectiveness of the testing process for their specific software.},
	pages = {1613--1637},
	number = {6},
	journaltitle = {Journal of Systems and Software},
	author = {Cotroneo, Domenico and Pietrantuono, Roberto and Russo, Stefano},
	date = {2013},
	keywords = {Software testing, xno}
}

@article{huang_commtpst_2020,
	title = {{CommtPst}: Deep learning source code for commenting positions prediction},
	volume = {170},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301758},
	doi = {https://doi.org/10.1016/j.jss.2020.110754},
	abstract = {Existing techniques for automatic code commenting assume that the code snippet to be commented has been identified, thus requiring users to provide the code snippet in advance. A smarter commenting approach is desired to first self-determine where to comment in a given source code and then generate comments for the code snippets that need comments. To achieve the first step of this goal, we propose a novel method, {CommtPst}, to automatically find the appropriate commenting positions in the source code. Since commenting is closely related to the code syntax and semantics, we adopt neural language model (word embeddings) to capture the code semantic information, and analyze the abstract syntax trees to capture code syntactic information. Then, we employ {LSTM} (long short term memory) to model the long-term logical dependency of code statements over the fused semantic and syntactic information and learn the commenting patterns on the code sequence. We evaluated {CommtPst} using large data sets from dozens of open-source software systems in {GitHub}. The experimental results show that the precision, recall and F-Measure values achieved by {CommtPst} are 0.792, 0.602 and 0.684, respectively, which outperforms the traditional machine learning method with 11.4\% improvement on F-measure.},
	pages = {110754},
	journaltitle = {Journal of Systems and Software},
	author = {Huang, Yuan and Hu, Xinyu and Jia, Nan and Chen, Xiangping and Zheng, Zibin and Luo, Xiapu},
	date = {2020},
	keywords = {Code semantics, Code syntax, Comment generation, Comment position, {LSTM}, xno}
}

@article{phan_automatically_2018,
	title = {Automatically classifying source code using tree-based approaches},
	volume = {114},
	issn = {0169-023X},
	url = {https://www.sciencedirect.com/science/article/pii/S0169023X17300344},
	doi = {https://doi.org/10.1016/j.datak.2017.07.003},
	abstract = {Analyzing source code to solve software engineering problems such as fault prediction, cost, and effort estimation always receives attention of researchers as well as companies. The traditional approaches are based on machine learning, and software metrics obtained by computing standard measures of software projects. However, these methods have faced many challenges due to limitations of using software metrics which were not enough to capture the complexity of programs. To overcome the limitations, this paper aims to solve software engineering problems by exploring information of programs' abstract syntax trees ({ASTs}) instead of software metrics. We propose two combination models between a tree-based convolutional neural network ({TBCNN}) and k-Nearest Neighbors ({kNN}), support vector machines ({SVMs}) to exploit both structural and semantic {ASTs}' information. In addition, to deal with high-dimensional data of {ASTs}, we present several pruning tree techniques which not only reduce the complexity of data but also enhance the performance of classifiers in terms of computational time and accuracy. We survey many machine learning algorithms on different types of program representations including software metrics, sequences, and tree structures. The approaches are evaluated based on classifying 52000 programs written in C language into 104 target labels. The experiments show that the tree-based classifiers dramatically achieve high performance in comparison with those of metrics-based or sequences-based; and two proposed models {TBCNN} + {SVM} and {TBCNN} + {kNN} rank as the top and the second classifiers. Pruning redundant {AST} branches leads to not only a substantial reduction in execution time but also an increase in accuracy.},
	pages = {12--25},
	journaltitle = {Data \& Knowledge Engineering},
	author = {Phan, Anh Viet and Chau, Phuong Ngoc and Nguyen, Minh Le and Bui, Lam Thu},
	date = {2018},
	keywords = {Abtract Syntax Tree ({AST}), K-Nearest Neighbors ({kNN}), Support Vector Machines ({SVMs}), Tree-based convolutional neural networks({TBCNN}), xyes},
	file = {Phan et al. - 2018 - Automatically classifying source code using tree-b.pdf:C\:\\Users\\michalm\\Zotero\\storage\\LWB2FQJU\\Phan et al. - 2018 - Automatically classifying source code using tree-b.pdf:application/pdf}
}

@article{soares_feature_2018,
	title = {Feature interaction in software product line engineering: A systematic mapping study},
	volume = {98},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917302690},
	doi = {https://doi.org/10.1016/j.infsof.2018.01.016},
	abstract = {Context: Software product lines ({SPL}) engineering defines a set of systems that share common features and artifacts to achieve high productivity, quality, market agility, low time to market, and cost. An {SPL} product is derived from a configuration of features which need to be compounded together without violating their particular specifications. While it is easy to identify the behavior of a feature in isolation, specifying and resolving interactions among features may not be a straightforward task. The feature interaction problem has been a challenging subject for decades. Objective: This study aims at surveying existing research on feature interaction in {SPL} engineering in order to identify common practices and research trends. Method: A systematic mapping study was conducted with a set of seven research questions, in which the 35 studies found are mainly classified regarding the feature interaction solution presented: detection, resolution and general analysis. Results: 43\% of the papers deal with feature interaction at early phases of a software lifecycle. The remaining is shared among the other categories: source code detection, resolution and analysis. For each category, it was also identified the main strategies used to deal with interactions. Conclusions: The findings can help to understand the needs in feature interaction for {SPL} engineering, and highlight aspects that still demand an additional investigation. For example, often strategies are partial and only address specific points of a feature interaction investigation.},
	pages = {44--58},
	journaltitle = {Information and Software Technology},
	author = {Soares, Larissa Rocha and Schobbens, Pierre-Yves and Machado, Ivan do Carmo and Almeida, Eduardo Santana de},
	date = {2018},
	keywords = {Systematic mapping, Feature interaction, Software product lines, xno}
}

@article{meqdadi_mining_2019,
	title = {Mining software repositories for adaptive change commits using machine learning techniques},
	volume = {109},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584919300084},
	doi = {https://doi.org/10.1016/j.infsof.2019.01.008},
	abstract = {Context Version Control Systems, such as Subversion, are standard repositories that preserve all of the maintenance changes undertaken to source code artifacts during the evolution of a software system. The documented data of the version history are organized as commits; however, these commits do not keep a tag that would identify the purpose of the relevant undertaken change of a commit, thus, there is rarely enough detail to clearly direct developers to the changes associated with a specific type of maintenance. Objective This work examines the version histories of an open source system to automatically classify version commits into one of two categories, namely adaptive commits and non-adaptive commits. Method We collected the commits from the version history of three open source systems, then we obtained eight different code change metrics related to, for example, the number of changed statements, methods, hunks, and files. Based on these change metrics, we built a machine learning approach to classify whether a commit was adaptive or not. Results It is observed that code change metrics can be indicative of adaptive maintenance activities. Also, the classification findings show that the machine learning classifier developed has approximately 75\% prediction accuracy within labeled change histories. Conclusion The proposed method automates the process of examining the version history of a software system and identifies which commits to the system are related to an adaptive maintenance task. The evaluation of the method supports its applicability and efficiency. Although the evaluation of the proposed classifier on unlabeled change histories shows that it is not much better than the random guessing in terms of F-measure, we feel that our classifier would serve as a better basis for developing advanced classifiers that have predictive power of adaptive commits without the need of manual efforts.},
	pages = {80--91},
	journaltitle = {Information and Software Technology},
	author = {Meqdadi, Omar and Alhindawi, Nouh and Alsakran, Jamal and Saifan, Ahmad and Migdadi, Hatim},
	date = {2019},
	keywords = {Machine learning, Adaptive maintenance, Code change metrics, Commit types, Maintenance classification, xno}
}

@article{kaur_cognitive_2019,
	title = {Cognitive complexity as a quantifier of version to version Java-based source code change: An empirical probe},
	volume = {106},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918301903},
	doi = {https://doi.org/10.1016/j.infsof.2018.09.002},
	abstract = {Context It has been often argued that it is challenging to modify code fragments from existing software that contains files that are difficult to comprehend. Since systematic software maintenance includes an extensive human activity, cognitive complexity is one of the intrinsic factors that could potentially contribute to or impede an efficient software maintenance practice, the empirical validation of which remains vastly unaddressed. Objective This study conducts an experimental analysis in which the software developer's level of difficulty in comprehending the software: the cognitive complexity, is theoretically computed and empirically evaluated for estimating its relevance to actual software change. Method For multiple successive releases of two Java-based software projects, where the source code of a previous release has been substantively used in a novel release, we calculate the change results and the values of the cognitive complexity for each of the version's source code Java files. We construct eight datasets and build predictive models using statistical analysis and machine learning techniques. Results The pragmatic comparative examination of the estimated cognitive complexity against prevailing metrics of software change and software complexity clearly validates the cognitive complexity metric as a noteworthy measure of version to version source code change.},
	pages = {31--48},
	journaltitle = {Information and Software Technology},
	author = {Kaur, Loveleen and Mishra, Ashutosh},
	date = {2019},
	keywords = {Software metrics, Machine learning, Cognitive complexity, Logistic regression analysis, Software change, xno}
}

@article{bigonha_usefulness_2019,
	title = {The usefulness of software metric thresholds for detection of bad smells and fault prediction},
	volume = {115},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584919301697},
	doi = {https://doi.org/10.1016/j.infsof.2019.08.005},
	abstract = {Context Software metrics may be an effective tool to assess the quality of software, but to guide their use it is important to define their thresholds. Bad smells and fault also impact the quality of software. Extracting metrics from software systems is relatively low cost since there are tools widely used for this purpose, which makes feasible applying software metrics to identify bad smells and to predict faults. Objective To inspect whether thresholds of object-oriented metrics may be used to aid bad smells detection and fault predictions. Method To direct this research, we have defined three research questions ({RQ}), two related to identification of bad smells, and one for identifying fault in software systems. To answer these {RQs}, we have proposed detection strategies for the bad smells: Large Class, Long Method, Data Class, Feature Envy, and Refused Bequest, based on metrics and their thresholds. To assess the quality of the derived thresholds, we have made two studies. The first one was conducted to evaluate their efficacy on detecting these bad smells on 12 systems. A second study was conducted to investigate for each of the class level software metrics: {DIT}, {LCOM}, {NOF}, {NOM}, {NORM}, {NSC}, {NSF}, {NSM}, {SIX}, and {WMC}, if the ranges of values determined by thresholds are useful to identify fault in software systems. Results Both studies confirm that metric thresholds may support the prediction of faults in software and are significantly and effective in the detection of bad smells. Conclusion The results of this work suggest practical applications of metric thresholds to identify bad smells and predict faults and hence, support software quality assurance activities.Their use may help developers to focus their efforts on classes that tend to fail, thereby minimizing the occurrence of future problems.},
	pages = {79--92},
	journaltitle = {Information and Software Technology},
	author = {Bigonha, Mariza A. S. and Ferreira, Kecia and Souza, Priscila and Sousa, Bruno and Januário, Marcela and Lima, Daniele},
	date = {2019},
	keywords = {Software metrics, Software quality, Fault prediction, Bad smell, Detection strategies, Thresholds, xno}
}

@article{li_hmer_2020,
	title = {{HMER}: A Hybrid Mutation Execution Reduction approach for Mutation-based Fault Localization},
	volume = {168},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301230},
	doi = {https://doi.org/10.1016/j.jss.2020.110661},
	abstract = {Identifying the location of faults in programs has been recognized as one of the most manually and time cost activities during software debugging process. Fault localization techniques, which seek to identify faulty program statements as quickly as possible, can assist developers in alleviating the time and manual cost of software debugging. Mutation-based fault localization({MBFL}) has a promising fault localization accuracy, but suffered from huge mutation execution cost. To reduce the cost of {MBFL}, we propose a Hybrid Mutation Execution Reduction({HMER}) approach in this paper. {HMER} consists of two steps: Weighted Statement-Oriented Mutant Sampling({WSOME}) and Dynamic Mutation Execution Strategy({DMES}). In the first step, we employ Spectrum-Based Fault Localization({SBFL}) techniques to calculate the suspiciousness value of statements, and guarantee that the mutants generated from statements with higher suspiciousness value will have more chance to be remained in the sampling process. Next, a dynamic mutation execution strategy is used to execute the reduced mutant set on test suite to avoid worthless execution. Empirical results on 130 versions from 9 subject programs show that {HMER} can reduce 74.5\%-93.4\% mutation execution cost while keeping almost the same fault localization accuracy with the original {MBFL}. A further Wilcoxonsigned−ranktest indicates that when employing {HMER} strategy in {MBFL}, the fault localization accuracy has no statistically significant difference in most cases compared with the original {MBFL} without any reduction techniques.},
	pages = {110661},
	journaltitle = {Journal of Systems and Software},
	author = {Li, Zheng and Wang, Haifeng and Liu, Yong},
	date = {2020},
	keywords = {Cost reduction, Mutant sampling, Mutation-based Fault Localization, Spectrum-based Fault Localization, xno}
}

@article{laradji_software_2015,
	title = {Software defect prediction using ensemble learning on selected features},
	volume = {58},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584914001591},
	doi = {https://doi.org/10.1016/j.infsof.2014.07.005},
	abstract = {Context Several issues hinder software defect data including redundancy, correlation, feature irrelevance and missing samples. It is also hard to ensure balanced distribution between data pertaining to defective and non-defective software. In most experimental cases, data related to the latter software class is dominantly present in the dataset. Objective The objectives of this paper are to demonstrate the positive effects of combining feature selection and ensemble learning on the performance of defect classification. Along with efficient feature selection, a new two-variant (with and without feature selection) ensemble learning algorithm is proposed to provide robustness to both data imbalance and feature redundancy. Method We carefully combine selected ensemble learning models with efficient feature selection to address these issues and mitigate their effects on the defect classification performance. Results Forward selection showed that only few features contribute to high area under the receiver-operating curve ({AUC}). On the tested datasets, greedy forward selection ({GFS}) method outperformed other feature selection techniques such as Pearson’s correlation. This suggests that features are highly unstable. However, ensemble learners like random forests and the proposed algorithm, average probability ensemble ({APE}), are not as affected by poor features as in the case of weighted support vector machines (W-{SVMs}). Moreover, the {APE} model combined with greedy forward selection (enhanced {APE}) achieved {AUC} values of approximately 1.0 for the {NASA} datasets: {PC}2, {PC}4, and {MC}1. Conclusion This paper shows that features of a software dataset must be carefully selected for accurate classification of defective components. Furthermore, tackling the software data issues, mentioned above, with the proposed combined learning model resulted in remarkable classification performance paving the way for successful quality control.},
	pages = {388--402},
	journaltitle = {Information and Software Technology},
	author = {Laradji, Issam H. and Alshayeb, Mohammad and Ghouti, Lahouari},
	date = {2015},
	keywords = {Software quality, Defect prediction, Ensemble learning, Feature selection, Data imbalance, Feature redundancy/correlation, xno}
}

@incollection{memon_chapter_2019,
	title = {Chapter Six - Mutation Testing Advances: An Analysis and Survey},
	volume = {112},
	url = {https://www.sciencedirect.com/science/article/pii/S0065245818300305},
	series = {Advances in Computers},
	abstract = {Mutation testing realizes the idea of using artificial defects to support testing activities. Mutation is typically used as a way to evaluate the adequacy of test suites, to guide the generation of test cases, and to support experimentation. Mutation has reached a maturity phase and gradually gains popularity both in academia and in industry. This chapter presents a survey of recent advances, over the past decade, related to the fundamental problems of mutation testing and sets out the challenges and open problems for the future development of the method. It also collects advices on best practices related to the use of mutation in empirical studies of software testing. Thus, giving the reader a “mini-handbook”-style roadmap for the application of mutation testing as experimental methodology.},
	pages = {275--378},
	publisher = {Elsevier},
	author = {Papadakis, Mike and Kintis, Marinos and Zhang, Jie and Jia, Yue and Traon, Yves Le and Harman, Mark},
	editor = {Memon, Atif M.},
	date = {2019},
	doi = {https://doi.org/10.1016/bs.adcom.2018.03.015},
	note = {{ISSN}: 0065-2458},
	keywords = {Software testing, Mutation testing, Seeded faults, Survey, xno}
}

@article{silveira_scenario_2016,
	title = {Scenario preprocessing approach for the reconfiguration of fault-tolerant {NoC}-based {MPSoCs}},
	volume = {40},
	issn = {0141-9331},
	url = {https://www.sciencedirect.com/science/article/pii/S0141933115001180},
	doi = {https://doi.org/10.1016/j.micpro.2015.08.005},
	abstract = {The latest technologies of integrated circuit manufacturing allow billions of transistors to be arranged on a single chip, enabling the chip to implement a complex parallel system, which requires a communications architecture that has high scalability and a high degree of parallelism, such as a Network-on-Chip ({NoC}). These technologies are very close to the physical limitations, which increases the faults in manufacturing and at runtime. Therefore, it is essential to provide a method for fault recovery that would enable the {NoC} to operate in the presence of faults and still ensure deadlock-free routing. The preprocessing of the most probable fault scenarios enables us to anticipate the calculation of deadlock-free routings, reducing the time that is necessary to interrupt the system during a fault occurrence. This work proposes a technique that employs the preprocessing of fault scenarios based on forecasting fault tendencies, which is performed with a fault threshold circuit operating in accordance with high-level software. We propose methods for dissimilarity analysis of scenarios based on cross-correlation measurements of link fault matrices. Experimental results employing {RTL} simulation with synthetic traffic prove the quality of the analytic metrics that are used to select the preprocessed scenarios. Furthermore, the experiments show the efficacy and efficiency of the proposed dissimilarity methods, quantifying the latency penalization when using the coverage scenarios approach.},
	pages = {137--153},
	journaltitle = {Microprocessors and Microsystems},
	author = {Silveira, Jarbas and Marcon, César and Cortez, Paulo and Barroso, Giovanni and Ferreira, João M. and Mota, Rafael},
	date = {2016},
	keywords = {Fault-tolerance, Irregular topology, {NoC}, Preprocessing, Routing methods, xno}
}

@article{dallal_constructing_2012,
	title = {Constructing models for predicting extract subclass refactoring opportunities using object-oriented quality metrics},
	volume = {54},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584912000754},
	doi = {https://doi.org/10.1016/j.infsof.2012.04.004},
	abstract = {Context Refactoring is a maintenance task that refers to the process of restructuring software source code to enhance its quality without affecting its external behavior. Inspecting and analyzing the source code of the system under consideration to identify the classes in need of extract subclass refactoring ({ESR}) is a time consuming and costly process. Objective This paper explores the abilities of several quality metrics considered individually and in combination to predict the classes in need of {ESR}. Method For a given a class, this paper empirically investigates, using univariate logistic regression analysis, the abilities of 25 existing size, cohesion, and coupling metrics to predict whether the class is in need of restructuring by extracting a subclass from it. In addition, models of combined metrics based on multivariate logistic regression analysis were constructed and validated to predict the classes in need of {ESR}, and the best model is justifiably recommended. We explored the statistical relations between the values of the selected metrics and the decisions of the developers of six open source Java systems with respect to whether the classes require {ESR}. Results The results indicate that there was a strong statistical relation between some of the quality metrics and the decision of whether {ESR} activity was required. From a statistical point of view, the recommended model of metrics has practical thresholds that lead to an outstanding classification of the classes into those that require {ESR} and those that do not. Conclusion The proposed model can be applied to automatically predict the classes in need of {ESR} and present them as suggestions to developers working to enhance the system during the maintenance phase. In addition, the model is capable of ranking the classes of the system under consideration according to their degree of need of {ESR}.},
	pages = {1125--1141},
	number = {10},
	journaltitle = {Information and Software Technology},
	author = {Dallal, Jehad Al},
	date = {2012},
	keywords = {Logistic regression analysis, Class cohesion, Class coupling, Class quality, Extract subclass refactoring, Object-oriented design, xno}
}

@article{malavolta_mining_2021,
	title = {Mining guidelines for architecting robotics software},
	volume = {178},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121221000662},
	doi = {https://doi.org/10.1016/j.jss.2021.110969},
	abstract = {Context: The Robot Operating System ({ROS}) is the de-facto standard for robotics software. However, {ROS}-based systems are getting larger and more complex and could benefit from good software architecture practices. Goal: We aim at (i) unveiling the state-of-the-practice in terms of targeted quality attributes and architecture documentation in {ROS}-based systems, and (ii) providing empirically-grounded guidance to roboticists about how to properly architect {ROS}-based systems. Methods: We designed and conducted an observational study where we (i) built a dataset of 335 {GitHub} repositories containing real open-source {ROS}-based systems, and (ii) mined the repositories to extract and synthesize quantitative and qualitative findings about how roboticists are architecting {ROS}-based systems. Results: First, we extracted an empirically-grounded overview of the state of the practice for architecting and documenting {ROS}-based systems. Second, we synthesized a catalog of 47 architecting guidelines for {ROS}-based systems. Third, the extracted guidelines were validated by 119 roboticists working on real-world open-source {ROS}-based systems. Conclusion: Roboticists can use our architecting guidelines for applying good design principles to develop robots that meet quality requirements, and researchers can use our results as evidence-based indications about how real-world {ROS} systems are architected today, thus inspiring future research contributions.},
	pages = {110969},
	journaltitle = {Journal of Systems and Software},
	author = {Malavolta, Ivano and Lewis, Grace A. and Schmerl, Bradley and Lago, Patricia and Garlan, David},
	date = {2021},
	keywords = {Software architecture, Robotics, {ROS}, xno}
}

@article{bansal_empirical_2017,
	title = {Empirical analysis of search based algorithms to identify change prone classes of open source software},
	volume = {47},
	issn = {1477-8424},
	url = {https://www.sciencedirect.com/science/article/pii/S1477842416301397},
	doi = {https://doi.org/10.1016/j.cl.2016.10.001},
	abstract = {There are numerous reasons leading to change in software such as changing requirements, changing technology, increasing customer demands, fixing of defects etc. Thus, identifying and analyzing the change-prone classes of the software during software evolution is gaining wide importance in the field of software engineering. This would help software developers to judiciously allocate the resources used for testing and maintenance. Software metrics can be used for constructing various classification models which can be used for timely identification of change prone classes. Search based algorithms which form a subset of machine learning algorithms can be utilized for constructing prediction models to identify change prone classes of software. Search based algorithms use a fitness function to find the best optimal solution among all the possible solutions. In this work, we analyze the effectiveness of hybridized search based algorithms for change prediction. In other words, the aim of this work is to find whether search based algorithms are capable for accurate model construction to predict change prone classes. We have also constructed models using machine learning techniques and compared the performance of these models with the models constructed using Search Based Algorithms. The validation is carried out on two open source Apache projects, Rave and Commons Math. The results prove the effectiveness of hybridized search based algorithms in predicting change prone classes of software. Thus, they can be utilized by the software developers to produce an efficient and better developed software.},
	pages = {211--231},
	journaltitle = {Computer Languages, Systems \& Structures},
	author = {Bansal, Ankita},
	date = {2017},
	keywords = {Software quality, Change proneness, Empirical validation, Metrics, Object oriented paradigm, Search based algorithms, xno}
}

@article{qiu_understanding_2017,
	title = {Understanding the syntactic rule usage in java},
	volume = {123},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121216302126},
	doi = {https://doi.org/10.1016/j.jss.2016.10.017},
	abstract = {Context: Syntax is fundamental to any programming language: syntax defines valid programs. In the 1970s, computer scientists rigorously and empirically studied programming languages to guide and inform language design. Since then, language design has been artistic, driven by the aesthetic concerns and intuitions of language architects. Despite recent studies on small sets of selected language features, we lack a comprehensive, quantitative, empirical analysis of how modern, real-world source code exercises the syntax of its programming language. Objective: This study aims to understand how programming language syntax is employed in actual development and explore their potential applications based on the results of syntax usage analysis. Method: We present our results on the first such study on Java, a modern, mature, and widely-used programming language. Our corpus contains over 5000 open-source Java projects, totalling 150 million source lines of code ({SLoC}). We study both independent (i.e. applications of a single syntax rule) and dependent (i.e. applications of multiple syntax rules) rule usage, and quantify their impact over time and project size. Results: Our study provides detailed quantitative information and yields insight, particularly (i) confirming the conventional wisdom that the usage of syntax rules is Zipfian; (ii) showing that the adoption of new rules and their impact on the usage of pre-existing rules vary significantly over time; and (iii) showing that rule usage is highly contextual. Conclusions: Our findings suggest potential applications across language design, code suggestion and completion, automatic syntactic sugaring, and language restriction.},
	pages = {160--172},
	journaltitle = {Journal of Systems and Software},
	author = {Qiu, Dong and Li, Bixin and Barr, Earl T. and Su, Zhendong},
	date = {2017},
	keywords = {Empirical study, Language syntax, Practical language usage, xyes}
}

@article{castro-leon_fault_2015,
	title = {Fault tolerance at system level based on {RADIC} architecture},
	volume = {86},
	issn = {0743-7315},
	url = {https://www.sciencedirect.com/science/article/pii/S0743731515001434},
	doi = {https://doi.org/10.1016/j.jpdc.2015.08.005},
	abstract = {The increasing failure rate in High Performance Computing encourages the investigation of fault tolerance mechanisms to guarantee the execution of an application in spite of node faults. This paper presents an automatic and scalable fault tolerant model designed to be transparent for applications and for message passing libraries. The model consists of detecting failures in the communication socket caused by a faulty node. In those cases, the affected processes are recovered in a healthy node and the connections are reestablished without losing data. The Redundant Array of Distributed Independent Controllers architecture proposes a decentralized model for all the tasks required in a fault tolerance system: protection, detection, recovery and masking. Decentralized algorithms allow the application to scale, which is a key property for current {HPC} system. Three different rollback recovery protocols are defined and discussed with the aim of offering alternatives to reduce overhead when multicore systems are used. A prototype has been implemented to carry out an exhaustive experimental evaluation through Master/Worker and Single Program Multiple Data execution models. Multiple workloads and an increasing number of processes have been taken into account to compare the above mentioned protocols. The executions take place in two multicore Linux clusters with different socket communications libraries.},
	pages = {98--111},
	journaltitle = {Journal of Parallel and Distributed Computing},
	author = {Castro-León, Marcela and Meyer, Hugo and Rexachs, Dolores and Luque, Emilio},
	date = {2015},
	keywords = {Resilience, Message passing, {RADIC}, Semi-coordinated checkpoint, Socket, Software fault tolerance, Uncoordinated checkpoint, xno}
}

@article{meng_detecting_2021,
	title = {Detecting anomalies in microservices with execution trace comparison},
	volume = {116},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X20330247},
	doi = {https://doi.org/10.1016/j.future.2020.10.040},
	abstract = {More and more developers and companies have adopted the concept of microservice. Detecting anomalies and locating root causes are important for improving the reliability of microservices. Current approaches typically monitor the metrics of physical resources, and manually set alarm rules. However, they often require domain knowledge to detect anomalies, and cannot locate faulty microservices causing the anomalies accurately. To address the above issues, we propose an anomaly detection approach for microservice application by comparing execution traces. First, we use dynamic instrumentations to collect execution traces across microservices, and then use call trees to describe an application’s execution traces. Then, we calculate the anomaly degree of traces with tree edit distance to detect structural anomalies, and then analyze the difference between traces to locate the components causing the anomalies. Third, we locate suspicious component calls causing the response time fluctuation with principal component analysis to detect response time anomalies. Finally, we have evaluated the approach with a {TPC}-W based benchmark called as Bench4Q and a typical microservice-based application called as Social Network. The results demonstrate that the approach achieves 81\%–97\% precision and 75\%–99\% recall in detecting anomalies caused by injected {CPU}, network, memory and service faults.},
	pages = {291--301},
	journaltitle = {Future Generation Computer Systems},
	author = {Meng, Lun and Ji, Feng and Sun, Yao and Wang, Tao},
	date = {2021},
	keywords = {Software reliability, Anomaly detection, Microservices, Performance anomaly, xno}
}

@article{lenarduzzi_does_2021,
	title = {Does code quality affect pull request acceptance? An empirical study},
	volume = {171},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220302090},
	doi = {https://doi.org/10.1016/j.jss.2020.110806},
	abstract = {Background Pull requests are a common practice for making contributions and reviewing them in both open-source and industrial contexts. Objective Our goal is to understand whether quality flaws such as code smells, anti-patterns, security vulnerabilities, and coding style violations in a pull request’s code affect the chance of its acceptance when reviewed by a maintainer of the project. Method We conducted a case study among 28 Java open-source projects, analyzing the presence of 4.7 M code quality flaws in 36 K pull requests. We analyzed further correlations by applying logistic regression and six machine learning techniques. Moreover, we manually validated 10\% of the pull requests to get further qualitative insights on the importance of quality issues in cases of acceptance and rejection. Results Unexpectedly, quality flaws measured by {PMD} turned out not to affect the acceptance of a pull request at all. As suggested by other works, other factors such as the reputation of the maintainer and the importance of the delivered feature might be more important than other qualities in terms of pull request acceptance. Conclusions . Researchers have already investigated the influence of the developers’ reputation and the pull request acceptance. This is the first work investigating code style violations and specifically {PMD} rules. We recommend that researchers further investigate this topic to understand if different measures or different tools could provide some useful measures.},
	pages = {110806},
	journaltitle = {Journal of Systems and Software},
	author = {Lenarduzzi, Valentina and Nikkola, Vili and Saarimäki, Nyyti and Taibi, Davide},
	date = {2021},
	keywords = {Machine learning, {PMD} rules, Pull requests, xno}
}

@article{lui_generalized_2021,
	title = {A generalized approach to real-time, non-intrusive instrumentation and monitoring of standards-based distributed middleware},
	volume = {117},
	issn = {1383-7621},
	url = {https://www.sciencedirect.com/science/article/pii/S1383762121001296},
	doi = {https://doi.org/10.1016/j.sysarc.2021.102181},
	abstract = {Dynamic Binary Instrumentation ({DBI}) is one way to monitor a distributed system in real-time without modifying application source code. Previous work has shown it is possible to instrument distributed systems using standards-based distributed middleware. Existing work, however, only applies to a single middleware, such as {CORBA}. This article therefore presents a tool named the Standards-based Distributed Middleware Monitor ({SDMM}), which generalizes two modern standards-based distributed middleware, the Data Distribution Service ({DDS}) and {gRemote} Procedure Call ({gRPC}). {SDMM} uses {DBI} to extract values and other data relevant to monitoring a distributed system in real-time. Using dynamic instrumentation allows {SDMM} to capture information without a priori knowledge of the distributed application under instrumentation. We applied {SDMM} to applications written with two {DDS} vendors, {RTI} Connext {DDS} and {OpenDDS}, as well as {gRPC} which is a complete remote procedure call framework. Our results show that the data collection process contributes to less than 1\% of the performance overhead in some tests.},
	pages = {102181},
	journaltitle = {Journal of Systems Architecture},
	author = {Lui, Nyalia and Hill, James H.},
	date = {2021},
	keywords = {Data Distribution Service, Distributed middleware, Dynamic binary instrumentation, {gRPC}, Pin++, xno}
}

@article{valdivia-garcia_characterizing_2018,
	title = {Characterizing and predicting blocking bugs in open source projects},
	volume = {143},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218300530},
	doi = {https://doi.org/10.1016/j.jss.2018.03.053},
	abstract = {Software engineering researchers have studied specific types of issues such reopened bugs, performance bugs, dormant bugs, etc. However, one special type of severe bugs is blocking bugs. Blocking bugs are software bugs that prevent other bugs from being fixed. These bugs may increase maintenance costs, reduce overall quality and delay the release of the software systems. In this paper, we study blocking bugs in eight open source projects and propose a model to predict them early on. We extract 14 different factors (from the bug repositories) that are made available within 24 hours after the initial submission of the bug reports. Then, we build decision trees to predict whether a bug will be a blocking bugs or not. Our results show that our prediction models achieve F-measures of 21\%–54\%, which is a two-fold improvement over the baseline predictors. We also analyze the fixes of these blocking bugs to understand their negative impact. We find that fixing blocking bugs requires more lines of code to be touched compared to non-blocking bugs. In addition, our file-level analysis shows that files affected by blocking bugs are more negatively impacted in terms of cohesion, coupling complexity and size than files affected by non-blocking bugs.},
	pages = {44--58},
	journaltitle = {Journal of Systems and Software},
	author = {Valdivia-Garcia, Harold and Shihab, Emad and Nagappan, Meiyappan},
	date = {2018},
	keywords = {Code metrics, Post-release defects, Process metrics, xno}
}

@article{feitosa_what_2019,
	title = {What can violations of good practices tell about the relationship between {GoF} patterns and run-time quality attributes?},
	volume = {105},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918301617},
	doi = {https://doi.org/10.1016/j.infsof.2018.07.014},
	abstract = {Context {GoF} patterns have been extensively studied with respect to the benefit they provide as problem-solving, communication and quality improvement mechanisms. The latter has been mostly investigated through empirical studies, but some aspects of quality (esp. run-time ones) are still under-investigated. Objective In this paper, we study if the presence of patterns enforces the conformance to good coding practices. To achieve this goal, we explore the relationship between the presence of {GoF} design patterns and violations of good practices related to source code correctness, performance and security, via static analysis. Method Specifically, we exploit static analysis so as to investigate whether the number of violations of good coding practices identified on classes is related to: (a) their participation in pattern occurrences, (b) the pattern category, (c) the pattern in which they participate, and (d) their role within the pattern occurrence. To answer these questions, we performed a case study on approximately 13,000 classes retrieved from five open-source projects. Results The obtained results suggest that classes not participating in patterns are more probable to violate good coding practices for correctness, performance and security. In a more fine-grained level of analysis, by focusing on specific patterns, we observed that patterns with more complex structure (e.g., Decorator) and pattern roles that are more change-prone (e.g., Subclasses) are more likely to be associated with a higher number of violations (up to 50 times more violations). Conclusion This finding implies that investing in a well-thought architecture based on best practices, such as patterns, is often accompanied with cleaner code with fewer violations.},
	pages = {1--16},
	journaltitle = {Information and Software Technology},
	author = {Feitosa, Daniel and Ampatzoglou, Apostolos and Avgeriou, Paris and Chatzigeorgiou, Alexander and Nakagawa, Elisa Y.},
	date = {2019},
	keywords = {Software architecture, Design, Evaluation, {GoF} patterns, Quality analysis, xno}
}

@article{gorbenko_fault_2019,
	title = {Fault tolerant internet computing: Benchmarking and modelling trade-offs between availability, latency and consistency},
	volume = {146},
	issn = {1084-8045},
	url = {https://www.sciencedirect.com/science/article/pii/S1084804519302462},
	doi = {https://doi.org/10.1016/j.jnca.2019.102412},
	abstract = {The paper discusses our practical experience and theoretical results of investigating the impact of consistency on latency in distributed fault tolerant systems built over the Internet and clouds. We introduce a time-probabilistic failure model of distributed systems that employ the service-oriented paradigm for defining cooperation with clients over the Internet and clouds. The trade-offs between consistency, availability and latency are examined, as well as the role of the application timeout as the main determinant in the interplay between system availability and responsiveness. The model introduced heavily relies on collecting and analysing a large amount of data representing the probabilistic behaviour of such systems. The paper presents experimental results of measuring the response time in a distributed service-oriented system whose replicas are deployed at different Amazon {EC}2 location domains. These results clearly show that improvements in system consistency increase system latency, which is in line with the qualitative implication of the well-known {CAP} theorem. The paper proposes a set of novel mathematical models that are based on statistical analysis of collected data and enable quantified response time prediction depending on the timeout setup and on the level of consistency provided by the replicated system.},
	pages = {102412},
	journaltitle = {Journal of Network and Computer Applications},
	author = {Gorbenko, Anatoliy and Romanovsky, Alexander and Tarasyuk, Olga},
	date = {2019},
	keywords = {Fault tolerance, Cloud computing, Availability, Consistency, Distributed applications, Internet computing, Latency, Modelling techniques, Service-oriented systems, Trade-off, xno}
}

@article{carvalho_implementation_2018,
	title = {On the implementation of dynamic software product lines: An exploratory study},
	volume = {136},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217302601},
	doi = {https://doi.org/10.1016/j.jss.2017.11.004},
	abstract = {Dynamic Software Product Line ({DSPL}) engineering is a paradigm aimed at handling adaptations at runtime. An inherent challenge in {DSPL} engineering is to reduce the design complexity of adaptable software, particularly in terms of evolution. Existing research only recently started to investigate evolution in this field, but does not assess the impact of different implementations under software quality in evolutionary scenarios. This work presents a characterization of thirteen dynamic variability mechanisms. Based on such characterization, we implemented a {DSPL} using Object-oriented Programming ({OOP}) mechanisms. From this implementation, we evidenced that {DSPL} requires changes and extensions to design, in terms of functionality and adaptation capabilities. Since Aspect-oriented Programming ({AOP}) was well ranked according to characterization and some studies have demonstrated the likely synergies between {AOP} and {DSPL}, we decided to compare it with {OOP}. We empirically evaluated how {OOP} and {AOP} could affect source code quality from the viewpoint of an evolving {DSPL}. As a result, {AOP} yields better results in terms of size, {SoC}, cohesion, and coupling measures. Conversely, {AOP} provides lower change propagation impact. Although the packages in {AOP} were more susceptible to changes than in {OOP}, we could indicate that {AOP} may be a feasible strategy for {DSPL} implementation.},
	pages = {74--100},
	journaltitle = {Journal of Systems and Software},
	author = {Carvalho, Michelle Larissa Luciano and Silva, Matheus Lessa Gonçalves da and Gomes, Gecynalda Soares da Silva and Santos, Alcemir Rodrigues and Machado, Ivan do Carmo and Souza, Magno Luã de Jesus and Almeida, Eduardo Santana de},
	date = {2018},
	keywords = {Software evolution, Dynamic software product lines, Evidence-based software engineering, Variability mechanisms, xno}
}

@article{zhu_how_2021,
	title = {How to kill them all: An exploratory study on the impact of code observability on mutation testing},
	volume = {173},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220302545},
	doi = {https://doi.org/10.1016/j.jss.2020.110864},
	abstract = {Mutation testing is well-known for its efficacy in assessing test quality, and starting to be applied in the industry. However, what should a developer do when confronted with a low mutation score? Should the test suite be plainly reinforced to increase the mutation score, or should the production code be improved as well, to make the creation of better tests possible? In this paper, we aim to provide a new perspective to developers that enables them to understand and reason about the mutation score in the light of testability and observability. First, we investigate whether testability and observability metrics are correlated with the mutation score on six open-source Java projects. We observe a correlation between observability metrics and the mutation score, e.g., test directness, which measures the extent to which the production code is tested directly, seems to be an essential factor. Based on our insights from the correlation study, we propose a number of ”mutation score anti-patterns”, enabling software engineers to refactor their existing code or add tests to improve the mutation score. In doing so, we observe that relatively simple refactoring operations enable an improvement or increase in the mutation score.},
	pages = {110864},
	journaltitle = {Journal of Systems and Software},
	author = {Zhu, Qianqian and Zaidman, Andy and Panichella, Annibale},
	date = {2021},
	keywords = {Testability, Code quality, Code refactoring, Mutation testing, Observability, xno}
}

@article{pecorelli_adaptive_2021,
	title = {Adaptive selection of classifiers for bug prediction: A large-scale empirical analysis of its performances and a benchmark study},
	volume = {205},
	issn = {0167-6423},
	url = {https://www.sciencedirect.com/science/article/pii/S0167642321000046},
	doi = {https://doi.org/10.1016/j.scico.2021.102611},
	abstract = {Bug prediction aims at locating defective source code components relying on machine learning models. Although some previous work showed that selecting the machine-learning classifier is crucial, the results are contrasting. Therefore, several ensemble techniques, i.e., approaches able to mix the output of different classifiers, have been proposed. In this paper, we present a benchmark study in which we compare the performance of seven ensemble techniques on 21 open-source software projects. Our aim is twofold. On the one hand, we aim at bridging the limitations of previous empirical studies that compared the accuracy of ensemble approaches in bug prediction. On the other hand, our goal is to verify how ensemble techniques perform in different settings such as cross- and local-project defect prediction. Our empirical experimentation results show that ensemble techniques are not a silver bullet for bug prediction. In within-project bug prediction, using ensemble techniques improves the prediction performance with respect to the best stand-alone classifier. We confirm that the models based on Validation and Voting achieve slightly better results. However, they are similar to those obtained by other ensemble techniques. Identifying buggy classes using external sources of information is still an open problem. In this setting, the use of ensemble techniques does not provide evident benefits with respect to stand-alone classifiers. The statistical analysis highlights that local and global models are mostly equivalent in terms of performance. Only one ensemble technique (i.e., {ASCI}) slightly exploits local learning to improve performance.},
	pages = {102611},
	journaltitle = {Science of Computer Programming},
	author = {Pecorelli, Fabiano and Nucci, Dario Di},
	date = {2021},
	keywords = {Bug prediction, Cross-project, Ensemble classifiers, Within-project, xno}
}

@article{braiek_testing_2020,
	title = {On testing machine learning programs},
	volume = {164},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220300248},
	doi = {https://doi.org/10.1016/j.jss.2020.110542},
	abstract = {Nowadays, we are witnessing a wide adoption of Machine learning ({ML}) models in many software systems. They are even being tested in safety-critical systems, thanks to recent breakthroughs in deep learning and reinforcement learning. Many people are now interacting with systems based on {ML} every day, e.g., voice recognition systems used by virtual personal assistants like Amazon Alexa or Google Home. As the field of {ML} continues to grow, we are likely to witness transformative advances in a wide range of areas, from finance, energy, to health and transportation. Given this growing importance of {ML}-based systems in our daily life, it is becoming utterly important to ensure their reliability. Recently, software researchers have started adapting concepts from the software testing domain (e.g., code coverage, mutation testing, or property-based testing) to help {ML} engineers detect and correct faults in {ML} programs. This paper reviews current existing testing practices for {ML} programs. First, we identify and explain challenges that should be addressed when testing {ML} programs. Next, we report existing solutions found in the literature for testing {ML} programs. Finally, we identify gaps in the literature related to the testing of {ML} programs and make recommendations of future research directions for the scientific community. We hope that this comprehensive review of software testing practices will help {ML} engineers identify the right approach to improve the reliability of their {ML}-based systems. We also hope that the research community will act on our proposed research directions to advance the state of the art of testing for {ML} programs.},
	pages = {110542},
	journaltitle = {Journal of Systems and Software},
	author = {Braiek, Houssem Ben and Khomh, Foutse},
	date = {2020},
	keywords = {Machine learning, Data cleaning, Feature engineering testing, Implementation testing, Model testing, xno}
}

@article{garcia-floriano_support_2018,
	title = {Support vector regression for predicting software enhancement effort},
	volume = {97},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917302902},
	doi = {https://doi.org/10.1016/j.infsof.2018.01.003},
	abstract = {Context Software maintenance ({SM}) has to be planned, which involves {SM} effort prediction. One type of {SM} is enhancement, where new functionality is added or existing functionality changed or deleted. Objective Analyze the prediction accuracy of two types of support vector regression (ε-{SVR} and ʋ-{SVR}) when applied to predict software enhancement effort. Method Both types of support vector regression used linear, polynomial, radial basis function, and sigmoid kernels. Prediction accuracies for ε-{SVR} and ʋ-{SVR} were compared with those of statistical regressions, neural networks, association rules, and decision trees. The models were trained and tested with five data sets of enhancement projects from Release 11 of the International Software Benchmarking Standards Group ({ISBSG}). Each data set was selected on the basis of data quality, development platform, programming language generation, and levels of effort recording. Results The polynomial kernel ε-{SVR} ({PKε}-{SVR}) was statistically better than statistical regression, neural networks, association rules and decision trees, with 95\% confidence. Conclusions A {PKε}-{SVR} could be used for predicting software enhancement effort in mainframe platforms and coded in a third-generation programming languages, and when enhancement effort recording includes the efforts of the development team, its support personnel, the computer operations involvement, and end users.},
	pages = {99--109},
	journaltitle = {Information and Software Technology},
	author = {García-Floriano, Andrés and López-Martín, Cuauhtémoc and Yáñez-Márquez, Cornelio and Abran, Alain},
	date = {2018},
	keywords = {Decision trees, Association rules, Statistical regression, Support vector regression, Neural networks, {ISBSG}, Software enhancement effort prediction, Support vector machine, xno}
}

@article{xie_testing_2011,
	title = {Testing and validating machine learning classifiers by metamorphic testing},
	volume = {84},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121210003213},
	doi = {https://doi.org/10.1016/j.jss.2010.11.920},
	abstract = {Abstract Machine learning algorithms have provided core functionality to many application domains – such as bioinformatics, computational linguistics, etc. However, it is difficult to detect faults in such applications because often there is no “test oracle” to verify the correctness of the computed outputs. To help address the software quality, in this paper we present a technique for testing the implementations of machine learning classification algorithms which support such applications. Our approach is based on the technique “metamorphic testing”, which has been shown to be effective to alleviate the oracle problem. Also presented include a case study on a real-world machine learning application framework, and a discussion of how programmers implementing machine learning algorithms can avoid the common pitfalls discovered in our study. We also conduct mutation analysis and cross-validation, which reveal that our method has high effectiveness in killing mutants, and that observing expected cross-validation result alone is not sufficiently effective to detect faults in a supervised classification program. The effectiveness of metamorphic testing is further confirmed by the detection of real faults in a popular open-source classification program.},
	pages = {544--558},
	number = {4},
	journaltitle = {Journal of Systems and Software},
	author = {Xie, Xiaoyuan and Ho, Joshua W. K. and Murphy, Christian and Kaiser, Gail and Xu, Baowen and Chen, Tsong Yueh},
	date = {2011},
	keywords = {Machine learning, Verification, Metamorphic testing, Oracle problem, Test oracle, Validation, xno}
}

@article{malhotra_dynamic_2019,
	title = {Dynamic selection of fitness function for software change prediction using Particle Swarm Optimization},
	volume = {112},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584919300904},
	doi = {https://doi.org/10.1016/j.infsof.2019.04.007},
	abstract = {Context Over the past few years, researchers have been actively searching for an effective classifier which correctly predicts change prone classes. Though, few researchers have ascertained the predictive capability of search-based algorithms in this domain, their effectiveness is highly dependent on the selection of an optimum fitness function. The criteria for selecting one fitness function over the other is the improved predictive capability of the developed model on the entire dataset. However, it may be the case that various subsets of instances of a dataset may give best results with a different fitness function. Objective The aim of this study is to choose the best fitness function for each instance rather than the entire dataset so as to create models which correctly ascertain the change prone nature of majority of instances. Therefore, we propose a novel framework for the adaptive selection of a dynamic optimum fitness function for each instance of the dataset, which would correctly determine its change prone nature. Method The predictive models in this study are developed using seven different fitness variants of Particle Swarm Optimization ({PSO}) algorithm. The proposed framework predicts the best suited fitness variant amongst the seven investigated fitness variants on the basis of structural characteristics of a corresponding instance. Results The results of the study are empirically validated on fifteen datasets collected from popular open-source software. The proposed adaptive framework was found efficient in determination of change prone classes as it yielded improved results when compared with models developed using individual fitness variants and fitness-based voting ensemble classifiers. Conclusion The performance of the models developed using the proposed adaptive framework were statistically better than the models developed using individual fitness variants of {PSO} algorithm and competent to models developed using machine learning ensemble classifiers.},
	pages = {51--67},
	journaltitle = {Information and Software Technology},
	author = {Malhotra, Ruchika and Khanna, Megha},
	date = {2019},
	keywords = {Change proneness, Empirical validation, Fitness function, Particle Swarm Optimization, xno}
}

@article{dallal_impact_2012,
	title = {The impact of accounting for special methods in the measurement of object-oriented class cohesion on refactoring and fault prediction activities},
	volume = {85},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121211003001},
	doi = {https://doi.org/10.1016/j.jss.2011.12.006},
	abstract = {Class cohesion is a key attribute that is used to assess the design quality of a class, and it refers to the extent to which the attributes and methods of the class are related. Typically, classes contain special types of methods, such as constructors, destructors, and access methods. Each of these special methods has its own characteristics, which can artificially affect the class cohesion measurement. Several metrics have been proposed in the literature to indicate class cohesion during high- or low-level design phases. The impact of accounting for special methods in cohesion measurement has not been addressed for most of these metrics. This paper empirically explores the impact of including or excluding special methods on cohesion measurements that were performed using 20 existing class cohesion metrics. The empirical study applies the metrics that were considered to five open-source systems under four different scenarios, including (1) considering all special methods, (2) ignoring only constructors, (3) ignoring only access methods, and (4) ignoring all special methods. This study empirically explores the impact of including special methods in cohesion measurement for two applications of interest to software practitioners, including refactoring and predicting faulty classes. The results of the empirical studies show that the cohesion values for most of the metrics considered differ significantly across the four scenarios and that this difference significantly affects the refactoring decisions, but does not significantly affect the abilities of the metrics to predict faulty classes.},
	pages = {1042--1057},
	number = {5},
	journaltitle = {Journal of Systems and Software},
	author = {Dallal, Jehad Al},
	date = {2012},
	keywords = {Fault prediction, Refactoring, Class cohesion, Class quality, Object-oriented design, Cohesion metric, Special methods, xno}
}

@article{morales_use_2017,
	title = {On the use of developers’ context for automatic refactoring of software anti-patterns},
	volume = {128},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121216300632},
	doi = {https://doi.org/10.1016/j.jss.2016.05.042},
	abstract = {Anti-patterns are poor solutions to design problems that make software systems hard to understand and extend. Entities involved in anti-patterns are reported to be consistently related to high change and fault rates. Refactorings, which are behavior preserving changes are often performed to remove anti-patterns from software systems. Developers are advised to interleave refactoring activities with their regular coding tasks to remove anti-patterns, and consequently improve software design quality. However, because the number of anti-patterns in a software system can be very large, and their interactions can require a solution in a set of conflicting objectives, the process of manual refactoring can be overwhelming. To automate this process, previous works have modeled anti-patterns refactoring as a batch process where a program provides a solution for the total number of classes in a system, and the developer has to examine a long list of refactorings, which is not feasible in most situations. Moreover, these proposed solutions often require that developers modify classes on which they never worked before (i.e., classes on which they have little or no knowledge). To improve on these limitations, this paper proposes an automated refactoring approach, {ReCon} (Refactoring approach based on task Context), that leverages information about a developer’s task (i.e., the list of code entities relevant to the developer’s task) and metaheuristics techniques to compute the best sequence of refactorings that affects only entities in the developer’s context. We mine 1705 task contexts (collected using the Eclipse plug-in Mylyn) and 1013 code snapshots from three open-source software projects (Mylyn, {PDE}, Eclipse Platform) to assess the performance of our proposed approach. Results show that {ReCon} can remove more than 50\% of anti-patterns in a software system, using fewer resources than the traditional approaches from the literature.},
	pages = {236--251},
	journaltitle = {Journal of Systems and Software},
	author = {Morales, Rodrigo and Soh, Zéphyrin and Khomh, Foutse and Antoniol, Giuliano and Chicano, Francisco},
	date = {2017},
	keywords = {Anti-patterns, Software maintenance, Automatic refactoring, Interaction traces, Metaheuristics, Task context, xno}
}

@article{hora_automatic_2015,
	title = {Automatic detection of system-specific conventions unknown to developers},
	volume = {109},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121215001727},
	doi = {https://doi.org/10.1016/j.jss.2015.08.007},
	abstract = {In Apache Ant, a convention to improve maintenance was introduced in 2004 stating a new way to close files instead of the Java generic {InputStream}.close(). Yet, six years after its introduction, this convention was still not generally known to the developers. Two existing solutions could help in these cases. First, one can deprecate entities, but, in our example, one can hardly deprecate Java’s method. Second, one can create a system-specific rule to be automatically enforced. In a preceding publication, we showed that system-specific rules are more likely to be noticed by developers than generic ones. However, in practice, developers rarely create specific rules. We therefore propose to free the developers from the need to create rules by automatically detecting such conventions from source code repositories. This is done by mining the change history of the system to discover similar changes being applied over several revisions. The proposed approach is applied to a real-world system, and the extracted rules are validated with the help of experts. The results show that many rules are in fact relevant for the experts.},
	pages = {192--204},
	journaltitle = {Journal of Systems and Software},
	author = {Hora, André and Anquetil, Nicolas and Etien, Anne and Ducasse, Stéphane and Valente, Marco Túlio},
	date = {2015},
	keywords = {Mining software repositories, Software evolution, Automatic coding convention detection, xno}
}

@article{aloraini_empirical_2019,
	title = {An empirical study of security warnings from static application security testing tools},
	volume = {158},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121219302018},
	doi = {https://doi.org/10.1016/j.jss.2019.110427},
	abstract = {The Open Web Application Security Project ({OWASP}) defines Static Application Security Testing ({SAST}) tools as those that can help find security vulnerabilities in the source code or compiled code of software. Such tools detect and classify the vulnerability warnings into one of many types (e.g., input validation and representation). It is well known that these tools produce high numbers of false positive warnings. However, what is not known is if specific types of warnings have a higher predisposition to be false positives or not. Therefore, our goal is to investigate the different types of {SAST}-produced warnings and their evolution over time to determine if one type of warning is more likely to have false positives than others. To achieve our goal, we carry out a large empirical study where we examine 116 large and popular C++ projects using six different state-of-the-art open source and commercial {SAST} tools that detect security vulnerabilities. In order to track a piece of code that has been tagged with a warning, we use a new state of the art framework called cregit+ that traces source code lines across different commits. The results demonstrate the potential of using {SAST} tools as an assessment tool to measure the quality of a product and the possible risks without manually reviewing the warnings. In addition, this work shows that pattern-matching static analysis technique is a very powerful method when combined with other advanced analysis methods.},
	pages = {110427},
	journaltitle = {Journal of Systems and Software},
	author = {Aloraini, Bushra and Nagappan, Meiyappan and German, Daniel M. and Hayashi, Shinpei and Higo, Yoshiki},
	date = {2019},
	keywords = {False positives, Security warnings, Software vulnerability, Static application security testing tools, xno}
}

@article{brotsis_suitability_2021,
	title = {On the suitability of blockchain platforms for {IoT} applications: Architectures, security, privacy, and performance},
	volume = {191},
	issn = {1389-1286},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128621001225},
	doi = {https://doi.org/10.1016/j.comnet.2021.108005},
	abstract = {Blockchain and distributed ledger technologies have received significant interest in various areas beyond the financial sector, with profound applications in the Internet of Things ({IoT}), providing the means for creating truly trustless and secure solutions for {IoT} applications. Taking into account the weak security defences that the majority of {IoT} devices have, it is critical that a blockchain-based solution targeting the {IoT} is not only capable of addressing the many challenges {IoT} is facing, but also does not introduce other defects, e.g. in terms of performance, making its adoption hard to achieve. This paper aims at addressing the above needs by providing a comprehensive and coherent review of the available blockchain solutions to determine their ability to meet the requirements and tackle the challenges of the {IoT}, using the smart home as the reference domain. Key architectural aspects of blockchain solutions, like the platforms’ software and network setups, the consensus protocols used, as well as smart contracts, are examined in terms of their ability to withstand various types of common {IoT} and blockchain attacks, deliver enhanced privacy features, and assure adequate performance levels while processing large amounts of transactions being generated in an {IoT} environment. The analysis carried out identified that the defences currently provided by blockchain platforms are not sufficient to thwart all the prominent attacks against blockchains, with blockchain 1.0 and 2.0 platforms being susceptible to the majority of them. On the other side, privacy related mechanisms are being supported, to varying degrees, by all platforms investigated; however, each of the them tackles specific only privacy aspects, thus rendering the overall privacy evaluation a challenging task which needs to be considered in an ad-hoc basis. If the underlying consensus protocols’ performance and fault tolerance is also considered, then only a small number of platforms meet the requirements of our reference {IoT} domain.},
	pages = {108005},
	journaltitle = {Computer Networks},
	author = {Brotsis, Sotirios and Limniotis, Konstantinos and Bendiab, Gueltoum and Kolokotronis, Nicholas and Shiaeles, Stavros},
	date = {2021},
	keywords = {Internet of things, Blockchain, Fault tolerance, Smart homes, Security, Consensus protocols, Cyber-attacks, Performance, Privacy, Smart contracts, xno}
}

@article{wang_using_2018,
	title = {Using reliability risk analysis to prioritize test cases},
	volume = {139},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218300128},
	doi = {https://doi.org/10.1016/j.jss.2018.01.033},
	abstract = {In this paper, we present a risk-based test case prioritization (Ri-{TCP}) algorithm based on the transmission of information flows among software components. Most of the existing approaches rely on the historical code changes or test case execution data, few of them effectively use the system topology information covered by test cases when scheduling the execution of test cases. From the perspective of code structure, the proposed algorithm firstly maps software into an information flow-based directed network model. Then, functional paths covered by each test case are represented by a set of barbell motifs. Finally, combining with probabilistic risk analysis ({PRA}) and fault tree model, we assign a priority to each test case by calculating the sum of risk indexes of all the barbells covered by it. Experimental results demonstrate that Ri-{TCP} technique has a higher detection rate of faults with serious risk indicators and performs stably in different systems, compared with the other state-of-the-art algorithms.},
	pages = {14--31},
	journaltitle = {Journal of Systems and Software},
	author = {Wang, Ying and Zhu, Zhiliang and Yang, Bo and Guo, Fangda and Yu, Hai},
	date = {2018},
	keywords = {Regression testing, Test case prioritization, Complex network, Information flow, Probabilistic risk analysis, xno}
}

@article{malhotra_empirical_2020,
	title = {An empirical study to investigate the impact of data resampling techniques on the performance of class maintainability prediction models},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S092523122031211X},
	doi = {https://doi.org/10.1016/j.neucom.2020.01.120},
	abstract = {With the increasing complexity of the software systems nowadays, the trend has been shifted to object-oriented ({OO}) development. The classes are the central construct in an {OO} software that are expected to be of utmost quality and high maintainability. The maintainability of a class is the probability that a class can be effortlessly modifiable in the maintenance phase. Unfortunately, it is very tough to determine the maintainability of a class with confidence before the release of the software. However, maintainability can be predicted with the help of internal quality attributes (viz. complexity, cohesion coupling, inheritance, etc.). The researchers in the literature have studied the relation amongst the internal quality attributes and class maintainability. Many class maintainability prediction models have been developed in the past with the help of internal quality attributes. Effective prediction models are vital to forecast class maintainability accurately. However, various datasets used to build prediction models for class maintainability suffer from imbalanced data problem. In that scenario, a model trained with imbalanced data gives erroneous predictions of class maintainability, which results in the inaccurate allocation of testing and maintenance resources to the misclassified classes. Therefore towards this direction, this study assesses the applicability of techniques to take care of imbalanced data. In this study the imbalanced data is treated with nine oversampling and three undersampling methods. A comprehensive comparison of fourteen machine learning ({ML}) techniques and fourteen search based ({SB}) techniques is conducted for class maintainability prediction. The results of the study support the applicability Safe-Level Synthetic Minority Oversampling Technique (Safe-{SMOTE}) to handle the imbalanced data for class maintainability prediction.},
	journaltitle = {Neurocomputing},
	author = {Malhotra, Ruchika and Lata, Kusum},
	date = {2020},
	keywords = {Machine learning techniques, Imbalanced data, Object-oriented metrics, Data resampling techniques, Maintainability prediction, Search-based techniques, xno}
}

@article{karus_code_2012,
	title = {Code churn estimation using organisational and code metrics: An experimental comparison},
	volume = {54},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584911001935},
	doi = {https://doi.org/10.1016/j.infsof.2011.09.004},
	abstract = {Context Source code revision control systems contain vast amounts of data that can be exploited for various purposes. For example, the data can be used as a base for estimating future code maintenance effort in order to plan software maintenance activities. Previous work has extensively studied the use of metrics extracted from object-oriented source code to estimate future coding effort. In comparison, the use of other types of metrics for this purpose has received significantly less attention. Objective This paper applies machine learning techniques to unveil predictors of yearly cumulative code churn of software projects on the basis of metrics extracted from revision control systems. Method The study is based on a collection of object-oriented code metrics, {XML} code metrics, and organisational metrics. Several models are constructed with different subsets of these metrics. The predictive power of these models is analysed based on a dataset extracted from eight open-source projects. Results The study shows that a code churn estimation model built purely with organisational metrics is superior to one built purely with code metrics. However, a combined model provides the highest predictive power. Conclusion The results suggest that code metrics in general, and {XML} metrics in particular, are complementary to organisational metrics for the purpose of estimating code churn.},
	pages = {203--211},
	number = {2},
	journaltitle = {Information and Software Technology},
	author = {Karus, Siim and Dumas, Marlon},
	date = {2012},
	keywords = {{XML}, Code metrics, Software maintenance, Code churn estimation, Organisational metrics, {XSLT}, xno}
}

@article{yu_towards_2012,
	title = {Towards automated debugging in software evolution: Evaluating delta debugging on real regression bugs from the developers’ perspectives},
	volume = {85},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121211002743},
	doi = {https://doi.org/10.1016/j.jss.2011.10.016},
	abstract = {Delta debugging has been proposed to isolate failure-inducing changes when regressions occur. In this work, we focus on evaluating delta debugging in practical settings from developers’ perspectives. A collection of real regressions taken from medium-sized open source programs is used in our evaluation. Towards automated debugging in software evolution, a tool based on delta debugging is created and both the limitations and costs are discussed. We have evaluated two variants of delta debugging. Different from successful isolation in Zeller's initial studies, the results in our experiments vary wildly. Two thirds of isolated changes in studied programs provide direct or indirect clues in locating regression bugs. The remaining results are superfluous changes or even wrong isolations. In the case of wrong isolations, the isolated changes cause the same behaviour of the regression but are failure-irrelevant. Moreover, the hierarchical variant does not yield definite improvements in terms of the efficiency and accuracy.},
	pages = {2305--2317},
	number = {10},
	journaltitle = {Journal of Systems and Software},
	author = {Yu, Kai and Lin, Mengxiang and Chen, Jin and Zhang, Xiangyu},
	date = {2012},
	keywords = {Fault localization, Automated debugging, Delta debugging, Regression bugs, xno}
}

@article{chowdhury_using_2011,
	title = {Using complexity, coupling, and cohesion metrics as early indicators of vulnerabilities},
	volume = {57},
	issn = {1383-7621},
	url = {https://www.sciencedirect.com/science/article/pii/S1383762110000615},
	doi = {https://doi.org/10.1016/j.sysarc.2010.06.003},
	abstract = {Software security failures are common and the problem is growing. A vulnerability is a weakness in the software that, when exploited, causes a security failure. It is difficult to detect vulnerabilities until they manifest themselves as security failures in the operational stage of software, because security concerns are often not addressed or known sufficiently early during the software development life cycle. Numerous studies have shown that complexity, coupling, and cohesion ({CCC}) related structural metrics are important indicators of the quality of software architecture, and software architecture is one of the most important and early design decisions that influences the final quality of the software system. Although these metrics have been successfully employed to indicate software faults in general, there are no systematic guidelines on how to use these metrics to predict vulnerabilities in software. If {CCC} metrics can be used to indicate vulnerabilities, these metrics could aid in the conception of more secured architecture, leading to more secured design and code and eventually better software. In this paper, we present a framework to automatically predict vulnerabilities based on {CCC} metrics. To empirically validate the framework and prediction accuracy, we conduct a large empirical study on fifty-two releases of Mozilla Firefox developed over a period of four years. To build vulnerability predictors, we consider four alternative data mining and statistical techniques – C4.5 Decision Tree, Random Forests, Logistic Regression, and Naïve-Bayes – and compare their prediction performances. We are able to correctly predict majority of the vulnerability-prone files in Mozilla Firefox, with tolerable false positive rates. Moreover, the predictors built from the past releases can reliably predict the likelihood of having vulnerabilities in the future releases. The experimental results indicate that structural information from the non-security realm such as complexity, coupling, and cohesion are useful in vulnerability prediction.},
	pages = {294--313},
	number = {3},
	journaltitle = {Journal of Systems Architecture},
	author = {Chowdhury, Istehad and Zulkernine, Mohammad},
	date = {2011},
	keywords = {Software metrics, Cohesion, Complexity, Coupling, Vulnerability prediction, xno}
}

@article{abuta_reliability_2018,
	title = {Reliability over consecutive releases of a semiconductor Optical Endpoint Detection software system developed in a small company},
	volume = {137},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217302996},
	doi = {https://doi.org/10.1016/j.jss.2017.12.006},
	abstract = {Demonstrating software reliability across multiple software releases has become essential in making informed decisions of upgrading software releases without impacting significantly end users’ characterized processes and software quality standards. Standard defect and workload data normally collected in a typical small software development organization can be used for this purpose. Most of these organizations are normally under aggressive schedules with limited resources and data availability that are significantly different from large commercial software organizations where software reliability engineering has been successfully applied. Trend test, input domain reliability models ({IDRM}), and software reliability growth models ({SRGM}) were used in this paper on a semiconductor Optical Endpoint Detection ({OED}) software system to examine its overall trend and stability, to assess the system’s operational reliability, and to track its reliability growth over multiple releases. These techniques also provided evidence that continuous defect fixes increased software reliability substantially over time for this software system.},
	pages = {355--365},
	journaltitle = {Journal of Systems and Software},
	author = {Abuta, Eric and Tian, Jeff},
	date = {2018},
	keywords = {Testing, Reliability, Defects analysis, Semiconductor software, Software versions and releases, xno}
}

@article{hettiarachchi_risk-based_2016,
	title = {Risk-based test case prioritization using a fuzzy expert system},
	volume = {69},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584915001500},
	doi = {https://doi.org/10.1016/j.infsof.2015.08.008},
	abstract = {Context: The use of system requirements and their risks enables software testers to identify more important test cases that can reveal the faults associated with system components. Objective: The goal of this research is to make the requirements risk estimation process more systematic and precise by reducing subjectivity using a fuzzy expert system. Further, we provide empirical results that show that our proposed approach can improve the effectiveness of test case prioritization. Method: In this research, we used requirements modification status, complexity, security, and size of the software requirements as risk indicators and employed a fuzzy expert system to estimate the requirements risks. Further, we employed a semi-automated process to gather the required data for our approach and to make the risk estimation process less subjective. Results: The results of our study indicated that the prioritized tests based on our new approach can detect faults early, and also the approach can be effective at finding more faults earlier in the high-risk system components compared to the control techniques. Conclusion: We proposed an enhanced risk-based test case prioritization approach that estimates requirements risks systematically with a fuzzy expert system. With the proposed approach, testers can detect more faults earlier than with other control techniques. Further, the proposed semi-automated, systematic approach can easily be applied to industrial applications and can help improve regression testing effectiveness.},
	pages = {1--15},
	journaltitle = {Information and Software Technology},
	author = {Hettiarachchi, Charitha and Do, Hyunsook and Choi, Byoungju},
	date = {2016},
	keywords = {Regression testing, Empirical study, Test case prioritization, Fuzzy expert system, Requirements risks-based testing, xno}
}

@article{malhotra_particle_2018,
	title = {Particle swarm optimization-based ensemble learning for software change prediction},
	volume = {102},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918300909},
	doi = {https://doi.org/10.1016/j.infsof.2018.05.007},
	abstract = {Context Various researchers have successfully established the association between Object-Oriented metrics and change prone nature of a class. However, they actively continue to explore effective classifiers for developing efficient change prediction models. Recent developments have ascertained that ensemble methodology can be used to improve the prediction performance of individual classifiers. Objective This study proposes four strategies of ensemble learning to predict change prone classes by combining seven individual Particle Swarm Optimization ({PSO}) based classifiers as constituents of ensembles and aggregating them using weighted voting. Method The weights allocated to individual classifiers are based on their accuracy and their ability to correctly predict “hard instances” i.e. classes which are frequently misclassified by a majority of classifiers. Each individual {PSO} based classifier uses a different fitness function. The ensembles are constructed on the premises that change in fitness functions leads to variation in the results of a search-based algorithm such as {PSO}. Therefore, it is important to combine them to obtain a better classifier with improved accuracy using the ensemble methodology. Results The proposed strategies of ensemble learning were found effective in predicting software change. The statistical analysis of the results indicates improved performance of the proposed ensemble classifiers as compared to individual classifiers. Furthermore, the results of the proposed voting ensemble classifiers were found competent with those of machine-learning ensemble classifiers for determination of change prone classes. Conclusion The accuracy and diversity of the individual classifiers were instrumental in the superior performance of the proposed voting ensemble classifiers.},
	pages = {65--84},
	journaltitle = {Information and Software Technology},
	author = {Malhotra, Ruchika and Khanna, Megha},
	date = {2018},
	keywords = {Empirical validation, Particle swarm optimization, Ensemble learners, Software change prediction, xno}
}

@article{hassouna_effort_2010,
	title = {An effort prediction framework for software defect correction},
	volume = {52},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584909001748},
	doi = {https://doi.org/10.1016/j.infsof.2009.10.003},
	abstract = {This article tackles the problem of predicting effort (in person–hours) required to fix a software defect posted on an Issue Tracking System. The proposed method is inspired by the Nearest Neighbour Approach presented by the pioneering work of Weiss et al. (2007) [1]. We propose four enhancements to Weiss et al. (2007) [1]: Data Enrichment, Majority Voting, Adaptive Threshold and Binary Clustering. Data Enrichment infuses additional issue information into the similarity-scoring procedure, aiming to increase the accuracy of similarity scores. Majority Voting exploits the fact that many of the similar historical issues have repeating effort values, which are close to the actual. Adaptive Threshold automatically adjusts the similarity threshold to ensure that we obtain only the most similar matches. We use Binary Clustering if the similarity scores are very low, which might result in misleading predictions. This uses common properties of issues to form clusters (independent of the similarity scores) which are then used to produce the predictions. Numerical results are presented showing a noticeable improvement over the method proposed in Weiss et al. (2007) [1].},
	pages = {197--209},
	number = {2},
	journaltitle = {Information and Software Technology},
	author = {Hassouna, Alaa and Tahvildari, Ladan},
	date = {2010},
	keywords = {Software effort prediction, Clustering, Case-based reasoning, Issue tracking system, Software defect correction, xno}
}

@article{chadha_facilitating_2017,
	title = {Facilitating the development of cross-platform software via automated code synthesis from web-based programming resources},
	volume = {48},
	issn = {1477-8424},
	url = {https://www.sciencedirect.com/science/article/pii/S1477842415300634},
	doi = {https://doi.org/10.1016/j.cl.2016.08.005},
	abstract = {When a mobile application is supported on multiple major platforms, its market penetration is maximized. Such cross-platform native applications essentially deliver the same core functionality, albeit within the conventions of each supported platform. Maintaining and evolving a cross-platform native application is tedious and error-prone, as each modification requires replicating the changes for each of the application׳s platform-specific variants. Syntax-directed source-to-source translation proves inadequate to alleviate the problem, as native {API} access is always domain-specific. In this paper, we present a novel approach—Native-2-Native—that uses program transformations performed on one platform to automatically synthesize equivalent code blocks to be used on another platform. When a programmer modifies the source version of an application, the changes are captured. Based on the changes, Native-2-Native identifies the semantic content of the source code block and formulates an appropriate query to search for the equivalent target code block using popular web-based programming resources. The discovered target code block is then presented to the programmer as an automatically synthesized target language source file for further fine-tuning and subsequent integration into the mobile application׳s target version. We evaluate the proposed method using common native resources, such as sensors, network access, and canonical data structures. We show that our approach can correctly synthesize more than 74\% of {iOS} code from the provided Android source code and 91\% of Android code from the provided {iOS} source code. The presented approach effectively automates the process of extracting the source code block׳s semantics and discovering existing target examples with the equivalent functionality, thus alleviating some of the most laborious and intellectually tiresome programming tasks in modern mobile development.},
	pages = {3--19},
	journaltitle = {Computer Languages, Systems \& Structures},
	author = {Chadha, Sanchit and Byalik, Antuan and Tilevich, Eli and Rozovskaya, Alla},
	date = {2017},
	keywords = {Android, Java, Code synthesis, {IOS}, Mobile computing, Recommendation systems, Swift, xno}
}

@article{tarinejad_metrics_2021,
	title = {Metrics for assessing reliability of self-healing software systems},
	volume = {90},
	issn = {0045-7906},
	url = {https://www.sciencedirect.com/science/article/pii/S0045790620307989},
	doi = {https://doi.org/10.1016/j.compeleceng.2020.106952},
	abstract = {Evaluating the reliability of component-based software systems from their architecture is of great importance. This paper proposes metrics to assess the reliability of software systems considering the self-healing effect of components on software reliability. A self-healing component when being broken, heals itself with a probability and returns to normal conditions. Because designing a self-healing component is complex and costly, it is not possible to add self-healing operations to all components. Identifying effective components on the overall reliability of a software system, for adding self-healing operations to them, especially in the early stages of Software Development Life Cycle ({SDLC}) can have a great impact on reliability. In the literature, considering design models, many methods are presented for assessing the reliability of the software systems, but there exists no method to evaluate the impact of self-healing on reliability and also to identify candidate components to perform self-healing. In this paper, first, using the Markov chain, a method for modeling the self-healing behavior of a component is proposed. Then, by different combinations of Taylor series expansion and self-healing, several metrics are proposed to evaluate the reliability of a software system. Finally, we will present relationships that help a software engineer to identify the influential and bottleneck components for self-healing.},
	pages = {106952},
	journaltitle = {Computers \& Electrical Engineering},
	author = {Tarinejad, Ali and Izadkhah, Habib and Ardakani, Mohammadreza Mollahoseini and Mirzaie, Kamal},
	date = {2021},
	keywords = {Software reliability, Software architecture, Sensitivity analysis, Discrete-time Markov chain, Non-functional requirements, Self-healing component, xno}
}

@article{phillips_architecture_2018,
	title = {An architecture, system engineering, and acquisition approach for space system software resiliency},
	volume = {94},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917300575},
	doi = {https://doi.org/10.1016/j.infsof.2017.10.006},
	abstract = {Context Software-intensive space systems can harbor defects and vulnerabilities that may enable external adversaries or malicious insiders to disrupt or disable system functions, risking mission compromise or loss. Mitigating this risk demands a sustained focus on the security and resiliency of the system architecture including software, hardware, and other components. Objective In this paper we offer methodical approaches for improving space system resiliency through software architecture design, system engineering, and increased software security, thereby reducing the risk of latent software defects and vulnerabilities. Method We conducted a systematic review of existing architectural practices, standards, security and coding practices, various threats, defects, and vulnerabilities that impact space systems from hundreds of relevant publications and interviews of subject matter experts. We expanded on the system-level body of knowledge for resiliency and identified a new software architecture framework and acquisition methodology to improve the resiliency of space systems from a software perspective with an emphasis on the early phases of the systems engineering life cycle. This methodology involves seven steps: 1) Define technical resiliency requirements, 1a) Identify standards/policy for software resiliency, 2) Develop a request for proposal ({RFP})/statement of work ({SOW}) for resilient space systems software, 3) Define software resiliency goals for space systems, 4) Establish software resiliency quality attributes, 5) Perform architectural tradeoffs and identify risks, 6) Conduct architecture assessments as part of the procurement process, and 7) Ascertain space system software architecture resiliency metrics. Results Data illustrates that software vulnerabilities can lead to opportunities for malicious cyber activities, which could degrade the space mission capability for its user community. Reducing the number of vulnerabilities by improving architecture and software system engineering practices can contribute to making space systems more resilient. Conclusion Since cyber-attacks [1] are enabled by shortfalls in software, robust software engineering practices and an architectural design are foundational to resiliency, which is a quality that allows the system to take a hit to a critical component and recover in a known, bounded, and generally acceptable period of time. To achieve software resiliency for space systems, acquirers and suppliers must identify relevant factors and systems engineering practices to apply across the life cycle, in software requirements analysis, architecture development, design, implementation, verification and validation, and maintenance phases.},
	pages = {150--164},
	journaltitle = {Information and Software Technology},
	author = {Phillips, Dewanne M. and Mazzuchi, Thomas A. and Sarkani, Shahram},
	date = {2018},
	keywords = {Software, Systems engineering, Architecture, Life cycle, Cybersecurity, Resiliency, Threats, Vulnerabilities, xno}
}

@article{kaur_how_2019,
	title = {How does object-oriented code refactoring influence software quality? Research landscape and challenges},
	volume = {157},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121219301694},
	doi = {https://doi.org/10.1016/j.jss.2019.110394},
	abstract = {Context Software refactoring aims to improve software quality and developer productivity. Numerous empirical studies investigating the impact of refactoring activities on software quality have been conducted over the last two decades. Objective This study aims to perform a comprehensive systematic mapping study of existing empirical studies on evaluation of the effect of object-oriented code refactoring activities on software quality attributes. Method We followed a multi-stage scrutinizing process to select 142 primary studies published till December 2017. The selected primary studies were further classified based on several aspects to answer the research questions defined for this work. In addition, we applied vote-counting approach to combine the empirical results and their analysis reported in primary studies. Results The findings indicate that studies conducted in academic settings found more positive impact of refactoring on software quality than studies performed in industries. In general, refactoring activities caused all quality attributes to improve or degrade except for cohesion, complexity, inheritance, fault-proneness and power consumption attributes. Furthermore, individual refactoring activities have variable effects on most quality attributes explored in primary studies, indicating that refactoring does not always improve all quality attributes. Conclusions This study points out several open issues which require further investigation, e.g., lack of industrial validation, lesser coverage of refactoring activities, limited tool support, etc.},
	pages = {110394},
	journaltitle = {Journal of Systems and Software},
	author = {Kaur, Satnam and Singh, Paramvir},
	date = {2019},
	keywords = {Software quality, Systematic mapping study, Object-oriented software, Quality measures, Refactoring activity, xno}
}

@article{barros-justo_exploratory_2019,
	title = {An exploratory study of the standard reuse practice in a medium sized software development firm},
	volume = {61},
	issn = {0920-5489},
	url = {https://www.sciencedirect.com/science/article/pii/S0920548918301077},
	doi = {https://doi.org/10.1016/j.csi.2018.06.005},
	abstract = {Reuse has been a topic of interest in software engineering since 1968. Although many academic papers have been written about adopting software reuse in companies, such a process in practice has proven difficult, long and costly to implement. At present, rigorous studies on the current practice of reuse in industry are scarce. Objective: The aim of this paper was to study the current practice of software reuse at a medium sized company, in particular, we aimed to alleviate the lack of data and identify barriers and success factors. Method: An exploratory study based upon descriptive surveys. Results: The predominant practice of reuse is ad hoc (73\%) and the reusable artefacts were shared by means of a central repository (81\%). Most practitioners use the Web to look for artefacts (92\%), trying to understand them by studying code snippets or the artefact's documentation. The existence of a well-established reuse process (81\%) and a high quality of the artefacts (70\%) were the two most mentioned facilitators for reuse. Conclusions: All participants view software reuse as a beneficial process and believe that management should promote it. The results offer opportunities for further interpretation and comparison to software developers, project leaders, and researchers. However, these results cannot be generalized due to the specificity of the context we have studied. Replications of this study, in other business domains, are needed to generalize the results.},
	pages = {137--146},
	journaltitle = {Computer Standards \& Interfaces},
	author = {Barros-Justo, José L. and Olivieri, David N. and Pinciroli, Fernando},
	date = {2019},
	keywords = {Survey, Exploratory study, Industrial setting, Software reuse, Standard reuse practice, xno}
}

@article{alqahtani_tracing_2016,
	title = {Tracing known security vulnerabilities in software repositories – A Semantic Web enabled modeling approach},
	volume = {121},
	issn = {0167-6423},
	url = {https://www.sciencedirect.com/science/article/pii/S0167642316000253},
	doi = {https://doi.org/10.1016/j.scico.2016.01.005},
	abstract = {The introduction of the Internet has revolutionized not only our society but also transformed the software industry, with knowledge and information sharing becoming a central part of software development processes. The resulting globalization of the software industry has not only increased software reuse, but also introduced new challenges. Among the challenges, arising from the knowledge sharing is Information Security, which has emerged to become a major threat to the software development community, since not only source code but also its vulnerabilities are shared across project boundaries. Developers are unaware of such security vulnerabilities in their projects, often until a vulnerability is either exploited by attackers or made publicly available by independent security advisory databases. In this research, we present a modeling approach, which takes advantage of Semantic Web technologies, to establish traceability links between security advisory repositories and other software repositories. More specifically, we establish a unified ontological representation, which supports bi-directional traceability links between knowledge captured in software build repositories and specialized vulnerability database. These repositories can be considered trusted information silos that are typically not directly linked to other resources, such as source code repositories containing the reported instances of these problems. The novelty of our approach is that it allows us to overcome some of these traditional information silos and transform them into information hubs, which promote sharing of knowledge across repository boundaries. We conducted several experiments to illustrate the applicability of our approach by tracing existing vulnerabilities to projects which might directly or indirectly be affected by vulnerabilities inherited from other projects and libraries.},
	pages = {153--175},
	journaltitle = {Science of Computer Programming},
	author = {Alqahtani, Sultan S. and Eghan, Ellis E. and Rilling, Juergen},
	date = {2016},
	keywords = {Impact analysis, Semantic knowledge modelling, Semantic web, Software security vulnerabilities, Software traceability, xno}
}

@incollection{memon_chapter_2017,
	title = {Chapter Three - Fault Localization Using Hybrid Static/Dynamic Analysis},
	volume = {105},
	url = {https://www.sciencedirect.com/science/article/pii/S0065245816300778},
	series = {Advances in Computers},
	abstract = {With the increasing complexity of today's software, the software development process is becoming highly time and resource consuming. The increasing number of software configurations, input parameters, usage scenarios, supporting platforms, external dependencies, and versions plays an important role in expanding the costs of maintaining and repairing unforeseeable software faults. To repair software faults, developers spend considerable time in identifying the scenarios leading to those faults and root causing the problems. While software debugging remains largely manual, it is not the case with software testing and verification. The goal of this research is to improve the software development process in general, and software debugging process in particular, by devising techniques and methods for automated software debugging, which leverage the advances in automatic test case generation and replay. In this research, novel algorithms are devised to discover faulty execution paths in programs by utilizing already existing software test cases, which can be either automatically or manually generated. The execution traces or, alternatively, the sequence covers of the failing test cases are extracted. Afterward, commonalities between these test case sequence covers are extracted, processed, analyzed, and then presented to the developers in the form of subsequences that may be causing the fault. The hypothesis is that code sequences that are shared between a number of faulty test cases for the same reason resemble the faulty execution path, and hence, the search space for the faulty execution path can be narrowed down by using a large number of test cases. To achieve this goal, an efficient algorithm is implemented for finding common subsequences among a set of code sequence covers. Optimization techniques are devised to generate shorter and more logical sequence covers, and to select subsequences with high likelihood of containing the root cause among the set of all possible common subsequences. A hybrid static/dynamic analysis approach is designed to trace back the common subsequences from the end to the root cause.},
	pages = {79--114},
	publisher = {Elsevier},
	author = {Elsaka, E.},
	editor = {Memon, Atif M.},
	date = {2017},
	doi = {https://doi.org/10.1016/bs.adcom.2016.12.004},
	note = {{ISSN}: 0065-2458},
	keywords = {Software quality, Static analysis, Code coverage, Automated software debugging, Automated software testing, Dynamic analysis, Software debugging tools, xno}
}

@article{mo_exploring_2020,
	title = {Exploring software bug-proneness based on evolutionary clique modeling and analysis},
	volume = {128},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920301476},
	doi = {https://doi.org/10.1016/j.infsof.2020.106380},
	abstract = {Context: Even if evolutionary coupling between files has been widely used for various studies, such as change impact analysis, defect prediction, and software design analysis etc., there has little work focusing on studying the linkage among evolutionary coupled files. Objective: In this paper, we propose a novel model, evolutionary clique ({EClique}), to characterize evolutionary coupled files as maintainable groups for bug fixes, analyze their bug-proneness and examine the possible causes of the bug-proneness. Methods: To identify {ECliques} from a project, we propose two history measures to reason about the evolutionary coupling between files, and create a novel clustering algorithm. Given the evolutionary coupling information, our clustering algorithm will automatically identify {ECliques} in a project. Results: We conduct analyses on 33,099 commits of ten open source projects to evaluate the usefulness of our {EClique} modeling and analysis approach: (1) The results show that files involved in an {EClique} are more likely to share similar design characteristics and change together for resolving bugs; (2) The results also show that the identified {ECliques} significantly contribute to a project’s bug-proneness. Meanwhile, the majority of a project’s bug-proneness can be captured by just a few {ECliques} which only contain a small portion of files; (3) Finally, we qualitatively demonstrate that bug-prone {ECliques} often exhibit design problems that propagate changes among files and can potentially be the causes of bug-proneness. Conclusion: To reduce the bug-proneness of a software project, practitioners should pay attention to the identified {ECliques}, and resolve design problems embedded in these {ECliques}.},
	pages = {106380},
	journaltitle = {Information and Software Technology},
	author = {Mo, Ran and Yin, Zhen},
	date = {2020},
	keywords = {Software design, Co-change analysis, Mining repository, Software bug-proneness, xno}
}

@article{yazdanbakhsh_deterministic_2016,
	title = {On deterministic chaos in software reliability growth models},
	volume = {49},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494616304008},
	doi = {https://doi.org/10.1016/j.asoc.2016.08.006},
	abstract = {Software reliability growth models attempt to forecast the future reliability of a software system, based on observations of the historical occurrences of failures. This allows management to estimate the failure rate of the system in field use, and to set release criteria based on these forecasts. However, the current software reliability growth models have never proven to be accurate enough for widespread industry use. One possible reason is that the model forms themselves may not accurately capture the underlying process of fault injection in software; it has been suggested that fault injection is better modeled as a chaotic process rather than a random one. This possibility, while intriguing, has not yet been evaluated in large-scale, modern software reliability growth datasets. We report on an analysis of four software reliability growth datasets, including ones drawn from the Android and Mozilla open-source software communities. These are the four largest software reliability growth datasets we are aware of in the public domain, ranging from 1200 to over 86,000 observations. We employ the methods of nonlinear time series analysis to test for chaotic behavior in these time series; we find that three of the four do show evidence of such behavior (specifically, a multifractal attractor). Finally, we compare a deterministic time series forecasting algorithm against a statistical one on both datasets, to evaluate whether exploiting the apparent chaotic behavior might lead to more accurate reliability forecasts.},
	pages = {1256--1269},
	journaltitle = {Applied Soft Computing},
	author = {Yazdanbakhsh, O. and Dick, S. and Reay, I. and Mace, E.},
	date = {2016},
	keywords = {Forecasting, Machine learning, Software reliability, Time series analysis, Chaos theory, xno}
}

@article{hendrawan_visualizing_2015,
	title = {Visualizing Time-based Weighted Coupling Using Particle Swarm Optimization to Aid Program Comprehension},
	volume = {72},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050915036297},
	doi = {https://doi.org/10.1016/j.procs.2015.12.168},
	abstract = {By knowing software coupling, developers can get better view of the software quality and improve their productivity in development and maintenance. This paper presents a method to visualize coupling network that are often very complex, using heuristic approach based on particle swarming optimization. Each node is placed randomly and assigned with initial speed. Node that are coupled together will be attracted each other and trying to get closer until they reach a particular distance. This distance is determined from the coupling value of two nodes. A closely related nodes will move closer until reaching a short distance. On each iteration, node position is dynamically updated based on attraction and repulsive force around them. Thus, gradually forming a near best solution of logical coupling graph. The coupling values are measured by mining the association rule from changes history. A software development project sometimes can be very active, updates happen within minutes. Sometimes it becomes slow with weekly or even monthly updates. Time-based weighted analysis method was used to accommodate these time sensitive situations. A co-change in a short duration will be weighted more than co-changes that happen in longer duration.},
	pages = {597--604},
	journaltitle = {Procedia Computer Science},
	author = {Hendrawan, Rully Agus and Maruyama, Katsuhisa},
	date = {2015},
	keywords = {particle swarm optimization, association mining, logical coupling, program comprehension, source code visualization, xno}
}

@article{walter_code_2018,
	title = {Code smells and their collocations: A large-scale experiment on open-source systems},
	volume = {144},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218301109},
	doi = {https://doi.org/10.1016/j.jss.2018.05.057},
	abstract = {Code smells indicate possible flaws in software design, that could negatively affect system’s maintainability. Interactions among smells located in the same classes (i.e., collocated smells) have even more detrimental effect on quality. Extracted frequent patterns of collocated smells could help to understand practical consequences of collocations. In this paper we identify and empirically validate frequent collocations of 14 code smells detected in 92 Java systems, using three approaches: pairwise correlation analysis, {PCA} and associative rules. To cross-validate the results, we used up to 6 detectors for each smell. Additionally, we examine and compare techniques used to extract the relationships. The contribution is three-fold: (1) we identify and empirically validate relationships among the examined code smells on a large dataset that we made publicly available, (2) we discuss how the choice of code smell detectors affects results, and (3) we analyze the impact of software domain on existence of the smell collocations. Additionally, we found that analytical methods we used to discover collocations, are complementary. Smells collocations display recurring patterns that could help prioritizing the classes affected by code smells to be refactored and developing or enhancing detectors exploiting information about collocations. They can also help the developers focusing on classes deserving more maintenance effort.},
	pages = {1--21},
	journaltitle = {Journal of Systems and Software},
	author = {Walter, Bartosz and Fontana, Francesca Arcelli and Ferme, Vincenzo},
	date = {2018},
	keywords = {Code smell detectors, Code smells, Collocated smells, Inter-smell relationships, Smell interaction, Source code quality, xno}
}

@article{pascarella_performance_2020,
	title = {On the performance of method-level bug prediction: A negative result},
	volume = {161},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121219302675},
	doi = {https://doi.org/10.1016/j.jss.2019.110493},
	abstract = {Bug prediction is aimed at identifying software artifacts that are more likely to be defective in the future. Most approaches defined so far target the prediction of bugs at class/file level. Nevertheless, past research has provided evidence that this granularity is too coarse-grained for its use in practice. As a consequence, researchers have started proposing defect prediction models targeting a finer granularity (particularly method-level granularity), providing promising evidence that it is possible to operate at this level. Particularly, models mixing product and process metrics provided the best results. We present a study in which we first replicate previous research on method-level bug-prediction, by using different systems and timespans. Afterwards, based on the limitations of existing research, we (1) re-evaluate method-level bug prediction models more realistically and (2) analyze whether alternative features based on textual aspects, code smells, and developer-related factors can be exploited to improve method-level bug prediction abilities. Key results of our study include that (1) the performance of the previously proposed models, tested using the same strategy but on different systems/timespans, is confirmed; but, (2) when evaluated with a more practical strategy, all the models show a dramatic drop in performance, with results close to that of a random classifier. Finally, we find that (3) the contribution of alternative features within such models is limited and unable to improve the prediction capabilities significantly. As a consequence, our replication and negative results indicate that method-level bug prediction is still an open challenge.},
	pages = {110493},
	journaltitle = {Journal of Systems and Software},
	author = {Pascarella, Luca and Palomba, Fabio and Bacchelli, Alberto},
	date = {2020},
	keywords = {Mining software repositories, Defect prediction, Empirical software engineering, xno}
}

@article{palomba_large-scale_2018,
	title = {A large-scale empirical study on the lifecycle of code smell co-occurrences},
	volume = {99},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918300211},
	doi = {https://doi.org/10.1016/j.infsof.2018.02.004},
	abstract = {Context Code smells are suboptimal design or implementation choices made by programmers during the development of a software system that possibly lead to low code maintainability and higher maintenance costs. Objective Previous research mainly studied the characteristics of code smell instances affecting a source code file, while only few studies analyzed the magnitude and effects of smell co-occurrence, i.e., the co-occurrence of different types of smells on the same code component. This paper aims at studying in details this phenomenon. Method We analyzed 13 code smell types detected in 395 releases of 30 software systems to firstly assess the extent to which code smells co-occur, and then we analyze (i) which code smells co-occur together, and (ii) how and why they are introduced and removed by developers. Results 59\% of smelly classes are affected by more than one smell, and in particular there are six pairs of smell types (e.g., Message Chains and Spaghetti Code) that frequently co-occur. Furthermore, we observed that method-level code smells may be the root cause for the introduction of class-level smells. Finally, code smell co-occurrences are generally removed together as a consequence of other maintenance activities causing the deletion of the affected code components (with a consequent removal of the code smell instances) as well as the result of a major restructuring or scheduled refactoring actions. Conclusions Based on our findings, we argue that more research aimed at designing co-occurrence-aware code smell detectors and refactoring approaches is needed.},
	pages = {1--10},
	journaltitle = {Information and Software Technology},
	author = {Palomba, Fabio and Bavota, Gabriele and Penta, Massimiliano Di and Fasano, Fausto and Oliveto, Rocco and Lucia, Andrea De},
	date = {2018},
	keywords = {Mining software repositories, Empirical study, Code smells co-occurrences, xyes},
	file = {Palomba et al. - 2018 - A large-scale empirical study on the lifecycle of .pdf:C\:\\Users\\michalm\\Zotero\\storage\\AUFLGEZ2\\Palomba et al. - 2018 - A large-scale empirical study on the lifecycle of .pdf:application/pdf}
}

@article{jiang_how_2012,
	title = {How well does test case prioritization integrate with statistical fault localization?},
	volume = {54},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584912000171},
	doi = {https://doi.org/10.1016/j.infsof.2012.01.006},
	abstract = {Context Effective test case prioritization shortens the time to detect failures, and yet the use of fewer test cases may compromise the effectiveness of subsequent fault localization. Objective The paper aims at finding whether several previously identified effectiveness factors of test case prioritization techniques, namely strategy, coverage granularity, and time cost, have observable consequences on the effectiveness of statistical fault localization techniques. Method This paper uses a controlled experiment to examine these factors. The experiment includes 16 test case prioritization techniques and four statistical fault localization techniques using the Siemens suite of programs as well as grep, gzip, sed, and flex as subjects. The experiment studies the effects of the percentage of code examined to locate faults from these benchmark subjects after a given number of failures have been observed. Results We find that if testers have a budgetary concern on the number of test cases for regression testing, the use of test case prioritization can save up to 40\% of test case executions for commit builds without significantly affecting the effectiveness of fault localization. A statistical fault localization technique using a smaller fraction of a prioritized test suite is found to compromise its effectiveness seriously. Despite the presence of some variations, the inclusion of more failed test cases will generally improve the fault localization effectiveness during the integration process. Interestingly, during the variation periods, adding more failed test cases actually deteriorates the fault localization effectiveness. In terms of strategies, Random is found to be the most effective, followed by the {ART} and Additional strategies, while the Total strategy is the least effective. We do not observe sufficient empirical evidence to conclude that using different coverage granularity levels have different overall effects. Conclusion The paper empirically identifies that strategy and time–cost of test case prioritization techniques are key factors affecting the effectiveness of statistical fault localization, while coverage granularity is not a significant factor. It also identifies a mid-range deterioration in fault localization effectiveness when adding more test cases to facilitate debugging.},
	pages = {739--758},
	number = {7},
	journaltitle = {Information and Software Technology},
	author = {Jiang, Bo and Zhang, Zhenyu and Chan, W. K. and Tse, T. H. and Chen, Tsong Yueh},
	date = {2012},
	keywords = {Test case prioritization, Adaptive random testing, Continuous integration, Coverage, Software process integration, Statistical fault localization, xno}
}

@article{chen_understanding_2018,
	title = {Understanding metric-based detectable smells in Python software: A comparative study},
	volume = {94},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584916301690},
	doi = {https://doi.org/10.1016/j.infsof.2017.09.011},
	abstract = {Context Code smells are supposed to cause potential comprehension and maintenance problems in software development. Although code smells are studied in many languages, e.g. Java and C\#, there is a lack of technique or tool support addressing code smells in Python. Objective Due to the great differences between Python and static languages, the goal of this study is to define and detect code smells in Python programs and to explore the effects of Python smells on software maintainability. Method In this paper, we introduced ten code smells and established a metric-based detection method with three different filtering strategies to specify metric thresholds (Experience-Based Strategy, Statistics-Based Strategy, and Tuning Machine Strategy). Then, we performed a comparative study to investigate how three detection strategies perform in detecting Python smells and how these smells affect software maintainability with different detection strategies. This study utilized a corpus of 106 Python projects with most stars on {GitHub}. Results The results showed that: (1) the metric-based detection approach performs well in detecting Python smells and Tuning Machine Strategy achieves the best accuracy; (2) the three detection strategies discover some different smell occurrences, and Long Parameter List and Long Method are more prevalent than other smells; (3) several kinds of code smells are more significantly related to changes or faults in Python modules. Conclusion These findings reveal the key features of Python smells and also provide a guideline for the choice of detection strategy in detecting and analyzing Python smells.},
	pages = {14--29},
	journaltitle = {Information and Software Technology},
	author = {Chen, Zhifei and Chen, Lin and Ma, Wanwangying and Zhou, Xiaoyu and Zhou, Yuming and Xu, Baowen},
	date = {2018},
	keywords = {Code smell, Software maintainability, Detection strategy, Python, xno}
}

@article{zhang_dual_2013,
	title = {A dual process redundancy approach to transient fault tolerance for {ccNUMA} architecture},
	volume = {122},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231213005560},
	doi = {https://doi.org/10.1016/j.neucom.2013.01.043},
	abstract = {Transient fault is a critical concern in the reliability of microprocessor system. The software fault tolerance is more flexible and lower in cost than the hardware fault tolerance. And also, as architectural trends point toward multicore designs, there is substantial interest in adapting parallel and redundancy hardware resources for transient fault tolerance. The paper proposes a process-level fault tolerance technique, a software-centric approach, which efficiently schedules and synchronizes redundancy processes with {ccNUMA} processors redundancy. So it can improve efficiency of redundancy processes running and reduce time and space overhead. The paper focuses on the researching of redundancy processes error detection and handling method. A real prototype is implemented that is designed to be transparent to the application. The test results show that the system can timely detect soft errors of {CPU} and memory that cause the redundancy processes exception, and meanwhile ensure that the services of the application are uninterrupted and delayed shortly.},
	pages = {50--57},
	journaltitle = {Neurocomputing},
	author = {Zhang, Xingjun and Wang, Endong and Tang, Feilong and Yang, Meishun and Wei, Hengyi and Dong, Xiaoshe},
	date = {2013},
	keywords = {Redundancy, {CcNUMA}, Dual-process, Transient fault, xno}
}

@article{tosun_practical_2010,
	title = {Practical considerations in deploying statistical methods for defect prediction: A case study within the Turkish telecommunications industry},
	volume = {52},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584910001163},
	doi = {https://doi.org/10.1016/j.infsof.2010.06.006},
	abstract = {Context Building defect prediction models in large organizations has many challenges due to limited resources and tight schedules in the software development lifecycle. It is not easy to collect data, utilize any type of algorithm and build a permanent model at once. We have conducted a study in a large telecommunications company in Turkey to employ a software measurement program and to predict pre-release defects. Based on our prior publication, we have shared our experience in terms of the project steps (i.e. challenges and opportunities). We have further introduced new techniques that improve our earlier results. Objective In our previous work, we have built similar predictors using data representative for {US} software development. Our task here was to check if those predictors were specific solely to {US} organizations or to a broader class of software. Method We have presented our approach and results in the form of an experience report. Specifically, we have made use of different techniques for improving the information content of the software data and the performance of a Naïve Bayes classifier in the prediction model that is locally tuned for the company. We have increased the information content of the software data by using module dependency data and improved the performance by adjusting the hyper-parameter (decision threshold) of the Naïve Bayes classifier. We have reported and discussed our results in terms of defect detection rates and false alarms. We also carried out a cost–benefit analysis to show that our approach can be efficiently put into practice. Results Our general result is that general defect predictors, which exist across a wide range of software (in both {US} and Turkish organizations), are present. Our specific results indicate that concerning the organization subject to this study, the use of version history information along with code metrics decreased false alarms by 22\%, the use of dependencies between modules further reduced false alarms by 8\%, and the decision threshold optimization for the Naïve Bayes classifier using code metrics and version history information further improved false alarms by 30\% in comparison to a prediction using only code metrics and a default decision threshold. Conclusion Implementing statistical techniques and machine learning on a real life scenario is a difficult yet possible task. Using simple statistical and algorithmic techniques produces an average detection rate of 88\%. Although using dependency data improves our results, it is difficult to collect and analyze such data in general. Therefore, we would recommend optimizing the hyper-parameter of the proposed technique, Naïve Bayes, to calibrate the defect prediction model rather than employing more complex classifiers. We also recommend that researchers who explore statistical and algorithmic methods for defect prediction should spend less time on their algorithms and more time on studying the pragmatic considerations of large organizations.},
	pages = {1242--1257},
	number = {11},
	journaltitle = {Information and Software Technology},
	author = {Tosun, Ayşe and Bener, Ayşe and Turhan, Burak and Menzies, Tim},
	date = {2010},
	keywords = {Naïve Bayes, Software defect prediction, Experience report, Static code attributes, xno}
}

@article{biesialska_big_2021,
	title = {Big Data analytics in Agile software development: A systematic mapping study},
	volume = {132},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920301981},
	doi = {https://doi.org/10.1016/j.infsof.2020.106448},
	abstract = {Context: Over the last decade, Agile methods have changed the software development process in an unparalleled way and with the increasing popularity of Big Data, optimizing development cycles through data analytics is becoming a commodity. Objective: Although a myriad of research exists on software analytics as well as on Agile software development ({ASD}) practice on itself, there exists no systematic overview of the research done on {ASD} from a data analytics perspective. Therefore, the objective of this work is to make progress by linking {ASD} with Big Data analytics ({BDA}). Method: As the primary method to find relevant literature on the topic, we performed manual search and snowballing on papers published between 2011 and 2019. Results: In total, 88 primary studies were selected and analyzed. Our results show that {BDA} is employed throughout the whole {ASD} lifecycle. The results reveal that data-driven software development is focused on the following areas: code repository analytics, defects/bug fixing, testing, project management analytics, and application usage analytics. Conclusions: As {BDA} and {ASD} are fast-developing areas, improving the productivity of software development teams is one of the most important objectives {BDA} is facing in the industry. This study provides scholars with information about the state of software analytics research and the current trends as well as applications in the business environment. Whereas, thanks to this literature review, practitioners should be able to understand better how to obtain actionable insights from their software artifacts and on which aspects of data analytics to focus when investing in such initiatives.},
	pages = {106448},
	journaltitle = {Information and Software Technology},
	author = {Biesialska, Katarzyna and Franch, Xavier and Muntés-Mulero, Victor},
	date = {2021},
	keywords = {Machine learning, Artificial intelligence, Agile software development, Data analytics, Literature review, Software analytics, xno}
}

@article{perkusich_intelligent_2020,
	title = {Intelligent software engineering in the context of agile software development: A systematic literature review},
	volume = {119},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584919302587},
	doi = {https://doi.org/10.1016/j.infsof.2019.106241},
	abstract = {{CONTEXT}: Intelligent Software Engineering ({ISE}) refers to the application of intelligent techniques to software engineering. We define an “intelligent technique” as a technique that explores data (from digital artifacts or domain experts) for knowledge discovery, reasoning, learning, planning, natural language processing, perception or supporting decision-making. {OBJECTIVE}: The purpose of this study is to synthesize and analyze the state of the art of the field of applying intelligent techniques to Agile Software Development ({ASD}). Furthermore, we assess its maturity and identify adoption risks. {METHOD}: Using a systematic literature review, we identified 104 primary studies, resulting in 93 unique studies. {RESULTS}: We identified that there is a positive trend in the number of studies applying intelligent techniques to {ASD}. Also, we determined that reasoning under uncertainty (mainly, Bayesian network), search-based solutions, and machine learning are the most popular intelligent techniques in the context of {ASD}. In terms of purposes, the most popular ones are effort estimation, requirements prioritization, resource allocation, requirements selection, and requirements management. Furthermore, we discovered that the primary goal of applying intelligent techniques is to support decision making. As a consequence, the adoption risks in terms of the safety of the current solutions are low. Finally, we highlight the trend of using explainable intelligent techniques. {CONCLUSION}: Overall, although the topic area is up-and-coming, for many areas of application, it is still in its infancy. So, this means that there is a need for more empirical studies, and there are a plethora of new opportunities for researchers.},
	pages = {106241},
	journaltitle = {Information and Software Technology},
	author = {Perkusich, Mirko and Silva, Lenardo Chaves e and Costa, Alexandre and Ramos, Felipe and Saraiva, Renata and Freire, Arthur and Dilorenzo, Ednaldo and Dantas, Emanuel and Santos, Danilo and Gorgônio, Kyller and Almeida, Hyggo and Perkusich, Angelo},
	date = {2020},
	keywords = {Machine learning, Artificial intelligence, Bayesian networks, Search-based software engineering, Agile software development, Intelligent software engineering, xno}
}

@article{shahamiri_automated_2011,
	title = {An automated framework for software test oracle},
	volume = {53},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584911000589},
	doi = {https://doi.org/10.1016/j.infsof.2011.02.006},
	abstract = {Context One of the important issues of software testing is to provide an automated test oracle. Test oracles are reliable sources of how the software under test must operate. In particular, they are used to evaluate the actual results that produced by the software. However, in order to generate an automated test oracle, oracle challenges need to be addressed. These challenges are output-domain generation, input domain to output domain mapping, and a comparator to decide on the accuracy of the actual outputs. Objective This paper proposes an automated test oracle framework to address all of these challenges. Method I/O Relationship Analysis is used to generate the output domain automatically and Multi-Networks Oracles based on artificial neural networks are introduced to handle the second challenge. The last challenge is addressed using an automated comparator that adjusts the oracle precision by defining the comparison tolerance. The proposed approach was evaluated using an industry strength case study, which was injected with some faults. The quality of the proposed oracle was measured by assessing its accuracy, precision, misclassification error and practicality. Mutation testing was considered to provide the evaluation framework by implementing two different versions of the case study: a Golden Version and a Mutated Version. Furthermore, a comparative study between the existing automated oracles and the proposed one is provided based on which challenges they can automate. Results Results indicate that the proposed approach automated the oracle generation process 97\% in this experiment. Accuracy of the proposed oracle was up to 98.26\%, and the oracle detected up to 97.7\% of the injected faults. Conclusion Consequently, the results of the study highlight the practicality of the proposed oracle in addition to the automation it offers.},
	pages = {774--788},
	number = {7},
	journaltitle = {Information and Software Technology},
	author = {Shahamiri, Seyed Reza and Kadir, Wan Mohd Nasir Wan and Ibrahim, Suhaimi and Hashim, Siti Zaiton Mohd},
	date = {2011},
	keywords = {Artificial neural networks, Mutation testing, I/O Relationship Analysis, Software test oracle, xno}
}

@article{kechagia_exception_2018,
	title = {The exception handling riddle: An empirical study on the Android {API}},
	volume = {142},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218300724},
	doi = {https://doi.org/10.1016/j.jss.2018.04.034},
	abstract = {We examine the use of the Java exception types in the Android platform’s Application Programming Interface ({API}) reference documentation and their impact on the stability of Android applications. We develop a method that automatically assesses an {API}’s quality regarding the exceptions listed in the {API}’s documentation. We statically analyze ten versions of the Android platform’s {API} (14–23) and 3539 Android applications to determine inconsistencies between exceptions that analysis can find in the source code and exceptions that are documented. We cross-check the analysis of the Android platform’s {API} and applications with crash data from 901,274 application execution failures (crashes). We discover that almost 10\% of the undocumented exceptions that static analysis can find in the Android platform’s {API} source code manifest themselves in crashes. Additionally, we observe that 38\% of the undocumented exceptions that developers use in their client applications to handle {API} methods also manifest themselves in crashes. These findings argue for documenting known might-thrown exceptions that lead to execution failures. However, a randomized controlled trial we run shows that relevant documentation improvements are ineffective and that making such exceptions checked is a more effective way for improving applications’ stability.},
	pages = {248--270},
	journaltitle = {Journal of Systems and Software},
	author = {Kechagia, Maria and Fragkoulis, Marios and Louridas, Panos and Spinellis, Diomidis},
	date = {2018},
	keywords = {Documentation, Application programming interfaces, Exceptions, xno}
}

@article{chen_collective_2020,
	title = {Collective transfer learning for defect prediction},
	volume = {416},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231219308720},
	doi = {https://doi.org/10.1016/j.neucom.2018.12.091},
	abstract = {Most software defect prediction approaches require extensive data from the project under test for training. However, for a new project, enough training data is often not available. It is therefore necessary to build a predictive model using the data from other relevant projects and then use the model to predict defects in the target project. Such direct cross-project prediction performance can still be improved, mainly due to the distribution differences between the source and target projects, as well as the uncertainty in determining which source project should be selected to train the model. In this work, we propose a collective training mechanism for defect prediction ({CTDP}), which includes two phases: source data expansion phase and adaptive weighting phase. {CTDP} makes the feature distributions of source and target projects similar to each other by transfer learning, and uses the particle swarm optimization algorithm to comprehensively consider the multiple source projects to predict the target project. The experiments on a total of 28 projects in 5 groups show that our method can improve the performance of cross-project defect prediction, achieving the sate-of-the-art results.},
	pages = {103--116},
	journaltitle = {Neurocomputing},
	author = {Chen, Jinyin and Hu, Keke and Yang, Yitao and Liu, Yi and Xuan, Qi},
	date = {2020},
	keywords = {Transfer learning, Particle swarm optimization, Cross-project defect prediction, Multi-source domain adaption, xno}
}

@article{mensah_value_2018,
	title = {On the value of a prioritization scheme for resolving Self-admitted technical debt},
	volume = {135},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217302133},
	doi = {https://doi.org/10.1016/j.jss.2017.09.026},
	abstract = {Programmers tend to leave incomplete, temporary workarounds and buggy codes that require rework in software development and such pitfall is referred to as Self-admitted Technical Debt ({SATD}). Previous studies have shown that {SATD} negatively affects software project and incurs high maintenance overheads. In this study, we introduce a prioritization scheme comprising mainly of identification, examination and rework effort estimation of prioritized tasks in order to make a final decision prior to software release. Using the proposed prioritization scheme, we perform an exploratory analysis on four open source projects to investigate how {SATD} can be minimized. Four prominent causes of {SATD} are identified, namely code smells (23.2\%), complicated and complex tasks (22.0\%), inadequate code testing (21.2\%) and unexpected code performance (17.4\%). Results show that, among all the types of {SATD}, design debts on average are highly prone to software bugs across the four projects analysed. Our findings show that a rework effort of approximately 10 to 25 commented {LOC} per {SATD} source file is needed to address the highly prioritized {SATD} (vital few) tasks. The proposed prioritization scheme is a novel technique that will aid in decision making prior to software release in an attempt to minimize high maintenance overheads.},
	pages = {37--54},
	journaltitle = {Journal of Systems and Software},
	author = {Mensah, Solomon and Keung, Jacky and Svajlenko, Jeffery and Bennin, Kwabena Ebo and Mi, Qing},
	date = {2018},
	keywords = {Open source projects, Prioritization scheme, Self-admitted technical debt, Source code comment, Textual indicators, xno}
}

@article{xiao_improving_2019,
	title = {Improving bug localization with word embedding and enhanced convolutional neural networks},
	volume = {105},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918301654},
	doi = {https://doi.org/10.1016/j.infsof.2018.08.002},
	abstract = {Context: Automatic localization of buggy files can speed up the process of bug fixing to improve the efficiency and productivity of software quality assurance teams. Useful semantic information is available in bug reports and source code, but it is usually underutilized by existing bug localization approaches. Objective: To improve the performance of bug localization, we propose {DeepLoc}, a novel deep learning-based model that makes full use of semantic information. Method: {DeepLoc} is composed of an enhanced convolutional neural network ({CNN}) that considers bug-fixing recency and frequency, together with word-embedding and feature-detecting techniques. {DeepLoc} uses word embeddings to represent the words in bug reports and source files that retain their semantic information, and different {CNNs} to detect features from them. {DeepLoc} is evaluated on over 18,500 bug reports extracted from {AspectJ}, Eclipse, {JDT}, {SWT}, and Tomcat projects. Results: The experimental results show that {DeepLoc} achieves 10.87\%–13.4\% higher {MAP} (mean average precision) than conventional {CNN}. {DeepLoc} outperforms four current state-of-the-art approaches ({DeepLocator}, {HyLoc}, {LR}+{WE}, and {BugLocator}) in terms of Accuracy@k (the percentage of bug reports for which at least one real buggy file is located within the top k rank), {MAP}, and {MRR} (mean reciprocal rank) using less computation time. Conclusion: {DeepLoc} is capable of automatically connecting bug reports to the corresponding buggy files and achieves better performance than four state-of-the-art approaches based on a deep understanding of semantics in bug reports and source code.},
	pages = {17--29},
	journaltitle = {Information and Software Technology},
	author = {Xiao, Yan and Keung, Jacky and Bennin, Kwabena E. and Mi, Qing},
	date = {2019},
	keywords = {Deep learning, Convolutional neural network, Bug localization, Semantic information, {TF}-{IDF}, Word embedding, xno}
}

@article{peng_unit_2021,
	title = {Unit and regression tests of scientific software: A study on {SWMM}},
	volume = {53},
	issn = {1877-7503},
	url = {https://www.sciencedirect.com/science/article/pii/S1877750321000442},
	doi = {https://doi.org/10.1016/j.jocs.2021.101347},
	abstract = {Testing helps assure software quality by executing a program and uncovering bugs. Scientific software developers often find it challenging to carry out systematic and automated testing due to reasons like inherent model uncertainties and complex floating-point computations. Extending the recent work on analyzing the unit tests written by the developers of the Storm Water Management Model ({SWMM}) [32], we report in this paper the investigation of both unit and regression tests of {SWMM}. The results show that the 2953 unit tests of {SWMM} have a 39.7\% statement-level code coverage and a 82.4\% user manual coverage. Meanwhile, an examination of 58 regression tests of {SWMM} shows a 44.9\% statement-level code coverage and a near 100\% user manual coverage. We also observe a “getter-setter-getter” testing pattern from the {SWMM} unit tests, and suggest a diversified way of executing regression tests.},
	pages = {101347},
	journaltitle = {Journal of Computational Science},
	author = {Peng, Zedong and Lin, Xuanyi and Simon, Michelle and Niu, Nan},
	date = {2021},
	keywords = {Regression testing, Scientific software, Storm Water Management Model ({SWMM}), Test coverage, Unit testing, User manual, xno}
}

@article{azeem_machine_2019,
	title = {Machine learning techniques for code smell detection: A systematic literature review and meta-analysis},
	volume = {108},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584918302623},
	doi = {https://doi.org/10.1016/j.infsof.2018.12.009},
	abstract = {Background: Code smells indicate suboptimal design or implementation choices in the source code that often lead it to be more change- and fault-prone. Researchers defined dozens of code smell detectors, which exploit different sources of information to support developers when diagnosing design flaws. Despite their good accuracy, previous work pointed out three important limitations that might preclude the use of code smell detectors in practice: (i) subjectiveness of developers with respect to code smells detected by such tools, (ii) scarce agreement between different detectors, and (iii) difficulties in finding good thresholds to be used for detection. To overcome these limitations, the use of machine learning techniques represents an ever increasing research area. Objective: While the research community carefully studied the methodologies applied by researchers when defining heuristic-based code smell detectors, there is still a noticeable lack of knowledge on how machine learning approaches have been adopted for code smell detection and whether there are points of improvement to allow a better detection of code smells. Our goal is to provide an overview and discuss the usage of machine learning approaches in the field of code smells. Method: This paper presents a Systematic Literature Review ({SLR}) on Machine Learning Techniques for Code Smell Detection. Our work considers papers published between 2000 and 2017. Starting from an initial set of 2456 papers, we found that 15 of them actually adopted machine learning approaches. We studied them under four different perspectives: (i) code smells considered, (ii) setup of machine learning approaches, (iii) design of the evaluation strategies, and (iv) a meta-analysis on the performance achieved by the models proposed so far. Results: The analyses performed show that God Class, Long Method, Functional Decomposition, and Spaghetti Code have been heavily considered in the literature. Decision Trees and Support Vector Machines are the most commonly used machine learning algorithms for code smell detection. Models based on a large set of independent variables have performed well. {JRip} and Random Forest are the most effective classifiers in terms of performance. The analyses also reveal the existence of several open issues and challenges that the research community should focus on in the future. Conclusion: Based on our findings, we argue that there is still room for the improvement of machine learning techniques in the context of code smell detection. The open issues emerged in this study can represent the input for researchers interested in developing more powerful techniques.},
	pages = {115--138},
	journaltitle = {Information and Software Technology},
	author = {Azeem, Muhammad Ilyas and Palomba, Fabio and Shi, Lin and Wang, Qing},
	date = {2019},
	keywords = {Machine learning, Systematic literature review, Code smells, xno}
}

@article{nguyen_controlled_2011,
	title = {A controlled experiment in assessing and estimating software maintenance tasks},
	volume = {53},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584910002041},
	doi = {https://doi.org/10.1016/j.infsof.2010.11.003},
	abstract = {Context Software maintenance is an important software engineering activity that has been reported to account for the majority of the software total cost. Thus, understanding the factors that influence the cost of software maintenance tasks helps maintainers to make informed decisions about their work. Objective This paper describes a controlled experiment of student programmers performing maintenance tasks on a C++ program. The objective of the study is to assess the maintenance size, effort, and effort distributions of three different maintenance types and to describe estimation models to predict the programmer’s effort spent on maintenance tasks. Method Twenty-three graduate students and a senior majoring in computer science participated in the experiment. Each student was asked to perform maintenance tasks required for one of the three task groups. The impact of different {LOC} metrics on maintenance effort was also evaluated by fitting the data collected into four estimation models. Results The results indicate that corrective maintenance is much less productive than enhancive and reductive maintenance and program comprehension activities require as much as 50\% of the total effort in corrective maintenance. Moreover, the best software effort model can estimate the time of 79\% of the programmers with the error of or less than 30\%. Conclusion Our study suggests that the {LOC} added, modified, and deleted metrics are good predictors for estimating the cost of software maintenance. Effort estimation models for maintenance work may use the {LOC} added, modified, deleted metrics as the independent parameters instead of the simple sum of the three. Another implication is that reducing business rules of the software requires a sizable proportion of the software maintenance effort. Finally, the differences in effort distribution among the maintenance types suggest that assigning maintenance tasks properly is important to effectively and efficiently utilize human resources.},
	pages = {682--691},
	number = {6},
	journaltitle = {Information and Software Technology},
	author = {Nguyen, Vu and Boehm, Barry and Danphitsanuphan, Phongphan},
	date = {2011},
	keywords = {Software maintenance, {COCOMO}, Maintenance experiment, Maintenance size, Software estimation, xno}
}

@article{anderson_use_2019,
	title = {On the use of usage patterns from telemetry data for test case prioritization},
	volume = {113},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584919301223},
	doi = {https://doi.org/10.1016/j.infsof.2019.05.008},
	abstract = {Context Modern applications contain pervasive telemetry to ensure reliability and enable monitoring and diagnosis. This presents a new opportunity in the area of regression testing techniques, as we now have the ability to consider usage profiles of the software when making decisions on test execution. Objective The results of our prior work on test prioritization using telemetry data showed improvement rate on test suite reduction, and test execution time. The objective of this paper is to further investigate this approach and apply prioritization based on multiple prioritization algorithms in an enterprise level cloud application as well as open source projects. We aim to provide an effective prioritization scheme that practitioners can implement with minimum effort. The other objective is to compare the results and the benefits of this technique factors with code coverage-based prioritization approaches, which is the most commonly used test prioritization technique. Method We introduce a method for identifying usage patterns based on telemetry, which we refer to as “telemetry fingerprinting.” Through the use of various algorithms to compute fingerprints, we conduct empirical studies on multiple software products to show that telemetry fingerprinting can be used to more effectively prioritize regression tests. Results Our experimental results show that the proposed techniques were able to reduce over 30\% in regression test suite run times compared to the coverage-based prioritization technique in detecting discoverable faults. Further, the results indicate that fingerprints are effective in identifying usage patterns, and that the fingerprints can be applied to improve regression testing techniques. Conclusion In this research, we introduce the concept of fingerprinting software usage patterns through telemetry. We provide various algorithms to compute fingerprints and conduct empirical studies that show that fingerprints are effective in identifying distinct usage patterns. By applying these techniques, we believe that regression testing techniques can be improved beyond the current state-of-the-art, yielding additional cost and quality benefits.},
	pages = {110--130},
	journaltitle = {Information and Software Technology},
	author = {Anderson, Jeff and Azizi, Maral and Salem, Saeed and Do, Hyunsook},
	date = {2019},
	keywords = {Regression testing, Telemetry data, Test case prioritization, Usage patterns, xno}
}

@article{bicer_defect_2016,
	title = {Defect prediction for Cascading Style Sheets},
	volume = {49},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494616302484},
	doi = {https://doi.org/10.1016/j.asoc.2016.05.038},
	abstract = {Testing is a crucial activity in software development. However exhaustive testing of a given software is impossible in practice because projects have serious time and budget limitations. Therefore, software testing teams need guidance about which modules they should focus on. Defect prediction techniques are useful for this situation because they let testers to identify and focus on defect prone parts of software. These techniques are essential for software teams, because they help teams to efficiently allocate their precious resources in testing phase. Software defect prediction has been an active research area in recent years. Researchers in this field have been using different types of metrics in their prediction models. However, value of extracting static code metrics for style sheet languages has been ignored until now. User experience is a very important part of web applications and its mostly provided using Cascading Style Sheets ({CSS}). In this research, our aim is to improve defect prediction performance for web applications by utilizing metrics generated from {CSS} code. We generated datasets from four open source web applications to conduct our experiments. Defect prediction is then performed using three different well-known machine learning algorithms. The results revealed that static code metrics based defect prediction techniques can be performed effectively to improve quality of {CSS} code in web applications. Therefore we recommend utilizing domain-specific characteristics of applications in defect prediction as they result in significantly high prediction performance with low costs.},
	pages = {1078--1084},
	journaltitle = {Applied Soft Computing},
	author = {Biçer, M. Serdar and Diri, Banu},
	date = {2016},
	keywords = {Software quality, Defect prediction, Software Metrics, Web sites, xno}
}

@article{hofer_product_2021,
	title = {Product metrics for spreadsheets—A systematic review},
	volume = {175},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121221000078},
	doi = {https://doi.org/10.1016/j.jss.2021.110910},
	abstract = {Software product metrics allow practitioners to improve their products and to optimize development processes based on quantifiable characteristics of source code. To facilitate similar benefits for spreadsheet programs, researchers proposed various product metrics for spreadsheets over the last decades. However, to our knowledge, no comprehensive overview of those efforts is currently available. In this paper, we close this gap by conducting a literature review of research works that either inherently or explicitly define product metrics for spreadsheets. We scanned five major digital libraries for scientific papers that define or use spreadsheet product metrics. Based on the identified 37 papers, we created a novel catalog of product metrics for spreadsheets. The catalog can be used by practitioners and researchers as a central reference for spreadsheet product metrics. In the paper, we (i) describe the proposed metrics in detail, (ii) report how often and for what purposes the metrics are used, (iii) identify significant discrepancies in the naming and definition of the metrics, and (iv) investigate how the appropriateness of the metrics was evaluated.},
	pages = {110910},
	journaltitle = {Journal of Systems and Software},
	author = {Hofer, Birgit and Jannach, Dietmar and Koch, Patrick and Schekotihin, Konstantin and Wotawa, Franz},
	date = {2021},
	keywords = {Metrics catalog, Spreadsheet metrics, Spreadsheet metrics survey, Spreadsheet product metrics, Spreadsheet quality assurance, xno}
}

@incollection{berger_6_2020,
	title = {6 - The hardware/software integration phase},
	isbn = {978-0-12-817811-9},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128178119000065},
	abstract = {This chapter is a detailed examination of the hardware/software integration phase. It covers each phase of the integration process and looks at possible defects that can be introduced, or are introduced, in that phase. It also considers performance issues as the product begins to be tested against its design specifications. Finally, it examines compliance issues that will inevitably come to light during final product validation.},
	pages = {127--155},
	booktitle = {Debugging Embedded and Real-Time Systems},
	publisher = {Newnes},
	author = {Berger, Arnold S.},
	editor = {Berger, Arnold S.},
	date = {2020},
	doi = {https://doi.org/10.1016/B978-0-12-817811-9.00006-5},
	keywords = {Integration, Validation, {CodeTEST}, Compliance, {EEMBC}, {FPGA}, {MIPS}, {RF}, Synthesis, {TUV}, xno}
}

@article{orlando_linux_2019,
	title = {Linux page fault analysis in android systems},
	volume = {66},
	issn = {0141-9331},
	url = {https://www.sciencedirect.com/science/article/pii/S0141933118302254},
	doi = {https://doi.org/10.1016/j.micpro.2019.01.006},
	abstract = {In modern smartphones, system performances are tightly related to a variety of underlying subsystems. In particular, internal storage, along the years, has become crucial because it is extensively used to access content relevant to the system and, finally, to the end user. To understand its role in a commercial Android smartphone and to evaluate its effects on the User experience, within the context of a real usage, we analyzed Linux page fault handling, a critical mechanism that puts pressure on storage devices and may cause system inefficiencies. A kernel tracing technique has been conceived for real-time measurement of Android applications and services on commercial smartphones. The experimental results presented in this work are derived from the use of this kernel tracing on a 64-bit Android smartphone, equipped with a ufs storage subsystem. The main subject of the study is major page fault handling, a kernel mechanism behind many end-user actions recognized at industry level as source of possible performance deterioration in a smartphone. The analysis shows that major page fault handling is dominated by read accesses to ufs (between 30\% and 40\% of the total time), and that the related storage traffic is significantly affected by the {ReadAhead} mechanism, which is not always efficient.},
	pages = {10--18},
	journaltitle = {Microprocessors and Microsystems},
	author = {Orlando, A. and Amato, P. and Caraccio, D. and Cinque, M. and Izzi, R. and Mirichigni, G. and Porzio, L.},
	date = {2019},
	keywords = {Android, Linux, Mobile, Page fault, Storage, xno}
}

@article{oyetoyan_study_2013,
	title = {A study of cyclic dependencies on defect profile of software components},
	volume = {86},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121213001878},
	doi = {https://doi.org/10.1016/j.jss.2013.07.039},
	abstract = {Background Empirical evidence shows that dependency cycles among software components are pervasive in real-life software systems, although such cycles are known to be detrimental to software quality attributes such as understandability, testability, reusability, build-ability and maintainability. Research goals Can the use of extended object-oriented metrics make us better understand the relationships among cyclic related components and their defect-proneness? Approach First, we extend such metrics to mine and classify software components into two groups – the cyclic and the non-cyclic ones. Next, we have performed an empirical study of six software applications. Using standard statistical tests on four different hypotheses, we have determined the significance of the defect profiles of both groups. Results Our results show that most defects and defective components are concentrated in cyclic-dependent components, either directly or indirectly. Discussion and conclusion These results have important implications for software maintenance and system testing. By identifying the most defect-prone set in a software system, it is possible to effectively allocate testing resources in a cost efficient manner. Based on these results, we demonstrate how additional structural properties could be collected to understand component's defect proneness and aid decision process in refactoring defect-prone cyclic related components.},
	pages = {3162--3182},
	number = {12},
	journaltitle = {Journal of Systems and Software},
	author = {Oyetoyan, Tosin Daniel and Cruzes, Daniela S. and Conradi, Reidar},
	date = {2013},
	keywords = {Defects, Defect-prone components, Dependency cycle, xno}
}

@article{colazo_performance_2014,
	title = {Performance implications of stage-wise lead user participation in software development problem solving},
	volume = {67},
	issn = {0167-9236},
	url = {https://www.sciencedirect.com/science/article/pii/S016792361400222X},
	doi = {https://doi.org/10.1016/j.dss.2014.08.007},
	abstract = {The problem-solving view of new product development sees the innovation process as a series of problem-solving loops broken down into three stages: problem detection, analysis and removal. We link this framework with lead user-driven innovation regarding software and show that effort by lead users ({LUs}) in each stage of the innovation problem solving process is, in varying degrees, associated with the source code's quality, the productivity of the development process and the software's popularity. We also test whether front loading the problem solving process is associated with development performance and we find that front loading is associated with increased code quality but decreased development productivity. Empirical tests are carried out with data from open source software projects. Findings potentially impact the design and management of online communities to help product development.},
	pages = {100--108},
	journaltitle = {Decision Support Systems},
	author = {Colazo, Jorge},
	date = {2014},
	keywords = {Front Loading, Open Source, Problem Solving, Software Development, User Innovation, xno}
}

@article{zhang_automatic_2018,
	title = {Automatic generation of predictive monitors from scenario-based specifications},
	volume = {98},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917301507},
	doi = {https://doi.org/10.1016/j.infsof.2018.01.014},
	abstract = {Context Unpredictability and uncertainty about future evolutions of both the system and its environment may easily compromise the behavior of the system. The subsequent software failures can have serious consequences. When dealing with open environments, run-time monitoring is one of the most promising techniques to detect software failures. Several monitoring approaches have been proposed in the last years; however, they suffer from two main limitations. First, they provide limited information to be exploited at run-time for early detecting and managing situations that most probably will lead to failures. Second, they mainly rely on logic-based specifications, whose intrinsic complexity may hamper the use of these monitoring approaches in industrial contexts. Objective In order to address these two limitations, this paper proposes a novel approach, called {PREDIMO} ({PREDIctive} {MOnitoring}). The approach starts from scenario-based specifications, automatically generates predictive monitors called {MAs} (Multi-valued Automata), which take into account the actual status and also the possible evolution of both system and environment in the near future, and enables the definition of precise strategies to prevent failures. More specifically, the generated monitors evaluate the specified properties and return one of the seven different values representing the degree of controllability of the system and the distance of the potential incoming failure. The translation from scenario-based specifications to {MAs} preserves the semantics of the starting specification. Method We use the design and creation research methodology to design an innovative approach that fills highlighted gaps of state-of-the-art approaches. The validation of the approach is performed through a large experimentation with {OSGi} (Open Service Gateway Initiative) applications. Results We present a novel language to specify the properties to be monitored. Then, we present a novel approach to automatically generate predictive monitors from the specified properties. Conclusion The overall approach is tool supported and a large experimentation demonstrates its feasibility and usability.},
	pages = {5--31},
	journaltitle = {Information and Software Technology},
	author = {Zhang, Pengcheng and Pelliccione, Patrizio and Leung, Hareton and Li, Xuandong},
	date = {2018},
	keywords = {Predictive monitor, Property sequence charts, Run-time monitor, Scenario-based specifications, xno}
}

@article{akbarinasaji_partially_2020,
	title = {Partially observable Markov decision process to generate policies in software defect management},
	volume = {163},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220300017},
	doi = {https://doi.org/10.1016/j.jss.2020.110518},
	abstract = {Bug repositories are dynamic in nature and as new bugs arrive, the old ones are closed. In a typical software project, bugs and their dependencies are reported manually and gradually using a issue tracking system. Thus, not all of the bugs in the system are available at any time, creating uncertainty in the dependency structure of the bugs. In this research, we propose to construct a dependency graph based on the reported dependency-blocking information in a issue tracking system. We use two graph metrics, depth and degree, to measure the extent of blocking bugs. Due to the uncertainty in the dependency structure, simply ordering bugs in the descending order of depth and/or degree may not be the best policy to prioritize bugs. Instead, we propose a Partially Observable Markov Decision Process model for sequential decision making and Partially Observable Monte Carlo Planning to identify the best policy for this sequential decision-making process. We validated our proposed approach by mining the data from two open source projects, and a commercial project. We compared our proposed framework with three baseline policies. The results on all datasets show that our proposed model significantly outperforms the other policies with respect to average discounted return.},
	pages = {110518},
	journaltitle = {Journal of Systems and Software},
	author = {Akbarinasaji, Shirin and Kavaklioglu, Can and Başar, Ayşe and Neal, Adam},
	date = {2020},
	keywords = {Defect management, Reinforcement learning, Partially observable Markov decision Process, Partially observable Monte Carlo Planning, Policy, xno}
}

@article{sun_building_2017,
	title = {Building a fault tolerant framework with deadline guarantee in big data stream computing environments},
	volume = {89},
	issn = {0022-0000},
	url = {https://www.sciencedirect.com/science/article/pii/S0022000016301143},
	doi = {https://doi.org/10.1016/j.jcss.2016.10.010},
	abstract = {Big data stream computing systems should work continuously to process streams of on-line data. Therefore, fault tolerance is one of the key metrics of quality of service in big data stream computing. In this paper, we propose a fault tolerant framework with deadline guarantee for stream computing called {FTDG}. First, {FTDG} identifies the critical path of a data stream graph at a given data stream throughput, and quantifies the system reliability of a data stream graph. Second, {FTDG} allocates tasks by the fault tolerance aware heuristic and critical path scheduling mechanism. Third, {FTDG} online optimizes the task scheduling by reallocating the critical vertices on the critical path of the data stream graph to lower the response time and reduce system fluctuations. Theoretical as well as experimental results demonstrate that the {FTDG} makes a desirable trade-off between high fault tolerance and low response time objectives in big data stream computing environments.},
	pages = {4--23},
	journaltitle = {Journal of Computer and System Sciences},
	author = {Sun, Dawei and Zhang, Guangyan and Wu, Chengwen and Li, Keqin and Zheng, Weimin},
	date = {2017},
	keywords = {Fault tolerance, Big data, Critical path, Deadline guarantee, Online applications, Stream computing, xno}
}

@article{arar_software_2015,
	title = {Software defect prediction using cost-sensitive neural network},
	volume = {33},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494615002720},
	doi = {https://doi.org/10.1016/j.asoc.2015.04.045},
	abstract = {The software development life cycle generally includes analysis, design, implementation, test and release phases. The testing phase should be operated effectively in order to release bug-free software to end users. In the last two decades, academicians have taken an increasing interest in the software defect prediction problem, several machine learning techniques have been applied for more robust prediction. A different classification approach for this problem is proposed in this paper. A combination of traditional Artificial Neural Network ({ANN}) and the novel Artificial Bee Colony ({ABC}) algorithm are used in this study. Training the neural network is performed by {ABC} algorithm in order to find optimal weights. The False Positive Rate ({FPR}) and False Negative Rate ({FNR}) multiplied by parametric cost coefficients are the optimization task of the {ABC} algorithm. Software defect data in nature have a class imbalance because of the skewed distribution of defective and non-defective modules, so that conventional error functions of the neural network produce unbalanced {FPR} and {FNR} results. The proposed approach was applied to five publicly available datasets from the {NASA} Metrics Data Program repository. Accuracy, probability of detection, probability of false alarm, balance, Area Under Curve ({AUC}), and Normalized Expected Cost of Misclassification ({NECM}) are the main performance indicators of our classification approach. In order to prevent random results, the dataset was shuffled and the algorithm was executed 10 times with the use of n-fold cross-validation in each iteration. Our experimental results showed that a cost-sensitive neural network can be created successfully by using the {ABC} optimization algorithm for the purpose of software defect prediction.},
	pages = {263--277},
	journaltitle = {Applied Soft Computing},
	author = {Arar, Ömer Faruk and Ayan, Kürşat},
	date = {2015},
	keywords = {Software quality, Software defect prediction, Machine learning, Artificial Bee Colony, Artificial Neural Network, Cost-sensitive classification, xno}
}

@article{aktekin_imperfect_2013,
	title = {Imperfect debugging in software reliability: A Bayesian approach},
	volume = {227},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221712009083},
	doi = {https://doi.org/10.1016/j.ejor.2012.11.056},
	abstract = {The objective of studying software reliability is to assist software engineers in understanding more of the probabilistic nature of software failures during the debugging stages and to construct reliability models. In this paper, we consider modeling of a multiplicative failure rate whose components are evolving stochastically over testing stages and discuss its Bayesian estimation. In doing so, we focus on the modeling of parameters such as the fault detection rate per fault and the number of faults. We discuss how the proposed model can account for “imperfect debugging” under certain conditions. We use actual inter-failure data to carry out inference on model parameters via Markov chain Monte Carlo methods and present additional insights from Bayesian analysis.},
	pages = {112--121},
	number = {1},
	journaltitle = {European Journal of Operational Research},
	author = {Aktekin, Tevfik and Caglar, Toros},
	date = {2013},
	keywords = {Software reliability, Bayesian inference, Imperfect debugging, xno}
}

@article{ovaska_knowledge_2010,
	title = {Knowledge based quality-driven architecture design and evaluation},
	volume = {52},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584909002080},
	doi = {https://doi.org/10.1016/j.infsof.2009.11.008},
	abstract = {Modelling and evaluating quality properties of software is of high importance, especially when our every day life depends on the quality of services produced by systems and devices embedded into our surroundings. This paper contributes to the body of research in quality and model driven software engineering. It does so by introducing; (1) a quality aware software architecting approach and (2) a supporting tool chain. The novel approach with supporting tools enables the systematic development of high quality software by merging benefits of knowledge modelling and management, and model driven architecture design enhanced with domain-specific quality attributes. The whole design flow of software engineering is semi-automatic; specifying quality requirements, transforming quality requirements to architecture design, representing quality properties in architectural models, predicting quality fulfilment from architectural models, and finally, measuring quality aspects from implemented source code. The semi-automatic design flow is exemplified by the ongoing development of a secure middleware for peer-to-peer embedded systems.},
	pages = {577--601},
	number = {6},
	journaltitle = {Information and Software Technology},
	author = {Ovaska, Eila and Evesti, Antti and Henttonen, Katja and Palviainen, Marko and Aho, Pekka},
	date = {2010},
	keywords = {Ontology, Software architecture, Evaluation, Model-driven development, Quality attribute, Tool, xno}
}

@article{tsoukalas_technical_2020,
	title = {Technical debt forecasting: An empirical study on open-source repositories},
	volume = {170},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220301904},
	doi = {https://doi.org/10.1016/j.jss.2020.110777},
	abstract = {Technical debt ({TD}) is commonly used to indicate additional costs caused by quality compromises that can yield short-term benefits in the software development process, but may negatively affect the long-term quality of software products. Predicting the future value of {TD} could facilitate decision-making tasks regarding software maintenance and assist developers and project managers in taking proactive actions regarding {TD} repayment. However, no notable contributions exist in the field of {TD} forecasting, indicating that it is a scarcely investigated field. To this end, in the present paper, we empirically evaluate the ability of machine learning ({ML}) methods to model and predict {TD} evolution. More specifically, an extensive study is conducted, based on a dataset that we constructed by obtaining weekly snapshots of fifteen open source software projects over three years and using two popular static analysis tools to extract software-related metrics that can act as {TD} predictors. Subsequently, based on the identified {TD} predictors, a set of {TD} forecasting models are produced using popular {ML} algorithms and validated for various forecasting horizons. The results of our analysis indicate that linear Regularization models are able to fit and provide meaningful forecasts of {TD} evolution for shorter forecasting horizons, while the non-linear Random Forest regression performs better than the linear models for longer forecasting horizons. In most of the cases, the future {TD} value is captured with a sufficient level of accuracy. These models can be used to facilitate planning for software evolution budget and time allocation. The approach presented in this paper provides a basis for predictive {TD} analysis, suitable for projects with a relatively long history. To the best of our knowledge, this is the first study that investigates the feasibility of using {ML} models for forecasting {TD}.},
	pages = {110777},
	journaltitle = {Journal of Systems and Software},
	author = {Tsoukalas, Dimitrios and Kehagias, Dionysios and Siavvas, Miltiadis and Chatzigeorgiou, Alexander},
	date = {2020},
	keywords = {Machine learning, Empirical study, Technical debt, Technical debt forecasting, xno}
}

@article{alves_test_2017,
	title = {Test coverage of impacted code elements for detecting refactoring faults: An exploratory study},
	volume = {123},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121216000388},
	doi = {https://doi.org/10.1016/j.jss.2016.02.001},
	abstract = {Refactoring validation by testing is critical for quality in agile development. However, this activity may be misleading when a test suite is insufficiently robust for revealing faults. Particularly, refactoring faults can be tricky and difficult to detect. Coverage analysis is a standard practice to evaluate fault detection capability of test suites. However, there is usually a low correlation between coverage and fault detection. In this paper, we present an exploratory study on the use of coverage data of mostly impacted code elements to identify shortcomings in a test suite. We consider three real open source projects and their original test suites. The results show that a test suite not directly calling the refactored method and/or its callers increases the chance of missing the fault. Additional analysis of branch coverage on test cases shows that there are higher chances of detecting a refactoring fault when branch coverage is high. These results give evidence that a combination of impact analysis with branch coverage could be highly effective in detecting faults introduced by refactoring edits. Furthermore, we propose a statistic model that evidences the correlation of coverage over certain code elements and the suite’s capability of revealing refactoring faults.},
	pages = {223--238},
	journaltitle = {Journal of Systems and Software},
	author = {Alves, Everton L. G. and Massoni, Tiago and Machado, Patrícia Duarte de Lima},
	date = {2017},
	keywords = {Testing, Refactoring, Coverage, xno}
}

@article{giray_software_2021,
	title = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
	volume = {180},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S016412122100128X},
	doi = {https://doi.org/10.1016/j.jss.2021.111031},
	abstract = {Context: Advancements in machine learning ({ML}) lead to a shift from the traditional view of software development, where algorithms are hard-coded by humans, to {ML} systems materialized through learning from data. Therefore, we need to revisit our ways of developing software systems and consider the particularities required by these new types of systems. Objective: The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of software engineering ({SE}) research for engineering {ML} systems. Method: I performed a systematic literature review ({SLR}). I systematically selected a pool of 141 studies from {SE} venues and then conducted a quantitative and qualitative analysis using the data extracted from these studies. Results: The non-deterministic nature of {ML} systems complicates all {SE} aspects of engineering {ML} systems. Despite increasing interest from 2018 onwards, the results reveal that none of the {SE} aspects have a mature set of tools and techniques. Testing is by far the most popular area among researchers. Even for testing {ML} systems, engineers have only some tool prototypes and solution proposals with weak experimental proof. Many of the challenges of {ML} systems engineering were identified through surveys and interviews. Researchers should conduct experiments and case studies, ideally in industrial environments, to further understand these challenges and propose solutions. Conclusion: The results may benefit (1) practitioners in foreseeing the challenges of {ML} systems engineering; (2) researchers and academicians in identifying potential research questions; and (3) educators in designing or updating {SE} courses to cover {ML} systems engineering.},
	pages = {111031},
	journaltitle = {Journal of Systems and Software},
	author = {Giray, Görkem},
	date = {2021},
	keywords = {Machine learning, Software engineering, Deep learning, Software process, Systematic literature review, Software development, xno}
}

@article{czibula_aggregated_2019,
	title = {An aggregated coupling measure for the analysis of object-oriented software systems},
	volume = {148},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218302371},
	doi = {https://doi.org/10.1016/j.jss.2018.10.052},
	abstract = {Coupling is a fundamental property of software systems which is strongly connected with the quality of software design and has high impact on program understanding. The coupling between software components influences software maintenance and evolution as well. In order to ease the maintenance and evolution processes it is essential to estimate the impact of changes made in the software system, coupling indicating such a possible impact. This paper introduces a new aggregated coupling measurement which captures both the structural and the conceptual characteristics of coupling between the software components. The proposed measure combines the textual information contained in the source code with the structural relationships between software components. We conduct several experiments which underline that the proposed aggregated coupling measure reveals new characteristics of coupling and is also effective for change impact analysis.},
	pages = {1--20},
	journaltitle = {Journal of Systems and Software},
	author = {Czibula, Istvan Gergely and Czibula, Gabriela and Miholca, Diana-Lucia and Onet-Marian, Zsuzsanna},
	date = {2019},
	keywords = {Conceptual coupling, Coupling measure, Structural coupling, Unsupervised learning, xno}
}

@article{khalilian_aprsuite_2020,
	title = {{APRSuite}: A suite of components and use cases based on categorical decomposition of automatic program repair techniques and tools},
	volume = {57},
	issn = {2590-1184},
	url = {https://www.sciencedirect.com/science/article/pii/S2590118419300528},
	doi = {https://doi.org/10.1016/j.cola.2019.100927},
	abstract = {During the last decade, we are witnessing the advent of a proliferation of techniques and associated tools for automatic program repair ({APR}). The current techniques and tools provide rich sources of knowledge that should be taken into consideration for future research. An overview of the current {APR} techniques and tools can serve the research community as a knowledge accumulator. However, {APR} techniques and tools differ in many aspects making knowledge accumulation challenging. To overcome this challenge, in this paper, we propose to leverage common components that constitute the {APR} techniques and tools. To achieve this objective, we surveyed current {APR} techniques and tools to identify the {APR} Suite of common constituent components, namely as {APRSuite}. Repair source and defect class are examples of identified components. We grouped these components into several categories such as patch evaluation and target defects. We have also identified some of the possible use cases per component as well as different lessons learned in studies for each component and for each use case. In addition, we developed a principled way for application of the components. The {APRSuite} and the principled way to apply it comprise a framework for knowledge accumulation, evaluation, and comparison of {APR} techniques and tools. The novelty of our work lies in its original viewpoint to the process of literature review in the {APR} research field. To demonstrate the applicability of the framework, we mapped out several concrete {APR} techniques, as a first instantiation of the framework. We observed that the framework brings discipline into the evaluation and/or comparison of {APR} techniques and tools. The framework offers these benefits objectively and systematically. We concluded that knowledge accumulation and characterization through literature reviews can be therefore facilitated through the identified suite of components while at the same time the existing component suite can be modified, augmented, or improved.},
	pages = {100927},
	journaltitle = {Journal of Computer Languages},
	author = {Khalilian, Alireza and Baraani-Dastjerdi, Ahmad and Zamani, Bahman},
	date = {2020},
	keywords = {Evaluation, Automatic program repair, Debugging, Fault detection and localization, Patch, xno}
}

@article{cinque_injection_2017,
	title = {On the injection of hardware faults in virtualized multicore systems},
	volume = {106},
	issn = {0743-7315},
	url = {https://www.sciencedirect.com/science/article/pii/S0743731517300849},
	doi = {https://doi.org/10.1016/j.jpdc.2017.03.004},
	abstract = {Virtualized multicore systems represent an emerging computing paradigm in the critical systems industry. Virtualization-based solutions leverage the different cores of the processor to run operating systems and applications within separate partitions, to support the development of parallel mixed-criticality systems, and to improve fault-tolerance by protecting and isolating the operating environments. The critical systems industry is subjected to international standards, which recommend fault injection as a mean to contribute with evidence to safety cases. This paper proposes a framework to inject hardware faults in virtualized multicore systems. Our proposal capitalizes on the error reporting architecture of modern processors and allows injecting faults both at hypervisor- and guest-{OS}-level. We implement the framework in the context of the widely used Intel Core i7 processor and Xen hypervisor. We demonstrate the use of the framework by means of about 60,000 injection experiments in a Linux-based virtualized multicore system installation.},
	pages = {50--61},
	journaltitle = {Journal of Parallel and Distributed Computing},
	author = {Cinque, Marcello and Pecchia, Antonio},
	date = {2017},
	keywords = {Fault injection, Dependability, Machine check exception, Multicore, Virtualization, xno}
}

@article{santos_systematic_2018,
	title = {A systematic review on the code smell effect},
	volume = {144},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218301444},
	doi = {https://doi.org/10.1016/j.jss.2018.07.035},
	abstract = {Context: Code smell is a term commonly used to describe potential problems in the design of software. The concept is well accepted by the software engineering community. However, some studies have presented divergent findings about the usefulness of the smell concept as a tool to support software development tasks. The reasons of these divergences have not been considered because the studies are presented independently. Objective: To synthesize current knowledge related to the usefulness of the smell concept. We focused on empirical studies investigating how smells impact the software development, the code smell effect. Method: A systematic review about the smell effect is carried out. We grouped the primary studies findings in a thematic map. Result: The smell concept does not support the evaluation of quality design in practice activities of software development. There is no strong evidence correlating smells and some important software development attributes, such as effort in maintenance. Moreover, the studies point out that human agreement on smell detection is low. Conclusion: In order to improve analysis on the subject, the area needs to better outline: (i) factors affecting human evaluation of smells; and (ii) a classification of types of smells, grouping them according to relevant characteristics.},
	pages = {450--477},
	journaltitle = {Journal of Systems and Software},
	author = {Santos, José Amancio M. and Rocha-Junior, João B. and Prates, Luciana Carla Lins and Nascimento, Rogeres Santos do and Freitas, Mydiã Falcão and Mendonça, Manoel Gomes de},
	date = {2018},
	keywords = {Code smell, Systematic review, Thematic synthesis, xno}
}

@article{debroy_combining_2014,
	title = {Combining mutation and fault localization for automated program debugging},
	volume = {90},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121213002616},
	doi = {https://doi.org/10.1016/j.jss.2013.10.042},
	abstract = {This paper proposes a strategy for automatically fixing faults in a program by combining the ideas of mutation and fault localization. Statements ranked in order of their likelihood of containing faults are mutated in the same order to produce potential fixes for the faulty program. The proposed strategy is evaluated using 8 mutant operators against 19 programs each with multiple faulty versions. Our results indicate that 20.70\% of the faults are fixed using selected mutant operators, suggesting that the strategy holds merit for automatically fixing faults. The impact of fault localization on efficiency of the overall fault-fixing process is investigated by experimenting with two different techniques, Tarantula and Ochiai, the latter of which has been reported to be better at fault localization than Tarantula, and also proves to be better in the context of fault-fixing using our proposed strategy. Further experiments are also presented to evaluate stopping criteria with respect to the mutant examination process and reveal that a significant fraction of the (fixable) faults can be fixed by examining a small percentage of the program code. We also report on the relative fault-fixing capabilities of mutant operators used and present discussions on future work.},
	pages = {45--60},
	journaltitle = {Journal of Systems and Software},
	author = {Debroy, Vidroha and Wong, W. Eric},
	date = {2014},
	keywords = {Program debugging, Software testing, Fault localization, Mutation, Fault-fixing, xno}
}

@article{nguyen_machine-learning_2020,
	title = {A machine-learning approach for classifying defects on tree trunks using terrestrial {LiDAR}},
	volume = {171},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169919317065},
	doi = {https://doi.org/10.1016/j.compag.2020.105332},
	abstract = {Three-dimensional data are increasingly prevalent in forestry thanks to terrestrial {LiDAR}. This work assesses the feasibility for an automated recognition of the type of local defects present on the bark surface. These singularities are frequently external markers of inner defects affecting wood quality, and their type, size, and frequency are major components of grading rules. The proposed approach assigns previously detected abnormalities in the bark roughness to one of the defect types: branches, branch scars, epicormic shoots, burls, and smaller defects. Our machine learning approach is based on random forests using potential defects shape descriptors, including Hu invariant moments, dimensions, and species. The results of our experiments involving different French commercial species, oak, beech, fir, and pine showed that most defects were well classified with an average F1 score of 0.86.},
	pages = {105332},
	journaltitle = {Computers and Electronics in Agriculture},
	author = {Nguyen, Van-Tho and Constant, Thiéry and Kerautret, Bertrand and Debled-Rennesson, Isabelle and Colin, Francis},
	date = {2020},
	keywords = {Random forests, Roundwood quality, Standing tree grading, xno}
}

@incollection{bird_chapter_2015,
	location = {Boston},
	title = {Chapter 3 - Analyzing Text in Software Projects},
	isbn = {978-0-12-411519-4},
	url = {https://www.sciencedirect.com/science/article/pii/B9780124115194000033},
	abstract = {Most of the data produced in software projects is of textual nature: source code, specifications, or documentation. The advances in quantitative analysis methods drove a lot of data analytics in software engineering. This has overshadowed to some degree the importance of texts and their qualitative analysis. Such analysis has, however, merits for researchers and practitioners as well. In this chapter, we describe the basics of analyzing text in software projects. We first describe how to manually analyze and code textual data. Next, we give an overview of mixed methods for automatic text analysis, including n-grams and clone detection, as well as more sophisticated natural language processing identifying syntax and contexts of words. Those methods and tools are of critical importance to aid in the challenges associated with today’s huge amounts of textual data. We illustrate the methods introduced via a running example and conclude by presenting two industrial studies.},
	pages = {39--72},
	booktitle = {The Art and Science of Analyzing Software Data},
	publisher = {Morgan Kaufmann},
	author = {Wagner, Stefan and Fernández, Daniel Méndez},
	editor = {Bird, Christian and Menzies, Tim and Zimmermann, Thomas},
	date = {2015},
	doi = {https://doi.org/10.1016/B978-0-12-411519-4.00003-3},
	keywords = {Automated analysis, Manual coding, Qualitative analysis, Text analytics, xno}
}

@article{garousi_experience_2010,
	title = {Experience and challenges with {UML}-driven performance engineering of a Distributed Real-Time System},
	volume = {52},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584910000042},
	doi = {https://doi.org/10.1016/j.infsof.2010.01.003},
	abstract = {Context Performance-related failures of Distributed and Real-Time Software Systems ({DRTS}’s) can be very costly, e.g., explosion of a nuclear reactor. We reported in a previous work a stress testing methodology to detect performance-related Real-Time ({RT}) faults in {DRTS}’s based on the design {UML} model of a System Under Test ({SUT}). The stress methodology aimed at increasing the chances of {RT} failures (violations in {RT} constraints). Objective After stress testing a {SUT} and finding {RT} faults, an important immediate question is how to fix (debug) those {RT} faults and prevent the same {RT} violations in the future and after deployment. If appropriate solutions to this challenge cannot be found, stress testing and its findings (detection of {RT} faults) will be of no or little use to the quality assurance goals of the development team. Method To move towards systematically solving performance-related problems causing {RT} faults, we develop a customized version of the standard Software Performance Engineering process and conduct an experiment on a {DRTS}. The process is iteratively applied to a {SUT}, while results from stress testing reveal that there are still scenarios in which {RT} constraints are violated. Results Application of the performance engineering paradigm in this context on a real {DRTS} enables systematic analysis of performance-related defects and their fixations. Conclusion The contributions of this work are an initial approach to software performance engineering based on stress testing, and an analysis, based on experimentation, of the open issues that need to be addressed in order to improve the approach.},
	pages = {625--640},
	number = {6},
	journaltitle = {Information and Software Technology},
	author = {Garousi, Vahid},
	date = {2010},
	keywords = {Distributed Real-Time Systems, Experiment, Performance tuning, Software Performance Engineering, Stress testing, {UML}, xno}
}

@incollection{zelkowitz_chapter_2011,
	title = {Chapter 5 - Action Research Can Swing the Balance in Experimental Software Engineering},
	volume = {83},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123855107000059},
	series = {Advances in Computers},
	abstract = {In general, professionals still ignore scientific evidence in place of expert opinions in most of their decision making. For this reason, it is still common to see the adoption of new software technologies in the field without any scientific basis or well-grounded criteria, but on the opinions of experts. Experimental Software Engineering is of paramount importance to provide the foundations to understand the limits and applicability of software technologies. The need to better observe and understand the practice of Software Engineering leads us to look for alternative experimental approaches to support our studies. Different research strategies can be used to explore different Software Engineering practices. Action Research can be seen as one alternative to intensify the conducting of important experimental studies with results of great value while investigating the Software Engineering practices in depth. In this chapter, a discussion on the use of Action Research in Software Engineering is presented. As indicated by a technical literature survey, along the years a growing tendency for addressing different research topics in Software Engineering through Action Research studies has been seen. This behavior can indicate the great potential of its applicability in our scientific field. Despite their clear benefits and diversity of application, the initial findings also revealed that the rigor and control of such studies should improve in Software Engineering. Aiming at better explaining the application of Action Research, an experimental study (in vivo) on the investigation of the subjective decisions of software developers, concerned with the refactoring of source code to improve source code quality in a distributed software development context is depicted. A Software Engineering theory regarding refactoring and some guidance on how to accomplish an Action Research study in Software Engineering supplement the discussions in this chapter.},
	pages = {205--276},
	publisher = {Elsevier},
	author = {Santos, Paulo Sérgio Medeiros dos and Travassos, Guilherme Horta},
	editor = {Zelkowitz, Marvin V.},
	date = {2011},
	doi = {https://doi.org/10.1016/B978-0-12-385510-7.00005-9},
	note = {{ISSN}: 0065-2458},
	keywords = {Refactoring, Action Research, Experimental Software Engineering, Scientific Knowledge Management, Software Engineering Theory, study, xno}
}

@article{ajienka_understanding_2017,
	title = {Understanding the interplay between the logical and structural coupling of software classes},
	volume = {134},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S016412121730184X},
	doi = {https://doi.org/10.1016/j.jss.2017.08.042},
	abstract = {During the lifetime of object-Oriented ({OO}) software systems, new classes are added to increase functionality, also increasing the inter-dependencies between classes. Logical coupling depicts the change dependencies between classes, while structural coupling measures source code dependencies induced via the system architecture. The relationship or dependency between logical and structural coupling have been debated in the past, but no large study has confirmed yet their interplay. In this study, we have analysed 79 open-source software projects of different sizes to investigate the interplay between the two types of coupling. First, we quantified the overlapping or intersection of structural and logical class dependencies. Second, we statistically computed the correlation between the strengths of logical and structural dependencies. Third, we propose a simple technique to determine the stability of {OO} software systems, by clustering the pairs of classes as “stable” or “unstable”, based on their co-change pattern. The results from our statistical analysis show that although there is no strong evidence of a linear correlation between the strengths of the coupling types, there is substantial evidence to conclude that structurally coupled class pairs usually include logical dependencies. However, not all co-changed class pairs are also linked by structural dependencies. Finally, we identified that only a low proportion of structural coupling shows excessive instability in the studied {OSS} projects.},
	pages = {120--137},
	journaltitle = {Journal of Systems and Software},
	author = {Ajienka, Nemitari and Capiluppi, Andrea},
	date = {2017},
	keywords = {Structural coupling, Co-changed structural dependencies ({CSD}), Coupled logical dependencies ({CLD}), Object-oriented ({OO}), Open-source software ({OSS}), References, xno}
}

@article{peng_fault-tolerant_2014,
	title = {Fault-tolerant routing mechanism based on network coding in wireless mesh networks},
	volume = {37},
	issn = {1084-8045},
	url = {https://www.sciencedirect.com/science/article/pii/S1084804513000532},
	doi = {https://doi.org/10.1016/j.jnca.2013.02.015},
	abstract = {As an essential part of next generation Internet, Wireless Mesh Networks ({WMNs}) have attracted much research attention due to their potential advantages, including low up-front cost, ease of deployment, enhanced capacity and service coverage. However, the inherit features of wireless channels (e.g., interference, noise, fading and limited bandwidth) have put forward a severe challenge for network reliability. Conventional fault-tolerant techniques either waste too many bandwidth resources or postpone the recovery speed. This paper proposes a random linear network coding based fault-tolerant routing mechanism to instantaneously recover the native packets omitted by the source. This mechanism couples the multi-path routing and random linear network coding technique by improving the conventional method of coding nodes selection. Simulation results demonstrate that our proposed fault-tolerant routing mechanism, which includes Random linear Network Coding in Multi-path with Source Coding ({RNCM}-{SC}) and Random linear Network Coding in Multi-path with Source Forwarding ({RNCM}-{SF}), perform better in terms of packet delivery ratio, resource redundancy degree, end-to-end delay and useful throughput ratio than the traditional method.},
	pages = {259--272},
	journaltitle = {Journal of Network and Computer Applications},
	author = {Peng, Yuhuai and Song, Qingyang and Yu, Yao and Wang, Fei},
	date = {2014},
	keywords = {Reliability, Routing, Fault-tolerance, Network coding, Wireless mesh networks ({WMNs}), xno}
}

@article{xu_general_2013,
	title = {A general noise-reduction framework for fault localization of Java programs},
	volume = {55},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584912001735},
	doi = {https://doi.org/10.1016/j.infsof.2012.08.006},
	abstract = {Context Existing fault-localization techniques combine various program features and similarity coefficients with the aim of precisely assessing the similarities among the dynamic spectra of these program features to predict the locations of faults. Many such techniques estimate the probability of a particular program feature causing the observed failures. They often ignore the noise introduced by other features on the same set of executions that may lead to the observed failures. It is unclear to what extent such noise can be alleviated. Objective This paper aims to develop a framework that reduces the noise in fault-failure correlation measurements. Method We develop a fault-localization framework that uses chains of key basic blocks as program features and a noise-reduction methodology to improve on the similarity coefficients of fault-localization techniques. We evaluate our framework on five base techniques using five real-life median-scaled programs in different application domains. We also conduct a case study on subjects with multiple faults. Results The experimental result shows that the synthesized techniques are more effective than their base techniques by almost 10\%. Moreover, their runtime overhead factors to collect the required feature values are practical. The case study also shows that the synthesized techniques work well on subjects with multiple faults. Conclusion We conclude that the proposed framework has a significant and positive effect on improving the effectiveness of the corresponding base techniques.},
	pages = {880--896},
	number = {5},
	journaltitle = {Information and Software Technology},
	author = {Xu, Jian and Zhang, Zhenyu and Chan, W. K. and Tse, T. H. and Li, Shanping},
	date = {2013},
	keywords = {Program debugging, Fault localization, Key block chain, Noise reduction, xno}
}

@article{chong_analyzing_2015,
	title = {Analyzing maintainability and reliability of object-oriented software using weighted complex network},
	volume = {110},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121215001752},
	doi = {https://doi.org/10.1016/j.jss.2015.08.014},
	abstract = {Modeling software systems using complex networks can be an effective technique for analyzing the complexity of software systems. To enhance the technique, the structure of a complex network can be extended by assigning a weight to the edges of the complex network to denote the strength of communicational cohesion between a pair of related software components. This paper proposes an approach to represent an object-oriented software system using a weighted complex network in order to capture its structural characteristics, with respect to its maintainability and reliability. Nodes and edges are modeled based on the complexities of classes and their dependencies. Graph theory metrics are applied onto the transformed network with the purpose to evaluate the software system. Comparative analysis is performed using 40 object-oriented software systems, with different levels of maintenance effort. We found that common statistical patterns from the software systems can be identified easily. It is when these software systems are grouped and compared based on their levels of maintenance effort that their statistical patterns are more distinguishable to represent some common behavior and structural complexity of object-oriented software. The evaluations indicate that the proposed approach is capable of identifying software components that violate common software design principles.},
	pages = {28--53},
	journaltitle = {Journal of Systems and Software},
	author = {Chong, Chun Yong and Lee, Sai Peck},
	date = {2015},
	keywords = {Software maintenance, Complex network, Software complexity, xno}
}

@article{dallal_predicting_2017,
	title = {Predicting move method refactoring opportunities in object-oriented code},
	volume = {92},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584917302689},
	doi = {https://doi.org/10.1016/j.infsof.2017.07.013},
	abstract = {Context Refactoring is the maintenance process of restructuring software source code to improve its quality without changing its external behavior. Move Method Refactoring ({MMR}) refers to moving a method from one class to the class in which the method is used the most often. Manually inspecting and analyzing the source code of the system under consideration to determine the methods in need of {MMR} is a costly and time-consuming process. Existing techniques for identifying {MMR} opportunities have several limitations, such as scalability problems and being inapplicable in early development stages. Most of these techniques do not consider semantic relationships. Objective We introduce a measure and a corresponding model to precisely predict whether a class includes methods in need of {MMR}. The measure is applicable once a class has entered the early development stages without waiting for other classes to be developed. Method The proposed measure considers both the cohesion and coupling aspects of methods. In addition, the measure uses structural and semantic data available within the class of interest. A statistical technique is applied to construct prediction models for classes that include methods in need of {MMR}. The models are applied on seven object-oriented systems to empirically evaluate their abilities to predict {MMR} opportunities. Results The results show both that the prediction models based on the proposed measure had outstanding prediction abilities and that the measure was able to correctly detect more than 90\% of the methods in need of {MMR} within the predicted classes. Conclusions The proposed measure and corresponding prediction models are expected to greatly assist software engineers both in locating classes that include methods in need of {MMR} and in identifying these methods within the predicted classes.},
	pages = {105--120},
	journaltitle = {Information and Software Technology},
	author = {Dallal, Jehad Al},
	date = {2017},
	keywords = {Logistic regression analysis, Class quality, Object-oriented design, Move method refactoring, xno}
}

@article{malhotra_extensive_2018,
	title = {An extensive analysis of search-based techniques for predicting defective classes},
	volume = {71},
	issn = {0045-7906},
	url = {https://www.sciencedirect.com/science/article/pii/S0045790617315914},
	doi = {https://doi.org/10.1016/j.compeleceng.2018.08.017},
	abstract = {In spite of constant planning, effective documentation and proper implementation of a software during its life cycle, many defects still occur. Various empirical studies have found that prediction models developed using software metrics can be used to predict these defects. Researchers have advocated the use of search-based techniques and their hybridized versions in literature for developing software quality prediction models. This study conducts an extensive comparison of 20 search-based techniques, 16 hybridized techniques and 17 machine-learning techniques amongst each other, to develop software defect prediction models using 17 data sets. The comparison framework used in the study is efficient as it (i) deals with the stochastic nature of the techniques (ii) provides a fair comparison amongst the techniques (iii) promotes repeatability of the study and (iv) statistically validates the results. The results of the study indicate promising ability of search-based techniques and their hybridized versions for predicting defective classes.},
	pages = {611--626},
	journaltitle = {Computers \& Electrical Engineering},
	author = {Malhotra, Ruchika},
	date = {2018},
	keywords = {Defect prediction, Empirical validation, Object-oriented metrics, Search-based techniques, Hybridized techniques, xno}
}

@incollection{memon_chapter_2013,
	title = {Chapter 4 - Model-Driven Engineering of Reliable Fault-Tolerant Systems—A State-of-the-Art Survey},
	volume = {91},
	url = {https://www.sciencedirect.com/science/article/pii/B9780124080898000045},
	series = {Advances in Computers},
	abstract = {To improve the reliability of a system, we can add fault-tolerance mechanisms. This, however, leads to a rise of complexity that increases the probability of software faults being introduced. Hence, unless the process is handled carefully, adding fault tolerance may even lead to a less reliable system. As a way to deal with the inherently high level of complexity of fault-tolerant systems, some research groups have turned to the paradigm of model-driven engineering. This results in a research field that crosscuts the established fields of software engineering, system verification, fault-tolerant systems and distributed systems. Many works are presented in the context of one of these traditional fields, making it difficult to get a good overview of what is presently offered. We survey 10 approaches for model-driven engineering of reliable fault-tolerant systems and present 13 characteristics classifying the approaches in a manner useful for both users and developers of such approaches. We further discuss the state of the field and what the future may bring.},
	pages = {119--205},
	booktitle = {Advances in Computers},
	publisher = {Elsevier},
	author = {Slåtten, Vidar and Herrmann, Peter and Kraemer, Frank Alexander},
	editor = {Memon, Atif},
	date = {2013},
	doi = {https://doi.org/10.1016/B978-0-12-408089-8.00004-5},
	note = {{ISSN}: 0065-2458},
	keywords = {Fault tolerance, Verification, Reliability, Survey, Model-driven engineering, xno}
}

@article{ni_empirical_2019,
	title = {An empirical study on pareto based multi-objective feature selection for software defect prediction},
	volume = {152},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121219300573},
	doi = {https://doi.org/10.1016/j.jss.2019.03.012},
	abstract = {The performance of software defect prediction ({SDP}) models depend on the quality of considered software features. Redundant features and irrelevant features may reduce the performance of the constructed models, which require feature selection methods to identify and remove them. Previous studies mostly treat feature selection as a single objective optimization problem, and multi-objective feature selection for {SDP} has not been thoroughly investigated. In this paper, we propose a novel method {MOFES} (Multi-Objective {FEature} Selection), which takes two optimization objectives into account. One optimization objective is to minimize the number of selected features, this objective is related to the cost analysis of this problem. Another objective is to maximize the performance of the constructed {SDP} models, this objective is related to the benefit analysis of this problem. {MOFES} utilizes Pareto based multi-objective optimization algorithms ({PMAs}) to solve this problem. In our empirical study, we design and conduct experiments on {RELINK} and {PROMISE} datasets, which are gathered from real open source projects. Firstly, we analyze the influence of different {PMAs} on {MOFES} and find that {NSGA}-{II} can achieve the best performance on both datasets. Then, we compare {MOFES} method with 22 state-of-the-art filter based and wrapper based feature selection methods, and find that {MOFES} can effectively select fewer but closely related features to construct high-quality models. Moreover, we also analyze the frequently selected features by {MOFES}, and these findings can be used to provide guidelines on gathering high-quality {SDP} datasets. Finally, we analyze the computational cost of {MOFES} and find that {MOFES} only needs 107 seconds on average.},
	pages = {215--238},
	journaltitle = {Journal of Systems and Software},
	author = {Ni, Chao and Chen, Xiang and Wu, Fangfang and Shen, Yuxiang and Gu, Qing},
	date = {2019},
	keywords = {Software defect prediction, Feature selection, Empirical study, Search based software engineering, Multi-Objective optimization, xno}
}

@article{bao_execution_2018,
	title = {Execution anomaly detection in large-scale systems through console log analysis},
	volume = {143},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218301031},
	doi = {https://doi.org/10.1016/j.jss.2018.05.016},
	abstract = {Execution anomaly detection is important for development, maintenance and performance tuning in large-scale systems. System console logs are the significant source of troubleshooting and problem diagnosis. However, manually inspecting logs to detect anomalies is unfeasible due to the increasing volume and complexity of log files. Therefore, this is a substantial demand for automatic anomaly detection based on log analysis. In this paper, we propose a general method to mine console logs to detect system problems. We first give some formal definitions of the problem, and then extract the set of log statements in the source code and generate the reachability graph to reveal the reachable relations of log statements. After that, we parse the log files to create log messages by combining information about log statements with information retrieval techniques. These messages are grouped into execution traces according to their execution units. We propose a novel anomaly detection algorithm that considers traces as sequence data and uses a probabilistic suffix tree based method to organize and differentiate significant statistical properties possessed by the sequences. Experiments on a {CloudStack} testbed and a Hadoop production system show that our method can effectively detect running anomalies in comparison with existing four detection algorithms.},
	pages = {172--186},
	journaltitle = {Journal of Systems and Software},
	author = {Bao, Liang and Li, Qian and Lu, Peiyao and Lu, Jie and Ruan, Tongxiao and Zhang, Ke},
	date = {2018},
	keywords = {Control flow analysis, Execution anomaly detection, Log analysis, Trace anomaly index, xno}
}

@article{zhang_empirical_2021,
	title = {An empirical study on clone consistency prediction based on machine learning},
	volume = {136},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921000562},
	doi = {https://doi.org/10.1016/j.infsof.2021.106573},
	abstract = {Context: Code Clones have been accepted as a common phenomenon in software, thanks to the increasing demand for rapid production of software. The existence of code clones is recognized by developers in the form of clone group, which includes several pieces of clone fragments that are similar to one another. A change in one of these clone fragments may indicate necessary “consistent changes” are required for the rest of the clones within the same group, which can increase extra maintenance costs. A failure in making such consistent change when it is necessary is commonly known as a “clone consistency-defect”, which can adversely impact software maintainability. Objective: Predicting the need for “clone consistent changes” after successful clone-creating or clone-changing operations can help developers maintain clone changes effectively, avoid consistency-defects and reduce maintenance cost. Method: In this work, we use several sets of attributes in two scenarios of clone operations (clone-creating and clone-changing), and conduct an empirical study on five different machine-learning methods to assess each of their clone consistency predictability — whether any one of the clone operations will require or be free of clone consistency maintenance in future. Results: We perform our experiments on eight open-source projects. Our study shows that such predictions can be reasonably effective both for clone-creating and changing operating instances. We also investigate the use of five different machine-learning methods for predictions and show that our selected features are effective in predicting the needs of consistency-maintenance across all selected machine-learning methods. Conclusion: The empirical study conducted here demonstrates that the models developed by different machine-learning methods with the specified sets of attributes have the ability to perform clone-consistency prediction.},
	pages = {106573},
	journaltitle = {Information and Software Technology},
	author = {Zhang, Fanlong and Khoo, Siau-cheng},
	date = {2021},
	keywords = {Machine learning, Software maintenance, Clone consistency prediction, Clone consistent change, Code clones, xno}
}

@article{sun_frlink_2017,
	title = {{FRLink}: Improving the recovery of missing issue-commit links by revisiting file relevance},
	volume = {84},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584916303792},
	doi = {https://doi.org/10.1016/j.infsof.2016.11.010},
	abstract = {Context: Though linking issues and commits plays an important role in software verification and maintenance, such link information is not always explicitly provided during software development or maintenance activities. Current practices in recovering such links highly depend on tedious manual examination. To automatically recover missing links, several approaches have been proposed to compare issue reports with log messages and source code files in commits. However, none of such approaches looked at the role of non-source code complementary documents in commits; nor did they consider the distinct roles each piece of the source code played in the same commit. Objective: We propose to revisit the definition of relevant files contributing to missing link recovery. More specifically, our work extends existing approaches from two perspectives: (1) Inclusion extension: incorporating complementary documents (i.e., non-source documents) to learn from more relevant data; (2) Exclusion extension: analyzing and filtering out irrelevant source code files to reduce data noise. Method: We propose a File Relevance-based approach ({FRLink}), to implement the above two considerations. {FRLink} utilizes non-source documents in commits, since they typically clarify code changes details, with similar textual information from corresponding issues. Moreover, {FRLink} differentiates the roles of different source code files in a single commit and discards files containing no similar code terms as those in issues based on similarity analysis. Results: {FRLink} is evaluated on 6 projects and compared with {RCLinker}, which is the latest state-of-the-art approach in missing link recovery. The result shows that {FRLink} outperforms {RCLinker} in F-Measure by 40.75\% when achieving the highest recalls. Conclusion: {FRLink} can significantly improve the performance of missing link recovery compared with existing approaches. This indicates that in missing link recovery studies, sophisticated data selection and processing techniques necessitate more discussions due to the increasing variety and volume of information associated with issues and commits.},
	pages = {33--47},
	journaltitle = {Information and Software Technology},
	author = {Sun, Yan and Wang, Qing and Yang, Ye},
	date = {2017},
	keywords = {Mining software repositories, Commit analysis, Information retrieval ({IR}), Issue reports, Missing links, xno}
}